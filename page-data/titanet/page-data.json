{"componentChunkName":"component---src-templates-post-tsx","path":"/titanet/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<ul>\n<li>paper : <a href=\"https://arxiv.org/pdf/2110.04410v1.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n<li>code : <a href=\"https://github.com/NVIDIA/NeMo\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></li>\n</ul>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2005.03191\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">contextnet paper</a></li>\n<li><a href=\"https://arxiv.org/abs/2005.07143\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ecapa-tdnn paper</a></li>\n<li><a href=\"https://arxiv.org/abs/1806.03464\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">angular softmax paper</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 582px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 127.02702702702702%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAIAAAC+dZmEAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAEp0lEQVR42oVU+2/TVhTuHzYhlYn9hqYxDQ2hlYptCNB+QEKTJqbuPYFg7SisUNrSdtDybEFAH9CmadI83DRPSBrHduwmcVI/8rCdOH473nFaxiZN2pVjSyfnu/c793zf6XEcp9PpOB3H0CymUm/UWo7ldGw39r+rB34NiV3M/jQf/25u64dHyPfzyQvrxIiqKt19Lbtj7b8d+z/AnFCaTZ28G/tidK1v6Pkn48in86+/qdb4UqnEVKqQoLQVy3KRlrtsy7bhA9xcMC8WZ1L9dxL9o77j44HPphPHn2cHFKVtmQ7O+17mLi6lfl9GL2bZFaiui3WXYZguuFIlJgL9Y57TY2tfjnlOja1/vpD+udlqaqoTpe+NRT6+6T1+CzkSLIy7hTj7l7EPrtVq+XzesjRdU1RFdjqmoeuy0rZNJ1y8fQ3pve796Dpy0Ede64L3KzdMs0dVVYbZJXeowDY950s9DWTSBV4Uag1RtG2HFSh0d2M1Nvu64CnXsY7tQL17nXBPVlWN4ziW5RI79cUQvhQhcUYSGnWp2YK7URVdaevheKBSZhp1sd1ui6KoKMo72qIopTMZEsNX/DOJlK9conM4LreBvxMqTAz5e/9YPzK0ftBHubR1XQOy78A8z0ejWyRBrgaeIlE/iedzuRzcNlT3uvLs7ubZKe+5O8iZaOmB2za1JbebtmPqhtED9OtV3htOjLzCbyyiwy+2J9ewLIopqguO048nN/tuLJ2aCPVtFu90T9ah0v2TgTNToZcCyQtPyPO3A1/PJH59hr3JYiqAO06Enh7yHrr05MNBz6FV4sqjzJmLL9/77dUHw+EDtJhyaQtCI4hEloPJBX9sBUlvRNNZNAeFGbqdwvwI/ihdXEe51V0pw8sYwYVwNkRLcVkVXHCr1aryfEusCzVeqHFyU2RYVpZlaEwmH05Sy1QtQtbDbDPnLVyeDp6d9p2by37FNom34Gq13mjw1RrHV6EQluOlpgR/hYrjw8GDgy8PXw28781f3a4trKLDq+mRcPlWXS53XdVoJBPx3DZ6/8WgP/y8tFPEcEyUJKg5Rj8AzU9unIb3VnH2bau0f8kznkjGM3lfNO6LJOJpHNQKRLrgh3/GuuB4f6QLVjW5rbTAIAa0qtWSOabs2Xwz8IQYmI19ez91eZFAsbwgCqDtLXrmpv/oqKdvNHg0XJgCsPZPkYAGazy7EoxdfoH/OBv65XHy+kIaw12woTux8r2JyLGRpZOTW8eC1BRcoWFAn1WQt2sM2EOSJJAUgWO5HEaS+WKhQNM0WFLXnHj54SRy4ubyqcnNE0C7UZe3sxkURSEBLN0DWgdj0OUygvNz/sz8RnabFttyE7Stq06wMHrFc+DS08ODa71e4lrHcmA8AcQ9GWiD3BiGyefJOMGtbOW8yR2sLDQlUdN0IGZYumlrHM/UBWie6yqguecqV9vwgRDgTcP4e7LtOdZ2ZxXMUUhQNA22AjNAlmlalunOMrtnb6xB6yCoACeYJaoKdGCYGG6iCee4kO7Su8G9+P70VNotBNlkWG53t5JDUYraKRVLJEmWuosgiEKxSFFUpVKGIAUPRYGLHcf5C3RTC47oUmZSAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png\"\n        srcset=\"/static/011c0e30e8c5868e8e9afcd77fca3909/12f09/architecture.png 148w,\n/static/011c0e30e8c5868e8e9afcd77fca3909/e4a3f/architecture.png 295w,\n/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png 582w\"\n        sizes=\"(max-width: 582px) 100vw, 582px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><code class=\"language-text\">ContextNet</code> architecture와 비슷한데, decoder 부분만 보면 attentive pooling에 2번의 projections 후 AAM (Additive Angular Margin) 한다.</p>\n<h3 id=\"encoder\" style=\"position:relative;\"><a href=\"#encoder\" aria-label=\"encoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Encoder</h3>\n<p>차이점은 거의 없지만 특징만 써 보면 다음과 같습니다.</p>\n<ol>\n<li>1d time-channel depth-wise separable convolution 사용\n<ul>\n<li>1d depth-wise conv + point-wise conv</li>\n</ul>\n</li>\n<li>residual connection 전 SE (Squeeze &#x26; Excitation) 함</li>\n</ol>\n<h3 id=\"decoder--embeddings\" style=\"position:relative;\"><a href=\"#decoder--embeddings\" aria-label=\"decoder  embeddings permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Decoder &#x26; Embeddings</h3>\n<p>decoder 도 이전 연구들에 비해 특별한 점이 없다.</p>\n<ol>\n<li>attentive statistics pooling 함</li>\n</ol>\n<h3 id=\"recipes\" style=\"position:relative;\"><a href=\"#recipes\" aria-label=\"recipes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Recipes</h3>\n<p>recipe 에도 큰 특별한 점은 없다.</p>\n<ul>\n<li>전처리로 SAD는 하지 않았다.</li>\n<li>3 secs 이상의 audio는 1.5, 2, 3 secs의 chunk로 나눴다.</li>\n<li>frame window : 25 ms, hop window : 10 ms, mel features : 80, num FFT : 512\n<ul>\n<li>frequency-axis로 normalize 함</li>\n</ul>\n</li>\n<li>augmentation 함\n<ul>\n<li>RIR impulse corpora</li>\n<li>speed perturbation</li>\n<li>spec augment</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"performance\" style=\"position:relative;\"><a href=\"#performance\" aria-label=\"performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Performance</h2>\n<h3 id=\"eer-on-voxceleb1\" style=\"position:relative;\"><a href=\"#eer-on-voxceleb1\" aria-label=\"eer on voxceleb1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EER on VoxCeleb1</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/940c5/voxceleb1_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.10810810810811%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB+0lEQVR42iVS2XKjMBDU/3+SSbIPLntdZXYd43CIwxwSAmIOcRlMoCqNPQ+qkWZ6plszRAjh+34cxzg554yz2+2Wpsl+t9tut19felXJ+/3Ooujvfn84HPAYC9H3fV3XJOZcVVXbcQzDuGja5+kUx2IcxzAMd7td3bRw3t8/Tqf/x+MR1d8UZbPZwC/ynKAnwlEUmabpuu71CgZ+URayqkQs2q4DkUQIQ9fzvJBScsYul4tIkrVzUzeWZTmO43lXx3a867UoimWZu7bN83ye52makIecYRznZUEhRVFuefEYR4I+mnbWDdNzPdPQIZKxCLRFzC1KoRbypKwA7roe1yzLVPWYphkCpG0b0DifNetplNKmaQAoy8L1PLRt2xZsoQgOwGmaUmohB1cy/0ymuWL8IMAZBOH0sxqofmfZ9DT4juu83quypJZVSTkOA0EMXDVNw095ngvx9/sAy7I0CIKXj3Eqbwr6Q072nf1T1aqqwI7gV2RdgwPuCA/Dmv6S+jpXqf3TutXGZ7Tr+8fjQf58fBiGWUuJnpTamCSmohuGba8+TkwBggPfxyJgFtgLm1J8E0ZI8IQJW5Zp2w61acQYqgAPAJDAQC0WAdIwCAg5nz+pbQNSFCVBBmKMsTRJ+HNhsCcc9TnHF0IIXrCtWNyXhWGAlUrSdFmWX/cPgY6q1Z0sAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/fcda8/voxceleb1_benchmark.png\"\n        srcset=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/12f09/voxceleb1_benchmark.png 148w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/e4a3f/voxceleb1_benchmark.png 295w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/fcda8/voxceleb1_benchmark.png 590w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/940c5/voxceleb1_benchmark.png 772w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>이전 연구 (<code class=\"language-text\">ECAPA</code>) 랑 거의 comparable 한 성능을 보인다.</p>\n<h3 id=\"det-cruve\" style=\"position:relative;\"><a href=\"#det-cruve\" aria-label=\"det cruve permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DET Cruve</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d4d37e8dd848c40204c9bec602cd6896/cc8d6/det_curve_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.32432432432432%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB10lEQVR42o1TWa6jMBDM/a+WEyTSJEDYQXi38cqU8ejxnmY+phVFbburqjdux2la640QKYVSQmsJ5/xlE5xLpSRnap2GYZjnGTf7vgN1K2Dv3Uak0EmaZN1hXQwh4T6lFEOEE0IwytRNDVvX9QLHiNDAKNXz7Bi3NnKVhIpcRLPnR5A4H6T2hBCKMK1/gJVSlDEj2L5O+9jv6+jtDm0hA2HO+ZgS+D0SQfx+2h/wtm24BV8CDZ5TskKYZfaMwHcuSnXsNldQarTWXuCu65CMECL4gOJzojGbpURPo/dZkPIgFRyQJ2PMBV6WBaFQPoVTKQRZ5D4pqYcunUYZWvOXMjRBhqmcehmP+goeTI5R4HEwJnBRav4GRjQO/wCn3ISAI2eya9AwxnNCP5RLUEk7ntl+5V+I4DhKzNQrg404nAPcXqOCLGPMn5Zncv4XLvioFZS6b9XGuIRybtm1YWV6mBnH6lkLB1ygxxTg4wn32zQaxijHKi1gzGB9mndeaU0pyYOJ6I0ex7Ft26qqsI9t2yEGAdY6pAUXvEjt1jT1/X7HV/F8PhH3fv16vV5A9l2PIy6naarrBg7W4f1+4wn+4/Hoh+GGakH/+XygM0Dt07yrCiUf/2G/AePjYiUGHNp6AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/d4d37e8dd848c40204c9bec602cd6896/fcda8/det_curve_benchmark.png\"\n        srcset=\"/static/d4d37e8dd848c40204c9bec602cd6896/12f09/det_curve_benchmark.png 148w,\n/static/d4d37e8dd848c40204c9bec602cd6896/e4a3f/det_curve_benchmark.png 295w,\n/static/d4d37e8dd848c40204c9bec602cd6896/fcda8/det_curve_benchmark.png 590w,\n/static/d4d37e8dd848c40204c9bec602cd6896/cc8d6/det_curve_benchmark.png 791w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>이전 연구와 거의 비슷한 성능을 보여준다.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>이전 연구랑 큰 성능 차이도 나지 않고 architecture design 도 대부분 이전 연구들과 차이점이 없어서 연구 자체가 재미있진 않았지만, 요즘 speaker verification 모델 성능이 이 정도 나오는구나 하고 넘어갔다.</p>\n<p>첫 회사 첫 프로젝트로 speaker diarization 모델을 만들었는데, 아쉬움이 많이 남은 프로젝트라서 아직도 애착이 가는 분야이자 프로젝트다. 그래서 아직도 speech domain 다루는 회사 (synthesis 도 좋지만 diarization 쪽)를 다녀보고 싶습니다 ㅋㅋㅋㅋ</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR paper : arXiv code : github Related Work contextnet paper ecapa-tdnn paper angular softmax paper Architecture   architecture와 비슷한데, d…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li><a href=\"#encoder\">Encoder</a></li>\n<li><a href=\"#decoder--embeddings\">Decoder &#x26; Embeddings</a></li>\n<li><a href=\"#recipes\">Recipes</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#performance\">Performance</a></p>\n<ul>\n<li><a href=\"#eer-on-voxceleb1\">EER on VoxCeleb1</a></li>\n<li><a href=\"#det-cruve\">DET Cruve</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/titanet/"},"frontmatter":{"title":"TitaNet - Neural Model for speaker representation with 1D Depth-wise separable convolutions and global context","date":"Aug 18, 2022","tags":["Deep-Learning"],"keywords":["speaker-verification","aam","cnn"],"update":"Aug 18, 2022"},"timeToRead":1}},"pageContext":{"slug":"/titanet/","series":[],"lastmod":"2022-08-18"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}