{"componentChunkName":"component---src-templates-post-tsx","path":"/titanet/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<ul>\n<li>paper : <a href=\"https://arxiv.org/pdf/2110.04410v1.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n<li>code : <a href=\"https://github.com/NVIDIA/NeMo\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></li>\n</ul>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2005.03191\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">contextnet paper</a></li>\n<li><a href=\"https://arxiv.org/abs/2005.07143\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ecapa-tdnn paper</a></li>\n<li><a href=\"https://arxiv.org/abs/1806.03464\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">angular softmax paper</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 582px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 127.02702702702702%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAIAAAC+dZmEAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAEuUlEQVR42oWU+2/TVhTH84dNSDCx39A0pqEhtFKxDQHaD0jTpImJvScQrB2FFUpbSldani0I6APaNE2ah5vmCUnjt5vESR07Lzuxff26vpvTMjZp0s4P/uFcf3zO9Tnfrw8h5LoucpFlOEK12Wp0kYNc6OX+N3wIoZZSWyj8OJf6dnbz+4fYd3OZc2v0MAB677sOdJ29J4L/AYvt8kz2xJ3kZyOrfYPPPhrDPp579XW9IZXLZaFaRwjpmu44Hul4AR0IHcdxXdeDJbk0ne2fSvePBI+NhT+ZTB97Vjiv65pjI0oKviAuLGZ/W8IvFGrLyEU91gvLsj24WqfHw/2j/lOjq5+P+k+Orn06n/up0+0YACX4u6PxD28Ejt3EDkeKY95F0N7P2IMbjQbDMI5jmIYOdBW5tmWaqq5BG8VKt65i+68FPriGHQiyV3vw3s0t2/YBAARhh93mwlv8bDD7JJzPFSW53WjJMoSo1ubwnfWV5Myror/SJF2IIHR2J+FVBsAQRbFWE9PbzYUotRhnKUFpt5pKp+s4EOimrpmxVLhaEVpNWdM0WZZ1XX/btiwruXyeJanl0HQ6G6yUeYKiVE1FLooWxwdD+39fOzy4diDIeW2bpgEAeAtLkpRIbLI0uxJ+giVCLMUQBKHrGoLoVfXpnY0ztwNnp7DTifJ9b2ygq2odiGzTsnwuQs26FIilh19S1xfwoedbE6tkASd14MEp/tHERt/1xZPj0b6N0lSvsgmAsVdZlhWhyi+GM+ces1/eCn81nf7lKfm6QAKgIRfF+cnBwMGLj98f8B9coS8/zJ++8OKdX1++NxTbx8tZr+12uxXB4kuRzHwouYzl1hO5Ak4AACwTZskQRj3MldZwcWVHyUsqSYtRqhbllZQK2h7c7XbrktSVm+2G1G6IakcWajVVVV2I8kwswy1xjTjbjNU6RKB4aTJyZjJ4drbwRa1Dv4Hr9WarJdUbolSXZaUmSkpHQQhFS2NDkQMDLw5dCb8bYK5sNeZX8KGV3HCscrOpVnqqarUy6RSxhd97PhCKPStvl0iKlBUFuSjJ359K90+sn5pK92+WZt6MyvjXeqbSmVSeCSZSwXg6laMYhmm2Wj34wR/JHpzqj/dgYKia3nWRY1mWr9tVRaHi33h9/jF9fib5zb3spQUaJ5m23IY22uSnb4SOjPj7RiJHYsXbCCHjn0viOLAh1ZYjyUvPqR9moj8/ylybz5GUB1smSlbujsePDi+emNg8GuFuuxBZlgkAcF3XEwZCSFEUgiBoiiQIkmWZUrHI83yn2zENlKo8mMCO31g6ObFxPF6aaTXVrUIex3Ge5yGEPk3TRFHkKxWMkmZD+bn1whYva2pH1VQToEhx5LJ/38UnhwZW9wfoq66DANA1TfMqW7bPNE1BEBiGTdHi8iYRyGyTlXZHkQ3DtGzbckwbGqIkNNuS0vFUpSjKrqq83UYIaZomCIJtWX87265ioedV0HWRpumGYdm2bVq2Zdm249iel0Hfrq0B4B3qAOg60AEwTdMyTct70dZ13UN6YfaSu/k999S1LoZtCDVxZ6dK4DjHbZdLZZZly72gabpYKnEcV61WWJblWJbjOEmS/oL/BHRTC46MZzncAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png\"\n        srcset=\"/static/011c0e30e8c5868e8e9afcd77fca3909/12f09/architecture.png 148w,\n/static/011c0e30e8c5868e8e9afcd77fca3909/e4a3f/architecture.png 295w,\n/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png 582w\"\n        sizes=\"(max-width: 582px) 100vw, 582px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><code class=\"language-text\">ContextNet</code> architecture와 비슷한데, decoder 부분만 보면 attentive pooling에 2번의 projections 후 AAM (Additive Angular Margin) 한다.</p>\n<h3 id=\"encoder\" style=\"position:relative;\"><a href=\"#encoder\" aria-label=\"encoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Encoder</h3>\n<p>차이점은 거의 없지만 특징만 써 보면 다음과 같습니다.</p>\n<ol>\n<li>1d time-channel depth-wise separable convolution 사용\n<ul>\n<li>1d depth-wise conv + point-wise conv</li>\n</ul>\n</li>\n<li>residual connection 전 SE (Squeeze &#x26; Excitation) 함</li>\n</ol>\n<h3 id=\"decoder--embeddings\" style=\"position:relative;\"><a href=\"#decoder--embeddings\" aria-label=\"decoder  embeddings permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Decoder &#x26; Embeddings</h3>\n<p>decoder 도 이전 연구들에 비해 특별한 점이 없다.</p>\n<ol>\n<li>attentive statistics pooling 함</li>\n</ol>\n<h3 id=\"recipes\" style=\"position:relative;\"><a href=\"#recipes\" aria-label=\"recipes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Recipes</h3>\n<p>recipe 에도 큰 특별한 점은 없다.</p>\n<ul>\n<li>전처리로 SAD는 하지 않았다.</li>\n<li>3 secs 이상의 audio는 1.5, 2, 3 secs의 chunk로 나눴다.</li>\n<li>frame window : 25 ms, hop window : 10 ms, mel features : 80, num FFT : 512\n<ul>\n<li>frequency-axis로 normalize 함</li>\n</ul>\n</li>\n<li>augmentation 함\n<ul>\n<li>RIR impulse corpora</li>\n<li>speed perturbation</li>\n<li>spec augment</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"performance\" style=\"position:relative;\"><a href=\"#performance\" aria-label=\"performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Performance</h2>\n<h3 id=\"eer-on-voxceleb1\" style=\"position:relative;\"><a href=\"#eer-on-voxceleb1\" aria-label=\"eer on voxceleb1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EER on VoxCeleb1</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/940c5/voxceleb1_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.10810810810811%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACIUlEQVR42iWS226jMBRF+f9PatrOQ5ROpWQmDRffwRiMgQLBxjG4TCKNkqyHo61z0daWTqCU4pxXVcU5l1KWsuy6rmnqj91uu93GcTKOep7nsih+f3x8fn5ut9tKKeecMSaopDwcDoRSAEAUhl/HY1Up770QYrfbmckKId7e3o/Hv/v9Xkr5utm8vLzs9/uh74OqqoQQRVFACBljWcY558N50OOoKmUvl67raqVAkvT9oLWWZRlFkarru/NkJoQQpTRNM0pommXDMNxu14u1fd9fr9d1XY0xCKHF++vtViu12Wy6fvjxPuCch+EpATBlKQRJHCdlWXjvVSURxvM8O+e0HhFCl4ub57lt28Nh3zTt7Fxg7RRF0ekUogcY42manHPn88DSdF1Xa63WmjFmrZ3nuWkajNE0Tdba4PpvhfB+w/McY5znYv13xxjz3bbrA2MMZfTZH89njNCotV+WYF3XJI7DMMw4T1NGKZ3nZVmWtm3yPH9qpdTmdaO19t633+2fw2EcR+dc0Pe9NsZaO46j1npZ7uvPqM96j+oeXO74x/Ti3M/PT/Dr/R0AaLSmlGJMpJQgSRIACLlrQkiaZoyxnHMAQJpllZQE4yiKuq4LAAAQQoQgIRQTXJQlpRQkCWOMEJJzThkVQiRxHMdJnuen0xcmBEI4DOeAECKEKMuyqWv5eJgs47KSUkqe51prIUTT1FKWT4TIRVHUTXO73f4D9w+BjjoODr8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/fcda8/voxceleb1_benchmark.png\"\n        srcset=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/12f09/voxceleb1_benchmark.png 148w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/e4a3f/voxceleb1_benchmark.png 295w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/fcda8/voxceleb1_benchmark.png 590w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/940c5/voxceleb1_benchmark.png 772w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>이전 연구 (<code class=\"language-text\">ECAPA</code>) 랑 거의 comparable 한 성능을 보인다.</p>\n<h3 id=\"det-cruve\" style=\"position:relative;\"><a href=\"#det-cruve\" aria-label=\"det cruve permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DET Cruve</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d4d37e8dd848c40204c9bec602cd6896/cc8d6/det_curve_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.32432432432432%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB70lEQVR42o2S647bIBCF9/1fbZ9gLTUxiR1jJ8Jch8sMQ4VdNV21P3qE+AMf58wMH+0QAKh9996F4AC89+5YXc5aH4K3JrzWZVm2bXPWppRaax8njFjU7h2wj5xLy6UScWuNmSvV1hoRxRDFTQghXq/XG661EpHRGratGJtztYFdqNbVmPpha1yQPOC+71prAPgGhxC0MdGZ9FqTfKSXxJyIm/O0m1KwMhMRMvc46dAvWCnFzADAtVbmxpydi88Nzd6YS6k+tJR7BWeNOec3PM+z1to5R0iIpQetXVnvsErEbqgt+YDMlZljjG/4+XzWWgHgMOazEK5Hn4KHZeZD2lSiv5ydczFG7/3h13kiOnlurRgNy1y5xkjWnTX/ATNzSukfMPcmEDNZ4+cbERrbA31zPi+dseuR9nf+86HWWtF7XB8hNsRWSs45v0flvTfG4KE+k2M/30LESv2jwGMKyljfcu4te/+wc3pKKWttylkpZYzJOWutlVIpJWutWmU0RlvYticidhgOYcEAoPXeB1NrjCClnKZpHEchxDTNABAAci5ECBByzkT0cbuJz89Pte/DMAghrpcfl8tFSvmYH0KIYRjWdRXiNgzDPM/X61VKOQzD19fXY1k+vPfjON7v92maFimn++06jojU/kM/AePjYiVQE8pNAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/d4d37e8dd848c40204c9bec602cd6896/fcda8/det_curve_benchmark.png\"\n        srcset=\"/static/d4d37e8dd848c40204c9bec602cd6896/12f09/det_curve_benchmark.png 148w,\n/static/d4d37e8dd848c40204c9bec602cd6896/e4a3f/det_curve_benchmark.png 295w,\n/static/d4d37e8dd848c40204c9bec602cd6896/fcda8/det_curve_benchmark.png 590w,\n/static/d4d37e8dd848c40204c9bec602cd6896/cc8d6/det_curve_benchmark.png 791w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>이전 연구와 거의 비슷한 성능을 보여준다.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>이전 연구랑 큰 성능 차이도 나지 않고 architecture design 도 대부분 이전 연구들과 차이점이 없어서 연구 자체가 재미있진 않았지만, 요즘 speaker verification 모델 성능이 이 정도 나오는구나 하고 넘어갔다.</p>\n<p>첫 회사 첫 프로젝트로 speaker diarization 모델을 만들었는데, 아쉬움이 많이 남은 프로젝트라서 아직도 애착이 가는 분야이자 프로젝트다. 그래서 아직도 speech domain 다루는 회사 (synthesis 도 좋지만 diarization 쪽)를 다녀보고 싶습니다 ㅋㅋㅋㅋ</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR paper : arXiv code : github Related Work contextnet paper ecapa-tdnn paper angular softmax paper Architecture   architecture와 비슷한데, d…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li><a href=\"#encoder\">Encoder</a></li>\n<li><a href=\"#decoder--embeddings\">Decoder &#x26; Embeddings</a></li>\n<li><a href=\"#recipes\">Recipes</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#performance\">Performance</a></p>\n<ul>\n<li><a href=\"#eer-on-voxceleb1\">EER on VoxCeleb1</a></li>\n<li><a href=\"#det-cruve\">DET Cruve</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/titanet/"},"frontmatter":{"title":"TitaNet - Neural Model for speaker representation with 1D Depth-wise separable convolutions and global context","date":"Aug 18, 2022","tags":["Deep-Learning"],"keywords":["speaker-verification","aam","cnn"],"update":"Aug 18, 2022"},"timeToRead":1}},"pageContext":{"slug":"/titanet/","series":[],"lastmod":"2022-08-18"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}