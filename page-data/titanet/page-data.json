{"componentChunkName":"component---src-templates-post-tsx","path":"/titanet/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<ul>\n<li>paper : <a href=\"https://arxiv.org/pdf/2110.04410v1.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n<li>code : <a href=\"https://github.com/NVIDIA/NeMo\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></li>\n</ul>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2005.03191\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">contextnet paper</a></li>\n<li><a href=\"https://arxiv.org/abs/2005.07143\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ecapa-tdnn paper</a></li>\n<li><a href=\"https://arxiv.org/abs/1806.03464\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">angular softmax paper</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 582px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 127.02702702702702%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAZCAIAAAC+dZmEAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAEyklEQVQ4y42U228bRRTG82chgUCiQgK1Lwgphd5SWrVqJRDwAGqbJ8Qloi1NCqSl5OYkqClUTRqlIW2TOE6cOE7s+BYnsb132+u112t7vR7vzuzuzMC6qQSIB0ajefvNOec753xdlFJCCCUUmo4i15r1NnUpIfT/nC5KqVLnZtJXHkZ6fwv3ToV6H8Y/X2N/QcjGBLvYwcTFxCXUJRT/B5yv7k3ET09GLtxZPNX/pHtoq/tJ+qua1hBFUVV0Sik0XS85QhzHdV3XcbyLMe7AWtoX+8C33XNn5f2h9VMj0ePPMn0Q2q5D46VHM7tXpiNfPk5fOagsU0pd18NcF9uO48FsKTa8es638tlY4KOxlU/G1i77sz+1gQktNySNjEd7hlcvjEd7kvJsRyD8QibHcT1YVasFqUgJRQjZCHnfOwSYbezQ50xf/8arA8vHBjZfC+d9/4SdLgBAsZBneeFZTJp8Hn0Q2NvLa3qjpjcN1yVVvcCXk/7oDFuKVxsyxsRxHdJphgdDCKuqqpTVhFBbDGdX4qJUaWqaBkDbdbEB9EqtuLb9VCqyVa0CIdR1HUJIKT2suappyVSSOcjMLt5L7G5IgphjGMsyKaaLzI3+wJHBlff6V49sFyYppRY0EerAdgeWZTkajXAsu7Q+G42Hc9lsjslBaFFMw+LEeOjSyNLHE1uXUqX5lzA6jIwxrijyH8H4zfnswOz+9cd7I0vZXI6B0CKYhoSR0c0P7y5cGg2fTXTUhtBCyD6M3ND1UkGaDsR7p9kvRteuTiW/nzvIdmBK6DJ38/rzN/umj97yv+Xn+n2xE1/Pv9K38PrtzTeqQOzUXFWDoa3FUOJpcCcQ2dvcSecYBtnIslDiIJiWAkI5UdDj9XZeMzlejQharAz2LdT2YMMwNE1rNXW9XtPrWsswymXVNE3XpduZJxu5yURxLqk8FurhmcynPyx2Dy6d/DV1ut4uenCz2axUKlWtVlJK5YpabzQUpQzagGK6wt/6cf3tgWfvDobe2RR9TMMfZMZD7P2U+ghYugdXKpWdnehBOj0x8214e1Hk+BzDtIAHB/l749Ezo8GLk/GepDzn6YQc18adIemMZ1lRIrFEOMX5t+L+7VQkleU4rqE3KaEbwvBE5PxY8PJk7HxK9lrVtloWbBPq2o7dpTeNspyfW9+99jB3bSJ8dSrZv8BwHN80DOzQVX7wTqD77vKZe6HuhDzj9dn625BgQiqKPL8auTF38M399e+mk0MLSZ7n9GbTsem6+PPw5onBhXO+nZNRaZpiCpFlWdaLrfbSrtfruVxW5BiWyeUlQc5Lsiy3AEAQbwhDw+s9dxcu+rbPJopzmtpMp3f39/dLpRLGpKvVapUVRSrIq3vlqeXE72uZrGyYwABtgCyywt267T/aP3d8MHgsIj3wrM6bMPRyqxAqleQcw8U5NbCT3UgXBKXRMpoI2bbtuQ4mWFXVhq4bhgEAaDS8rSKEHC4GAECrVjF2/+VvhBCMMaXENE3HsT37crFnQoR47wsPcxyn3TaRbQMAWi0A2m0LeqogCG2EAAC2jSwIEfK0gp3jOM6hexp6YzO8VdU0WS5mMhlBFPN5iWPZQqEgSSLLcpIk8rxQkmWW4wRB4Hm+Vqv9Bf8J/loMHpi025QAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png\"\n        srcset=\"/static/011c0e30e8c5868e8e9afcd77fca3909/12f09/architecture.png 148w,\n/static/011c0e30e8c5868e8e9afcd77fca3909/e4a3f/architecture.png 295w,\n/static/011c0e30e8c5868e8e9afcd77fca3909/7c1cd/architecture.png 582w\"\n        sizes=\"(max-width: 582px) 100vw, 582px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><code class=\"language-text\">ContextNet</code> architecture와 비슷한데, decoder 부분만 보면 attentive pooling에 2번의 projections 후 AAM (Additive Angular Margin) 한다.</p>\n<h3 id=\"encoder\" style=\"position:relative;\"><a href=\"#encoder\" aria-label=\"encoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Encoder</h3>\n<p>차이점은 거의 없지만 특징만 써 보면 다음과 같습니다.</p>\n<ol>\n<li>1d time-channel depth-wise separable convolution 사용\n<ul>\n<li>1d depth-wise conv + point-wise conv</li>\n</ul>\n</li>\n<li>residual connection 전 SE (Squeeze &#x26; Excitation) 함</li>\n</ol>\n<h3 id=\"decoder--embeddings\" style=\"position:relative;\"><a href=\"#decoder--embeddings\" aria-label=\"decoder  embeddings permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Decoder &#x26; Embeddings</h3>\n<p>decoder 도 이전 연구들에 비해 특별한 점이 없다.</p>\n<ol>\n<li>attentive statistics pooling 함</li>\n</ol>\n<h3 id=\"recipes\" style=\"position:relative;\"><a href=\"#recipes\" aria-label=\"recipes permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Recipes</h3>\n<p>recipe 에도 큰 특별한 점은 없다.</p>\n<ul>\n<li>전처리로 SAD는 하지 않았다.</li>\n<li>3 secs 이상의 audio는 1.5, 2, 3 secs의 chunk로 나눴다.</li>\n<li>frame window : 25 ms, hop window : 10 ms, mel features : 80, num FFT : 512\n<ul>\n<li>frequency-axis로 normalize 함</li>\n</ul>\n</li>\n<li>augmentation 함\n<ul>\n<li>RIR impulse corpora</li>\n<li>speed perturbation</li>\n<li>spec augment</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"performance\" style=\"position:relative;\"><a href=\"#performance\" aria-label=\"performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Performance</h2>\n<h3 id=\"eer-on-voxceleb1\" style=\"position:relative;\"><a href=\"#eer-on-voxceleb1\" aria-label=\"eer on voxceleb1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>EER on VoxCeleb1</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/940c5/voxceleb1_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.10810810810811%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAIAAADtbgqsAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACI0lEQVQozy2S226jMBCGef83ajfNVdJulW27lIONjU9gYkiIsQETAg1aJdnvYjSjGWlOv1cUBaVUSskozfM8y8TxeFRq//q63Ww2cQyapnHOCSF+v729v79vttv9XvV9b4zxpJQfn59pmgIAwjD0fV+pchxHxuh2u227XnD+sl5/fX392f3Jc/n86/np6Wm3251OJ68oCsFFJkQMQJpiShljTGvdNI1Stw7HY62UAgBorY0xhZRhFJZlZa31WmshhDjFlBCMMaW0acyyLF3Xaa2v1+s8z9baJEnG8XJdlv2+eFmtTlqP4+gxSnzfj2NACImjMIyiPM8vl1HKHCE0DINzrmkaCKFzbhiGslS73a46HJxzXtu2QfDtf38nCYQQIozbrhucO51qQuk0TV3XGWMIIV3XOeeUUkmSdHe8eZpiACBMGGcJTLgQ8zz//PxYYw6Hw3zHGIMxevhaawiBMfZ8PnuXyxRGYRAEnHFCUpyS4XyjLJUQ4u6e90WxWq2steM4VlX18flhjLmNXde1tbZtW900xtpH9WPV4Xyzfe8eUX9nHP9np2ny1us1hIm1FmOMEJZSRmEYxzFCSEqJECKUpmnKGYvjiFBWSJkkMAiCuq69KIogBBDcToUwzrIMYxzHMSEEIcQ5T3GaZdn9DxHn3Pf/IowhBLppPISwyDIpZVmWN8EIQRkrikJKybkwxnDOy7KUUuZSPvQrsqyqqmVZ/gGyboIpvW4AwQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/fcda8/voxceleb1_benchmark.png\"\n        srcset=\"/static/c1f0f3c0516171ac70ebc8d93c4ea405/12f09/voxceleb1_benchmark.png 148w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/e4a3f/voxceleb1_benchmark.png 295w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/fcda8/voxceleb1_benchmark.png 590w,\n/static/c1f0f3c0516171ac70ebc8d93c4ea405/940c5/voxceleb1_benchmark.png 772w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>이전 연구 (<code class=\"language-text\">ECAPA</code>) 랑 거의 comparable 한 성능을 보인다.</p>\n<h3 id=\"det-cruve\" style=\"position:relative;\"><a href=\"#det-cruve\" aria-label=\"det cruve permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>DET Cruve</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d4d37e8dd848c40204c9bec602cd6896/cc8d6/det_curve_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.32432432432432%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB4ElEQVQoz4VS2W7bQAz0/39c85zajnVYtu7VHlztwaOQFCQ1UqDzsgMSAw45e5IdzjmlFgAH4LyHg2zPDvAejIaxb5pmGAZjTEpJRE6HOOekFrCr2FVCkhgJkUWEmYlIRBDRw1oURV3X0zTFGD/FzJxyXubZt23SJgQyni2wNrQGIkIRjgkdpEUpY4z3/ltMRACgtQnGhLEP7SOMXY4RRaxDpXNGYkZCPGy+iKdp4r3EIry3ozVh6LJWIpwSWZCYvpoSQvjeuWkarbW1FhEx520KMzHHRUHXZszMpDT69Sjzy+RhGI4S7zgWOUi2xrcPZiHixRDxj8nHDZxztIOZEfHgJJIW5dsnC4NHC7zvvL5cO4TwU7zlhIjMeVGuqZFoMZuhdX0V55z/afsr5zRPa9/CKkSb7RjTd1TWWmPMlikeV8sHIaJPLuKbyilnQEL4a/JXANM0WWtDCOM4aq1DCPM8q3kOISxaz323Wqs09H1/2DkBQAgh5+yc08tyGHYAj8ejrqvb7VYURdM0239f15gSYgKAGCMinm4fH7/e3tSyvP9+v9/v1+ulKG5d1z+fz/u9vl6v4zhVVXW5XJ/PR1mWXdudL+fL+TwMw8kaU5ZlXdf3pmnbrq6rsqoOV//FH8ATYsJxWKTdAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/d4d37e8dd848c40204c9bec602cd6896/fcda8/det_curve_benchmark.png\"\n        srcset=\"/static/d4d37e8dd848c40204c9bec602cd6896/12f09/det_curve_benchmark.png 148w,\n/static/d4d37e8dd848c40204c9bec602cd6896/e4a3f/det_curve_benchmark.png 295w,\n/static/d4d37e8dd848c40204c9bec602cd6896/fcda8/det_curve_benchmark.png 590w,\n/static/d4d37e8dd848c40204c9bec602cd6896/cc8d6/det_curve_benchmark.png 791w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>이전 연구와 거의 비슷한 성능을 보여준다.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>이전 연구랑 큰 성능 차이도 나지 않고 architecture design 도 대부분 이전 연구들과 차이점이 없어서 연구 자체가 재미있진 않았지만, 요즘 speaker verification 모델 성능이 이 정도 나오는구나 하고 넘어갔다.</p>\n<p>첫 회사 첫 프로젝트로 speaker diarization 모델을 만들었는데, 아쉬움이 많이 남은 프로젝트라서 아직도 애착이 가는 분야이자 프로젝트다. 그래서 아직도 speech domain 다루는 회사 (synthesis 도 좋지만 diarization 쪽)를 다녀보고 싶습니다 ㅋㅋㅋㅋ</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR paper : arXiv code : github Related Work contextnet paper ecapa-tdnn paper angular softmax paper Architecture   architecture와 비슷한데, d…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li><a href=\"#encoder\">Encoder</a></li>\n<li><a href=\"#decoder--embeddings\">Decoder &#x26; Embeddings</a></li>\n<li><a href=\"#recipes\">Recipes</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#performance\">Performance</a></p>\n<ul>\n<li><a href=\"#eer-on-voxceleb1\">EER on VoxCeleb1</a></li>\n<li><a href=\"#det-cruve\">DET Cruve</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/titanet/"},"frontmatter":{"title":"TitaNet - Neural Model for speaker representation with 1D Depth-wise separable convolutions and global context","date":"Aug 18, 2022","tags":["Deep-Learning"],"keywords":["speaker-verification","aam","cnn"],"update":"Aug 18, 2022"},"timeToRead":1}},"pageContext":{"slug":"/titanet/","series":[],"lastmod":"2022-08-18"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}