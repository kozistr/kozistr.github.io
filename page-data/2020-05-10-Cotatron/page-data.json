{"componentChunkName":"component---src-templates-post-tsx","path":"/2020-05-10-Cotatron/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다.</p>\n<p>간단하게 요약하면, 유명한 google 의 TTS model 인 <em>tacotron2</em> 기반으로 given transcription 와 mel alignment 를 활용해서 speaker-independent linguistic representation 을 뽑는 concept(?) 입니다.</p>\n<p>결론은 VCTK dataset 에서 최근 paper 인 <em>Blow</em> 보다 높은 MOS, DMOS 를 달성했습니다. 아래 링크에 들어가면 모델이 생성한 sample 들을 들어볼 수 있어요.</p>\n<p>paper : <a href=\"https://arxiv.org/pdf/2005.03295.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></p>\n<p>demo : <a href=\"https://mindslab-ai.github.io/cotatron/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">link</a></p>\n<p>code : 아직 official code / pre-trained model은 없는데, 곧 나올 예정인 듯합니다</p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>이전 SOTA 였던 paper</p>\n<ul>\n<li>Blow : <a href=\"https://arxiv.org/pdf/1906.00794.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p><em>Cotatron</em>의 전체적인 architecture 는 아래와 같습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 88.51351351351352%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEVklEQVR42m2Ue2xTVRzHr0NiNMb/8A8T/zdG/1ARJSjC3BhEERWYkWgI4AMT/MfgH5qof4g8JgPlMWR0PObYy41RtkDZ6CwM9qLruq503dauj7Vrb2m7221dX1s/nt6NxNdJvvn97rn3fH6Pc86VlHiCJrObhj4Hl61+PHKE+UyaVGqOYGCQUNCAY1jHmKMV91gbblcbTuGPe9pxjOjwedu5L98mEuogGhlHkmNxThvHOX7ThmZAptc2ihK5jxyK4hvvJBlvZdReI6C12G0Xha1hoP8CQf8VJnxaghPNxKfbSSf0hMNOpLn5eWZm4pgtVpTYNPPi+cFIxKcFXGZ2RhGLJoWdFAFimE09mO52MWyzcM9iEoEsIsMJMukUUm6hxePg2yYNXcMW5IkAAxYLLqcTiy/MVbtMs8VDi3V8UT6qO+9RfXuQ2i4bjcZRGu6OcN0RwR+dWgA2GzsovnCIqluiJx4vJrMZn9tFS7+DU8YJSlvNlFw1UqIzUdpmoeyOg7PmICduDXNUP8iRtgE01gg2f3gBmM5ksHldJEXK8ZkZFEVRS85k50jMiw0SNrmoNFnMQ1Y8AR9jPi+zmRRzYi6ZSIp2ZZFiMVk0c5R0alaFDLr8WF0+1XcNerjd0E2P1khXU6+qO43dtGiuYajr4KpGh75CT2dzH12jViangkgBfy9u5+9iY2QSiTQXrSHqrLIKrDxQz28/VtBSew1tZQvXG/XUn75M0eNbeU16izVLt7D66W2sWr6D5cu2oqvWi2MT6GPEXslsPER6Dso7bFTcHFSB57+vZW/Rd+zbUcpPO45ycOcv/LDpAEXLPuaNl3aTv/YLCp/dTuGjxayW3uZGrQHJ5+2ht6uMmOInqkxz5o4djSEHnOPU3vM8L61h5ZINvCIV8LK0gRVPfUj+agF7ejsFD22hQHqfwjyRqbQJfd2tXMl36e8rF7fCidvjQ9Np55yAxqYjlH11jtdF5PWPbWPNi3soKPiSwmd2UZC3WQWpQAErzNsqgO/QXt8hgBNGTMZy4qLkTK7km9bFDEHzdZXo1UbWrdpD/nOfU/TIBxRJm1n3cDHrlgp/SbGq9cJfK71H+0KGPYwMVYgeihsxm6LSEqDmXkgFnvhGlPzkRlY+8a4o+U1WSEVCufLX/0Ov5m3gBSkfXY3YlMnoOMGgScCmVEiPw0+vY+HYDDmHuVjeTP1BLXWlV6j7WUvNoctU7W8Qtonqg5dUW1PSRNW+Bjx28XPIZiF3fXNWPczpJGE5SCgUEhulkErPisOdICUkh4O4vE6cnhHV//u9fzCkf0/kuLkPc1KmpwhGI4Qmo6r8IsiY10tvfz/eYICQMkk4pqjKvU+kkv8F5sZ8diFydbeej87sZ2f5IXadPcxnlUfYU1/GzooSdgl9cv6w6u+uPsantcfoHrH+PzC7WL9hqJ8j1//gxI1LnPxTS1lOhiscb23kV12DOneyfWH+uEGL3efmLzwvfS9PEImFAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png\"\n        srcset=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/12f09/cotatron-architecture.png 148w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e4a3f/cotatron-architecture.png 295w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png 590w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png 861w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"1-speaker-independent-linguistic-features-from-tts\" style=\"position:relative;\"><a href=\"#1-speaker-independent-linguistic-features-from-tts\" aria-label=\"1 speaker independent linguistic features from tts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. speaker-independent linguistic features from TTS</h3>\n<p>이번에 제안한 <em>cotatron</em> 은 google 의 <em>tacotron2</em> 를 기반으로 합니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><msub><mi>M</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>^</mo></mover><mo separator=\"true\">,</mo><msub><mi>A</mi><mi>i</mi></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>M</mi><mrow><mn>0</mn><mo>:</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msup><mi>z</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{M_{1:i}} , A_i = Decoder (Encoder(T), M_{0:i-1}, z^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1412em;vertical-align:-0.1944em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9468em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.2523em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0991em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">Deco</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">co</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n</blockquote>\n<p><em>T</em> 는 Transcription, <em>M</em> 은 log mel-spectogram, <em>z</em> 는 speaker representation.</p>\n<p>요거로부터 mel alignment + given transcription + speaker representation 으로 새로운 speech 를 생성합니다.</p>\n<p>이 이후가 중요(?)한데, TTS 훈련 후에,\nDecoder output 으로 transcription 과 mel-spectogram 사이의 <em>Alignment</em> 가 나오는데, 요 부분을 training 할 때 <em>teacher-forcing</em> 기술을 사용해서 훈련했다고 합니다.</p>\n<p>그래서 최종적으로 Speaker-Independent linguistic features 는 다음과 같습니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>t</mi><mi>m</mi><mi>u</mi><mi>l</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo separator=\"true\">,</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L = matmul(A, Encoder_{text}(T))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">L</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">co</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">))</span></span></span></span></span></p>\n</blockquote>\n<p>그런데 한 가지 짚어야 할 점은,\n<em>T</em> 는 speaker 에 대한 정보가 없는 text 고,\n<em>A</em> 는 간단히 text 와 mel spectogram 과의 coef 라 할 수 있는데,\n즉, <em>L</em> 이 speaker 에 대한 정보를 담고 있지 않다는 점이다. 이 부분은 아래에</p>\n<p><em>Cotatron</em>은 이미 <em>Tacotron2</em> 기반의 모델이라 multi-speaker speech synthesis 에 well-optimized 됐을 거지만,\n조금 더 잘해 보려고(?) 기존의 embedding table 을 걷어내고, speaker representation encoder 를 하나 만들어 넣었다고 합니다.</p>\n<p>해당 encoder 구조는 2d cnn 6 layers + gru 구조로 구성.</p>\n<h4 id=\"speaker-disentanglement-issue-\" style=\"position:relative;\"><a href=\"#speaker-disentanglement-issue-\" aria-label=\"speaker disentanglement issue  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>speaker disentanglement issue ?</h4>\n<p>그래서 이런 speaker disentanglement 에 대한 issue 를 해결하기 위해 speaker classifier 를 추가로 붙여 줬다고 캅니다.</p>\n<p>이 때 사용된 모델은 간단한 1d cnn 4 layers + temporal max-pooling + fc 로 구성.</p>\n<h3 id=\"2-voice-conversion\" style=\"position:relative;\"><a href=\"#2-voice-conversion\" aria-label=\"2 voice conversion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. voice conversion</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.972972972972975%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACAUlEQVR42nWS3WvTABTF+yf7IPgvKD76IoOh4IM4dKIyRJwijnWFfXVbl7RJ16SfSZO2Sdt8N+3Pm8igwrzhcu8l4d5zTk6F/8RmsylrFAaoyi2aoqLUr6hf1LEs659vtqOSxAlhGBIGIXEc4Xsd4miBOw+46jm0bJ++ZXN4WePz6RGqefd3mTyykTRNSZJMMiXLVlQmk4lcHDEcjpjOXEzjAG/ap6Z0ePGjzutqkzO1xfPvezz+8oqqdsM6h3maE2c5rmPT6+pl+r5PZRtunq9ZrXKiKMHzPOlXAmItlzOCZcBoMGQyttmvNXj69YyP5x1G/Rv05lsG3QOyNKRSbHWcMbbt4NgXDHufGJi/OFU7vPzd4E2txdmtyrNv73j0YYcjtU4Qpty0TbwgJk0iOeaIZFPW6zWVNM1Eu7jUIFhazH2dJLLwg4jrvmhozXAFbVVv8FO9xBiPSjYFg4eiYnQMut0erVYT152yXHgslyG6NUWTVAYOw8kcwx5w3LoWWilhFOK47r0ftlIWOo6DrmvcNhq0pXaNY8aC4v35HbsnOjtVTWgO2Ds55Mn+Lp5IVDAqnPEgwuKF73vMZkJNruZ5XmqRpkmJpqgbmRPpF+LJoi9+0kMeLBfeNwXSjmHQbosFej00TRfkusxtTNNEVVWRplvWYm42myiKUlpl2+R/AHI86hxzpvl6AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png\"\n        srcset=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/12f09/voice-conversion-system.png 148w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/e4a3f/voice-conversion-system.png 295w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png 590w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/efc66/voice-conversion-system.png 885w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png 936w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>위 이미지처럼 voice-conversion system 인데, 전반적인 pipeline 이 그려져 있습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.56756756756756%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADP0lEQVR42kWT+W8aVxDH+YOjKlWqVm1/6x8QtUoT17XTxKQ+SBzj2PhoLB/CYMfGgDl2gV0Mu7DLYY4FFljA4E8f5PBIX82h92bmO2+eq9s6xNC2UCQPmaQHRX6LqW/Tbh7Qbfr5lLrmp903/CLwvWeOx6sveLL+N4/XXvCzz80T3yveh/xsRYOcpKK4Wp001VqccjWGmg1SNK9mfsOSaFlptKrBXibMfvqKXfmSzWiAjbAfX/ycPTnEjohH8xl+9b5i8XQX17MjmblTlb/8Cn8K+/mxzHxAZS6QxR0q0Lb79AdjOr0RzmDCba1F+baJM7zHFrEpJhNoWk3sbhfXzrXKXizLf4kcGxdJdqIq+/EbdmM3BJQiUrGKO91iMVri9+MkzwKi8AwZ5kM6LyWLoFZn2O/S7zu4/gnILIfzrMUM3JdZViM6K8Jf+qSykTCw7B6t3gCr68y0WWtgVOu0+0OaImb1HAajMT3RneOIhHuywWY4gzeU5u1Zgo3LFL5Yjh2pyIlapmJ1iJoWFzclQvkKgXSB05RGKFfmUuA8W0KrtbGajc8Jt7MNPFeis0uVZYG18A1eqYQ3XeNQayFPKV+bzPslMWeJxbMMC8EMc8cJFgIpnvtT4nWL9DptxmKYroNcE1+iIDoyWL9S8CWLwtfZV2uc5BtiLn24G3I/HjGV6UW7bc3sWexOYDzmq7i2UmVWgwlWBd3XJ2FWzpOsCWzECxwoZRSzxnauwwelzopgshxSeXMhmETybKareLMWEaPxucD9Pa73cYN3kRzrEY130YKwNTalMtP4kd5GFytyZnYJ6C0OxLw/SgX2BYPDdAl/vslpsUO2Zn9JKDr0JVSx5ZKAjOc8yoeIJB4lI2grHKkFemId7u9sxsOOuDLAblXFL6oI22EyspkM20zunAfKP26/5JH7KY+Wnn7T3/37Bz9sLfDbxzWy+ThWfZ9MykPk6jWxiJvr8BJycgU97+W2skW1En6gnDQ0JFNDLhVmyIivlq4YMzvXqIoObYaDOgOnRrdbod0y6Npl+r2q0JVZfDjoPHRY1AsUNI0bRZ2hbJbQc3lKpvmt6lRGoxG6XqRSuZ1pRclSNL6c4UH+B+hr2LtZK02MAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png\"\n        srcset=\"/static/d0d7975fc223ded182582768b92bd9fc/12f09/residual_encoder_vc_decoder.png 148w,\n/static/d0d7975fc223ded182582768b92bd9fc/e4a3f/residual_encoder_vc_decoder.png 295w,\n/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png 590w,\n/static/d0d7975fc223ded182582768b92bd9fc/efc66/residual_encoder_vc_decoder.png 885w,\n/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png 978w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4 id=\"21-residual-encoder\" style=\"position:relative;\"><a href=\"#21-residual-encoder\" aria-label=\"21 residual encoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 residual encoder</h4>\n<p>speech 를 decoding 하는 과정에서 아무리 transcription + speech 에 정보가 잘 있어도 speech 자체 만에 대한 정보도 다양하고 중요하여서,\n해당 정보를 따로 encoding 해서 decoder 에서 사용한다고 합니다.</p>\n<p>residual encoder 의 특징은</p>\n<ul>\n<li>위에 한 번 언급된 speaker encoder 와 비슷한 구조</li>\n<li>temporal information 보존을 위해 time-wise 하게는 stride 적용 x</li>\n<li>특정 speaker feature 에 overfit 을 막기 위해 작은 channel size 를 사용.</li>\n<li>결론적으로 single channel output 이 위 문제를 막으면서 잘 동작했다고 캅니다.</li>\n<li>plus) Hann 으로 smoothing 함 (<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>=</mo><mn>21</mn></mrow><annotation encoding=\"application/x-tex\">k = 21</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">21</span></span></span></span></span>)</li>\n</ul>\n<h4 id=\"22-vc-decoder\" style=\"position:relative;\"><a href=\"#22-vc-decoder\" aria-label=\"22 vc decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2 VC decoder</h4>\n<p>위에 image 처럼, Cotatron feature 와 mel encoded feature 가 concat 돼서 들어가고 target speaker id 도 같이 들어갑니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>M</mi><mrow><mi>s</mi><mo>→</mo><mo>∗</mo></mrow></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>v</mi><mi>c</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mi>s</mi></msub><mo separator=\"true\">,</mo><msub><mi>R</mi><mi>s</mi></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msup><mi>y</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">M_{s \\to *} = Decoder_{vc} (concat(L_s, R_s), y^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1757em;\"><span style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∗</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0991em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">Deco</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal mtight\">c</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">co</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n</blockquote>\n<p>VC decoder 구조는 <em>GAN-TTS</em> 란 paper 와 유사합니다. head, tail 에 1d conv 가 1 layer 씩 있고, 중간에 GBlock w/ CondBN 4 blocks 있는 형태 입니다.\n물론 CondBN 에 Condition 으로 target speaker feature 가 들어갑니다.</p>\n<p>요 decoder 에 대한 모델적인 여러 시도를 했는데 결론적으로 성능 향상은 없었다고 하면서 future works 로 남기며 턴을 종료했습니다.</p>\n<h3 id=\"3-training-recipe\" style=\"position:relative;\"><a href=\"#3-training-recipe\" aria-label=\"3 training recipe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. training recipe</h3>\n<p>은 논문 참고해 주세요 (<del>귀찮</del>)</p>\n<h2 id=\"experiment-result\" style=\"position:relative;\"><a href=\"#experiment-result\" aria-label=\"experiment result permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiment Result</h2>\n<h3 id=\"vctk-benchmark-many-to-many\" style=\"position:relative;\"><a href=\"#vctk-benchmark-many-to-many\" aria-label=\"vctk benchmark many to many permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VCTK Benchmark (many-to-many)</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABk0lEQVR42jWSZ85qMRBD7/43w7cAJPhBB9FF7713EN3vHUtEiiaZTDy2k0D/R7/fV7FY1Gw2U6vVUqPR0Gg0Urvd9p58t9v1nE6nPhuPx+r1eq5Zr9fA6Pv9KrhcLmKeTicdj0ft93vtdjvH7Xbryf6X+63Jsz8cDt4T7/e7gmg0qnA4LCJM3++3zuezHo+HarWa/v7+tFgsdLvdnKtWqwqFQorH485BJJ1Oq1wu6/l8Kmg2m6aOFOZ8PnchDAaDgXOTycQqrter19QgGyter5fX2GHAQqGgfD6vTqejbDbrbgwuwQav8Al2ANIEULxljW/UQQzwAFkcYixM6QbDn+lcxoqfbzD5MSKSg1C9Xve9IJPJmAHdYUHy8/nY5NVqZSAieSQtl0ttNhsT4IyHQBnN8d8exmIxSy2VSqpUKr5IIb4BREQOOcB5NCaAgECGGogESEomkwaLRCL+Cgw8xQqkIwdWAKRSKedRRQ2NIEGNPYRhIpFQLpczy9/f43Nzhk8UIwm5gPAY+DocDl1LA/Kw/gdhGd92nz1T7wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png\"\n        srcset=\"/static/1ff9906a2a1bfb44626eff66a7423181/12f09/vctk_benchmark.png 148w,\n/static/1ff9906a2a1bfb44626eff66a7423181/e4a3f/vctk_benchmark.png 295w,\n/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png 590w,\n/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png 821w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>기존 SOTA 인 Blow 보다 훨 높은 MOS, DMOS 를 보여줍니다. SCA 는 Blow 를 넘진 못헀네요.</p>\n<h3 id=\"speaker-disentanglement\" style=\"position:relative;\"><a href=\"#speaker-disentanglement\" aria-label=\"speaker disentanglement permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Speaker Disentanglement</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.675675675675674%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA4UlEQVR42k2Q1wqEQAxF/f+/8kFfRSzYe+8dC3iXBHZZISSTyZzrjYC/z/d9GIaBrutg2zaiKEKWZVx7nse167pwHAeWZXGvrut/BIRt27AsC+Z5xjAMmKaJo2katG3LPcrfM2WCUFRVxeI00/c99n2HQCBRFKEoCiRJ4voLUlUVmqbx+b5vhjzPg6IouCYHx3HwfZ7neN8XAj2UZZmH6G9JkZQIYJomr+C6LpRlydbHceTQdR1hGOI8T14VrYDgAtkLgoBBBFzXlVdAQaokRD3KcRz/LCZJwiLkkO7SNOW5DxfNc/W3QucXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png\"\n        srcset=\"/static/81ba0c3552364e82dc7d254d975d1804/12f09/degree_of_speaker_disentanglement.png 148w,\n/static/81ba0c3552364e82dc7d254d975d1804/e4a3f/degree_of_speaker_disentanglement.png 295w,\n/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png 590w,\n/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png 830w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>그냥 Cotatron feature 만 쓸 때와 mel spectogram 만 따로 encoding 해서 쓴 경우와 비교했을 때,\nSCA 가 훨씬 높은 걸 보여주네요.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>간단한 concept 으로 꽤괜 성능이 나오고,\ntranscript 를 주지 않아도 성능이 준 것과 comparable 하다는 점도 재밌고,\nCortatron encoder 를 다른 task 에 적용해 봐도 재밌는 결과 볼 수 있을 것 같네용</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR 최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다. 간단하게 요약하면, 유명한 google 의 TTS model 인 tacotron2 기반…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li>\n<p><a href=\"#1-speaker-independent-linguistic-features-from-tts\">1. speaker-independent linguistic features from TTS</a></p>\n<ul>\n<li><a href=\"#speaker-disentanglement-issue-\">speaker disentanglement issue ?</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-voice-conversion\">2. voice conversion</a></p>\n<ul>\n<li><a href=\"#21-residual-encoder\">2.1 residual encoder</a></li>\n<li><a href=\"#22-vc-decoder\">2.2 VC decoder</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#3-training-recipe\">3. training recipe</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#experiment-result\">Experiment Result</a></p>\n<ul>\n<li><a href=\"#vctk-benchmark-many-to-many\">VCTK Benchmark (many-to-many)</a></li>\n<li><a href=\"#speaker-disentanglement\">Speaker Disentanglement</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/2020-05-10-Cotatron/"},"frontmatter":{"title":"Cotatron Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data","date":"May 10, 2020","tags":["Deep-Learning"],"keywords":["NLP","ChatBot","Blender"],"update":"May 10, 2020"},"timeToRead":3}},"pageContext":{"slug":"/2020-05-10-Cotatron/","series":[],"lastmod":"2020-05-10"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}