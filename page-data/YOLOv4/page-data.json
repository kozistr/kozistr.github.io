{"componentChunkName":"component---src-templates-post-tsx","path":"/YOLOv4/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>이번에 리뷰할 논문은 오랜만에 나온 YOLO 4번째 버전인 YOLOv4 논문입니다.</p>\n<p>이번 버전은 이야기가 있는(?) 버전인데, YOLO 원 저자인 Joe Redmon 님 께서 올해 2월쯤에 twit으로 CV 연구를 그만하겠다고 선언하셨는데 (<del>정말 YOLO 하러 가셨을까</del>),\n과연 이번 버전엔 저자에 포함될지, darknet page에는 YOLOv4 가 올라갈지 이야기가 있었는데, 이번 저자로는 빠지셨고 ㅠㅠ darknet 에는 올라갔더라고요.</p>\n<p>쨋든, 요약하면 현재 SOTA 인 EfficientDet 과 비슷한 AP를 달성하면서 높은 FPS를 달성했네요.</p>\n<p>paper : <a href=\"https://arxiv.org/pdf/2004.10934.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a>\ncode : <a href=\"https://github.com/pjreddie/darknet\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>YOLO 시리즈</p>\n<ul>\n<li>YOLO v1 : <a href=\"https://arxiv.org/pdf/1506.02640.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n<li>YOLO v2 : <a href=\"https://arxiv.org/pdf/1612.08242.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n<li>YOLO v3 : <a href=\"https://pjreddie.com/media/files/papers/YOLOv3.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n</ul>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>이번에도 논문에서는 speed를 추구한다고 강조를 하면서</p>\n<ol start=\"0\">\n<li>누구나 저렴한 GPU 장비로 학습 가능</li>\n<li>빠른 operation 사용</li>\n<li>parallel computing 최적화 등등</li>\n</ol>\n<p>여러 가지들을 고려했다고 합니다.</p>\n<p>총 2가지의 production serving 환경을 옵션을 들면서 설명하는데,</p>\n<h3 id=\"gpu\" style=\"position:relative;\"><a href=\"#gpu\" aria-label=\"gpu permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GPU</h3>\n<p>convolution layer 에서 작은 group 들 (1 ~ 8)을 사용했다고 카네요. CSPResNeXt50 / CSPDarknet53</p>\n<h3 id=\"vpu\" style=\"position:relative;\"><a href=\"#vpu\" aria-label=\"vpu permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VPU</h3>\n<p>grouped-convolution 을 사용하고, SE Module 를 사용하지 않는다고 하네요.</p>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p>크게 아키텍쳐를 설계하고 튜닝하는 것을 논문에선 3 부분으로 나눠서 설명합니다.</p>\n<ol>\n<li>아키텍쳐 선정</li>\n<li>BoF, BoS (여러가지 augmentation, activation, layer)</li>\n<li>기타 튜닝</li>\n</ol>\n<h3 id=\"selection-of-architecture\" style=\"position:relative;\"><a href=\"#selection-of-architecture\" aria-label=\"selection of architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Selection of Architecture</h3>\n<p>이 논문에선 optimal 한 architecture 를 설계하기 위해 총 3가지의 balance 를 고려하는데요,</p>\n<ol>\n<li>resolution of input image</li>\n<li>num of layers</li>\n<li>num of parameters</li>\n</ol>\n<p>Backbone으로 사용할 network가 ImageNet classification task에선 좋은 성능을 보일진 몰라도\nObject Detection task에선 고려해야 할 점이 또 다르기 때문에, 띵킹을 해야 한다라는 점을 언급해요.</p>\n<p>예로는 CSPResNeXt50 가 CSPDarknet53 보다 ImageNet 에선 성능이 좋아도, MS COCO dataset 에서 Object Detection 에선\n반대라고 합니다.</p>\n<p>결론적으로 CSPResNeXt50 vs CSPDarknet53 vs EfficientNet-B3 을 backbone 으로 benchmark 결과\nCSPDarknet53 이 detector backbone 으로 사용하기 optimal 하다는 결론을 내립니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0914c4e4386dda4ca2e26769170a651b/cf899/backbone-benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 17.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAIAAAABPYjBAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAvklEQVQI1x3NYW6EIBBAYe9/uG21P0wM0oVBIFp3kHHGFWzS2O8A7zXMLCLMnHO2FpxzWutpmowxAKC1Vko55xyAMSZnKqW8/4lIg4hEOyIqpRBxnucQAjOnlERkVLedOW/bdBdgWRYiijFaYxoHjllKKd57EXm9XjFGEQGA6/oFa42113URUQgBALZtq7Xu+/1rPh4PAEgp9X2/rus4jl33tf6sXdsdx6G1/n4+a61ENAzDZ9si4nmeOW/e+z/yrduQ9T2bhwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/0914c4e4386dda4ca2e26769170a651b/fcda8/backbone-benchmark.png\"\n        srcset=\"/static/0914c4e4386dda4ca2e26769170a651b/12f09/backbone-benchmark.png 148w,\n/static/0914c4e4386dda4ca2e26769170a651b/e4a3f/backbone-benchmark.png 295w,\n/static/0914c4e4386dda4ca2e26769170a651b/fcda8/backbone-benchmark.png 590w,\n/static/0914c4e4386dda4ca2e26769170a651b/efc66/backbone-benchmark.png 885w,\n/static/0914c4e4386dda4ca2e26769170a651b/c83ae/backbone-benchmark.png 1180w,\n/static/0914c4e4386dda4ca2e26769170a651b/cf899/backbone-benchmark.png 1513w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>또한 SSP Module 을 추가적으로 사용하고 (receptive field 때문에), PANet 을 feature aggregation 을 위해 사용한다고 합니다. (YOLOv3 에서 쓰던 FPN 대신 사용하는 거)</p>\n<p>최종적으로 아래와 같은 architecture 를 사용합니다.</p>\n<ul>\n<li><code class=\"language-text\">backbone</code> : CSPDarknet53 w/ SSP</li>\n<li><code class=\"language-text\">neck</code> : PANet (path-aggregation)</li>\n<li><code class=\"language-text\">head</code> : YOLOv3 (anchor-based)</li>\n</ul>\n<p>마지막으로 CGBN, SyncBN 같은 multi-gpu / TPU 환경같이 비싼 환경에서 사용하는 operation 들은 사용하지 않았다고 합니다.</p>\n<p>정말 누구나 훈련할 수 있다고 강조를 하네요 ㅋㅋㅋㅋ (<del>그런데 1080ti, 2080ti 1개 도 없는 게 현실</del>)</p>\n<h3 id=\"selection-of-bof-and-bos\" style=\"position:relative;\"><a href=\"#selection-of-bof-and-bos\" aria-label=\"selection of bof and bos permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Selection of BoF and BoS</h3>\n<p>여기선 모든 layer 들 loss, metric, augmentation 모든 기법을 나열하면서 괜춘한 걸 고르는 작업을 합니다.</p>\n<p>결론적으로 비싼 operation 들, 비싼 장비용 operation 들은 제외하고 누구나 써 볼 수 있는 operation 들을 고른 결과,</p>\n<p>regularization method 로 DropBlock 을 사용했답니다.</p>\n<h3 id=\"additional-improvements\" style=\"position:relative;\"><a href=\"#additional-improvements\" aria-label=\"additional improvements permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Additional improvements</h3>\n<p>여기선,</p>\n<ol>\n<li>새로운 augmentation 기법들과 SAT(Self-Adversarial Training)</li>\n<li>genetic algorithm 으로 hyper-parameter 튜닝</li>\n<li>효율적인 훈련을 위해 디자인 변경 -> SAM, PAN module 들 수정, BN -> CmBN (Cross mini)</li>\n</ol>\n<h4 id=\"1\" style=\"position:relative;\"><a href=\"#1\" aria-label=\"1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1</h4>\n<p>결론적으로 기존 CutMix 는 2장의 이미지끼리 blend 하는데, Mosaic 은 4장의 이미지를 섞기 때문에 더 좋아서 (둘 다) 쓴다.\n(large mini-batch 사용을 안 해도 된다 등등의 이유)</p>\n<p>SAT 는 구글에 찾아보세요~ (<del>귀찮</del>)</p>\n<h4 id=\"3\" style=\"position:relative;\"><a href=\"#3\" aria-label=\"3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3</h4>\n<p>SAM 에서 spatial-wise attention 을 point-wise attention 으로 변경\nPAN 에서 shortcut 을 concat 으로 변경</p>\n<p>이유는 나와 있지 않은데, SAM 같은 경우엔 그 작은 parameter 몇 개 줄여보겠다는 의도인 것 같고,\nPAN 에 concat 은 성능 측면인 것 같네요. (뇌피셜)</p>\n<h2 id=\"summary\" style=\"position:relative;\"><a href=\"#summary\" aria-label=\"summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Summary</h2>\n<p>정리 함 다시 해 보면</p>\n<h3 id=\"architecture-1\" style=\"position:relative;\"><a href=\"#architecture-1\" aria-label=\"architecture 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h3>\n<ul>\n<li><code class=\"language-text\">backbone</code> : CSPDarknet53 w/ SPP</li>\n<li><code class=\"language-text\">neck</code> : PAN</li>\n<li><code class=\"language-text\">head</code> : YOLOv3</li>\n</ul>\n<h3 id=\"uses\" style=\"position:relative;\"><a href=\"#uses\" aria-label=\"uses permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Uses</h3>\n<p>적용한 것들을 파트(?)별로 정리해 보면 아래와 같습니다.</p>\n<ul>\n<li>Bag of Freebies (BoF) for backbone\n<ul>\n<li>augmentation : CutMix, Mosaic</li>\n<li>regularization : DropBlock</li>\n<li>etc : class label smoothing</li>\n</ul>\n</li>\n<li>Bag of Specials (Bos) for backbone\n<ul>\n<li>activation : Mish</li>\n<li>network : CSP, MiWRC</li>\n</ul>\n</li>\n<li>Bag of Freebies (BoF) for detector\n<ul>\n<li>augmentation : Mosaic</li>\n<li>regularization : DropBlock</li>\n<li>loss : CIoU</li>\n<li>layer : CmBN</li>\n<li>lr scheduler : cosine annealing</li>\n<li>etc : SAT, eliminate grid sensitivity, multiple anchors for a single gt</li>\n</ul>\n</li>\n<li>Bag of Specials (Bos) for detector\n<ul>\n<li>activation : Mish</li>\n<li>module : SPP, SAM, PAN</li>\n<li>loss : DIoU-NMS</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"experiment-result\" style=\"position:relative;\"><a href=\"#experiment-result\" aria-label=\"experiment result permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiment Result</h2>\n<h3 id=\"bof-benchmark\" style=\"position:relative;\"><a href=\"#bof-benchmark\" aria-label=\"bof benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Bof Benchmark</h3>\n<p>위에 있는 모든 요소들을 benchmark 한 표.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/145aa96ca215b8e497c96cbafd8cbd11/cd138/bof-benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.75675675675676%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABWUlEQVQoz3WS2W7DIBBF/f8/SIwBEwMzQMH1pjgyOFR2qirdzgMPaM4Vd0QVQqCUKqUYY/wTdiEXKSWljRCirmshBOe8bVspJWNMKSUEjzFW8zyP4zCM4zRNw/A+jmPf9zHGaZr6vg8hzNPkDrz3PsYIADFGRHTOVznnfd9LKY/Ho/zieQkABsBa+xaClNL7t+v16r2vSin5IH2lvGrPU6muO3sZAM65ta5pGq119Tq973vO+XHyGqG00towdgitEM65tm0BoPrzqT9S0CKifWqMMe+9bFtArPZ9/69tzkdEKcU5Z50DY0II3vthGFTXHQtb1/W16p8LQwTrHCFEa23OCEKI0rratu1+v+ecUkrbtv0jo7W2oRQRm6axiBdCuq6rUkrruuact5PfckoJEeHUEO2FEGMMZ8wY8/wk43yyLMv6ndvttiwLAiBaSqkxpqFUa1XTulPqA0nAa9rKWNfhAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/145aa96ca215b8e497c96cbafd8cbd11/fcda8/bof-benchmark.png\"\n        srcset=\"/static/145aa96ca215b8e497c96cbafd8cbd11/12f09/bof-benchmark.png 148w,\n/static/145aa96ca215b8e497c96cbafd8cbd11/e4a3f/bof-benchmark.png 295w,\n/static/145aa96ca215b8e497c96cbafd8cbd11/fcda8/bof-benchmark.png 590w,\n/static/145aa96ca215b8e497c96cbafd8cbd11/efc66/bof-benchmark.png 885w,\n/static/145aa96ca215b8e497c96cbafd8cbd11/c83ae/bof-benchmark.png 1180w,\n/static/145aa96ca215b8e497c96cbafd8cbd11/cd138/bof-benchmark.png 1220w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"ap-fps-benchmark\" style=\"position:relative;\"><a href=\"#ap-fps-benchmark\" aria-label=\"ap fps benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>AP, FPS Benchmark</h3>\n<p>각 GPU architecture 별로 AP, FPS benchmark 를 했는데, 아래 V100 (volta arch)에서 테스트한 결과.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/38be4ae2954fb7aa9e2e62fd1d2a889f/6aacb/ap-fps-benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 30.405405405405407%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABCUlEQVQY0yWQW27CMBREs/9F9aMPIKEUVtCKFCVgSBzHsa/vy26B+R3N0ehUIlJKAaQfM3Tj2FnbTxMwl1JU87N1Ab7N0FnbWXueZ1ItpeScKxaJi+8dbJIccq4Ba5ZTLpQQEYmZkFqPDcuO5dWFj0i3nO/o+5gFortOQ+3D5zK9zeHFhZbI3q4hRiRKS+x9XDv3FX2N/B7TCWmepoRYQUpM6MJYx7CFuFfeav5lnAaTEkYATukcaRVxl+Cgsiu5T2k0RlQrIlJmj7QGbDTXRBvVltHeDBIhUWYyQCukRrQhrlV7xBSW+215BFlOAY7eG+aLyMyUVZ/ChBlEjn5pvb8yX5iXh85/YX+DCVU/5QJmYwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/38be4ae2954fb7aa9e2e62fd1d2a889f/fcda8/ap-fps-benchmark.png\"\n        srcset=\"/static/38be4ae2954fb7aa9e2e62fd1d2a889f/12f09/ap-fps-benchmark.png 148w,\n/static/38be4ae2954fb7aa9e2e62fd1d2a889f/e4a3f/ap-fps-benchmark.png 295w,\n/static/38be4ae2954fb7aa9e2e62fd1d2a889f/fcda8/ap-fps-benchmark.png 590w,\n/static/38be4ae2954fb7aa9e2e62fd1d2a889f/efc66/ap-fps-benchmark.png 885w,\n/static/38be4ae2954fb7aa9e2e62fd1d2a889f/c83ae/ap-fps-benchmark.png 1180w,\n/static/38be4ae2954fb7aa9e2e62fd1d2a889f/6aacb/ap-fps-benchmark.png 1347w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>빠르네요</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>이번 논문은 정말 모든 case 들을 하나하나 고려하려는 게 보였고, 설명도 최대한 low-level(?) 하게 하나하나 스킾하지 않고\n다 짚고 넘어가서 뭔가 투머치 같지만 좋았어요</p>\n<p>또 정말 모든 부분 하나하나 튜닝한 점이 꽤 인상적이었어요. 온갖 힙한 것들도 사용하고.</p>\n<p>결론 : 굳굳</p>","excerpt":"TL;DR 이번에 리뷰할 논문은 오랜만에 나온 YOLO 4번째 버전인 YOLOv4 논문입니다. 이번 버전은 이야기가 있는(?) 버전인데, YOLO 원 저자인 Joe Redmon 님 께서 올해 2월쯤에 twit으로 CV 연구를 그만하겠다고 선언하셨는데…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#introduction\">Introduction</a></p>\n<ul>\n<li><a href=\"#gpu\">GPU</a></li>\n<li><a href=\"#vpu\">VPU</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li>\n<p><a href=\"#selection-of-architecture\">Selection of Architecture</a></p>\n</li>\n<li>\n<p><a href=\"#selection-of-bof-and-bos\">Selection of BoF and BoS</a></p>\n</li>\n<li>\n<p><a href=\"#additional-improvements\">Additional improvements</a></p>\n<ul>\n<li><a href=\"#1\">1</a></li>\n<li><a href=\"#3\">3</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#summary\">Summary</a></p>\n<ul>\n<li><a href=\"#architecture-1\">Architecture</a></li>\n<li><a href=\"#uses\">Uses</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#experiment-result\">Experiment Result</a></p>\n<ul>\n<li><a href=\"#bof-benchmark\">Bof Benchmark</a></li>\n<li><a href=\"#ap-fps-benchmark\">AP, FPS Benchmark</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/YOLOv4/"},"frontmatter":{"title":"YOLOv4 Optimal Speed and Accuracy of Object Detection","date":"Apr 26, 2020","tags":["Deep-Learning"],"keywords":["YOLO","Object Detection"],"update":"Apr 26, 2020"},"timeToRead":4}},"pageContext":{"slug":"/YOLOv4/","series":[],"lastmod":"2020-04-26"}},"staticQueryHashes":["2027115977","2744905544","694178885"]}