{"componentChunkName":"component---src-templates-post-tsx","path":"/screening-mammography-breast-cancer-detection/","result":{"data":{"markdownRemark":{"html":"<ul>\n<li>Original Post : <a href=\"https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/391133\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/391133</a></li>\n</ul>\n<h2 id=\"data\" style=\"position:relative;\"><a href=\"#data\" aria-label=\"data permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Data</h2>\n<h3 id=\"preprocessing\" style=\"position:relative;\"><a href=\"#preprocessing\" aria-label=\"preprocessing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Preprocessing</h3>\n<p>My preprocessing code heavily depends on the public notebooks (eg. remove letters, crop breast via contour).</p>\n<ol>\n<li>decode <code class=\"language-text\">.dicom</code> to <code class=\"language-text\">.jpeg</code> with <code class=\"language-text\">dicomsdl</code> &#x26; <code class=\"language-text\">nvjpeg2000</code>.</li>\n<li>crop edge (margin pixel 10)</li>\n<li>extract breast with <code class=\"language-text\">opencv2</code> (contour based)</li>\n<li>resize to 1536x960. (I roughly guess that resizing into a 1.5 ~ 2.0 aspect ratio is fine.)</li>\n</ol>\n<p>In my experiment, windowing doesn't affect the score positively, so I decide not to use it.</p>\n<h3 id=\"augmentation\" style=\"position:relative;\"><a href=\"#augmentation\" aria-label=\"augmentation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Augmentation</h3>\n<p>Heavy augmentation works well. Light augmentation tends to overfit.</p>\n<ul>\n<li>v/hflip</li>\n<li>scale / rotate</li>\n<li>brightness / contrast</li>\n<li>cutout (coarse dropout with large patch size)</li>\n<li>mixup</li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p>I couldn't spend much time running various experiments due to a lack of time &#x26; computing resources. So, I only tested few backbones &#x26; training recipes. (about 70% of my submissions are runtime errors &#x26; mistakes lol)</p>\n<p>Here's a full pipeline.</p>\n<ol>\n<li>pre-train segmentation model with the <code class=\"language-text\">cbis-ddsm</code> &#x26; <code class=\"language-text\">vindr</code> datasets.\n<ul>\n<li>segment: provided RoI image.</li>\n<li>label: <code class=\"language-text\">malignant</code> to cancer / <code class=\"language-text\">BIRADS 5</code> to cancer.</li>\n</ul>\n% Of course, the label doesn't perfectly correlate with the competition standards. But, I roughly think that maybe it could help train the model in some ways.</li>\n<li>train with competition data (initialize the weight with the pre-trained model)\n<ul>\n<li>segment: inferred with the pre-trained model.</li>\n<li>auxiliary: given meta-features (total 11 features).</li>\n</ul>\n</li>\n<li>re-label the external data with the <code class=\"language-text\">step 2</code> model.</li>\n<li>re-train with competition data (initialize with <code class=\"language-text\">step 3</code> model)</li>\n<li>train a meta-classifier (oof + meta-features (e.g. laterality, age, ...))</li>\n</ol>\n<p>For a baseline, I run step 1 ~ 2, 5 and achieve CV 0.4885 LB 0.59 (PB 0.46). Also, I test only with the <code class=\"language-text\">cbis-ddsm</code> dataset for pre-training, and there were about 0.02 drops on CV &#x26; LB, but the same score on PB (CV 0.4656 LB 0.57 PB 0.46).</p>\n<p>A week before the deadline, I finished up to step ~ 5 and got CV 0.5012 LB 0.55 (PB 0.51). Sadly, I didn't choose it as a final submission : (</p>\n<p>Last day of the competition, I ensembled <code class=\"language-text\">effnet_v2_s</code> backbone and got CV 0.5063 LB 0.56 (PB 0.49).</p>\n<p>Lastly, I choose the best LB &#x26; CV for the final submission.</p>\n<h3 id=\"meta-classifier\" style=\"position:relative;\"><a href=\"#meta-classifier\" aria-label=\"meta classifier permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Meta-Classifier</h3>\n<p>I built a meta-classifier with meta-features like age, laterality, and the (per-breast) statistics of the predictions. Usually, It gives ~ 0.02 improvements on the CV &#x26; LB (also PB).</p>\n<p>I'm worried about overfitting into some meta-features (eg. machine id, (predicted) density, ...), so I decided to use only 3 auxiliary features (age, site_id, laterality) to train the model.</p>\n<ul>\n<li>feature: age, site_id, laterality, (mean, std, min, max) of the predictions.</li>\n<li>cv: stratified k fold (5 folds)</li>\n<li>model: CatBoost</li>\n</ul>\n<h2 id=\"works\" style=\"position:relative;\"><a href=\"#works\" aria-label=\"works permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Works</h2>\n<ul>\n<li>higher resolution (1536x768 ~ 1024) is good.</li>\n<li>external data\n<ul>\n<li>it gives about +0.02 boosts.</li>\n</ul>\n</li>\n<li>architecture\n<ul>\n<li>encoder: backbone: <code class=\"language-text\">effnet-b3</code> works best</li>\n<li>decoder: u-net++</li>\n</ul>\n</li>\n<li>augmentation</li>\n<li>mixup (alpha 1.0)</li>\n<li>loss\n<ul>\n<li>0.6 * cls_loss (cross_entropy) + 0.4 * seg_loss (dice) + 0.1 * aux_loss (cross-entropy)</li>\n</ul>\n</li>\n<li>stratified group k fold (4 folds)</li>\n<li>meta-classifier</li>\n<li>TTA</li>\n</ul>\n<p>thanks for reading! I hope this could help you :)</p>","excerpt":"Original Post : https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/391133 Data Preprocessing My preprocessing codeâ€¦","tableOfContents":"<ul>\n<li>\n<p><a href=\"#data\">Data</a></p>\n<ul>\n<li><a href=\"#preprocessing\">Preprocessing</a></li>\n<li><a href=\"#augmentation\">Augmentation</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li><a href=\"#meta-classifier\">Meta-Classifier</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#works\">Works</a></p>\n</li>\n</ul>","fields":{"slug":"/screening-mammography-breast-cancer-detection/"},"frontmatter":{"title":"(Kaggle) Screening Mammography Breast Cancer Detection - 16th (top 1%) place solution","date":"Feb 28, 2023","tags":["Deep-Learning","Kaggle"],"keywords":["radiological-society-of-north-america","rsna","mammography","cv","cnn"],"update":"Feb 28, 2023"},"timeToRead":2}},"pageContext":{"slug":"/screening-mammography-breast-cancer-detection/","series":[],"lastmod":"2023-02-28"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}