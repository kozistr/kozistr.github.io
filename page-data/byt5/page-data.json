{"componentChunkName":"component---src-templates-post-tsx","path":"/byt5/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<ul>\n<li>paper : <a href=\"https://arxiv.org/abs/2105.13626\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n<li>code : <a href=\"https://github.com/google-research/byt5\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></li>\n</ul>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2103.06874\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CANINE</a></li>\n<li><a href=\"https://arxiv.org/abs/2010.11934\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">mT5 paper</a></li>\n</ul>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>기존 LM 에서는 tokenizer 를 사용하고 있어 여러 측면에서 단점이 있는데, 이런 문제를 해결하기 위해 <code class=\"language-text\">token-free</code> LM 모델을 제안했습니다.</p>\n<p><code class=\"language-text\">token-free</code> model 은 말대로 tokenizer 를 활용하지 않고 byte or character-level (utf-8 encoded) raw text 를 input 으로 받는 형태인데, 여러 장점이 존재합니다.</p>\n<ol>\n<li>tokenize 하는 code or service 를 관리할 필요가 없다. (서비스 복잡도가 낮아지고 운영 부담 줄어든다.)</li>\n<li>OOV (Out-Of-Vocabular) case 가 없다.</li>\n</ol>\n<ul>\n<li>특히 <code class=\"language-text\">T5</code> 같이 multi-lingual LM 인 경우에 더 유리</li>\n</ul>\n<ol start=\"3\">\n<li>noisy-robust 하다.</li>\n</ol>\n<p>그래서 이번 논문의 contributions 은 크게 3가지 입니다.</p>\n<ol>\n<li><code class=\"language-text\">token-free</code> model 시도</li>\n<li>기존 <code class=\"language-text\">token-based</code> model 에서 최소한의 수정으로 가능하게끔 구현</li>\n<li>여러 metrics, measurements 에서 <code class=\"language-text\">token-based</code> 에 comparable (or outperform) 한 architecture design</li>\n</ol>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<h3 id=\"pretraining\" style=\"position:relative;\"><a href=\"#pretraining\" aria-label=\"pretraining permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pretraining</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c6f74c824429862342e8c556830ae1aa/b59fb/pretrain_stage.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.94594594594595%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABj0lEQVQozzWRyY7bMBBE/f9fkj/IZe6DSTCTSQInzmgxbcqm1BQpLuIic0toI4UG+lIP1YXelVLWdRVClFJCCIIBObVwOS6cCSG0VgihRQhjzMPJOC//tSul5LvqLoUPf96fPjUvnzerQoir1hTAGKOUklI65zZjgrXR++D9LqUEANMElFIxgSLXGSOCemfMKuXQtUPX4a497PenpoG2pc3HtWmG3wcxQU0WQiB07Pse9T0/n1nTCKA5xpiS956M40xntXA7z24c7TiKYdD34yscU1qNgWlSUgIAA0gx5pxDCI9St9tNiMVZK4VYGE8hlpQqbIxB6IgxJsPgrbXGSIQUueZUZa2tpcaJErJ5b6RUhGiM3TxX2HvPGJN8MasNIcSYrTbbFlKquLMOADjMztjagvMFIYaxt7bCOWdE2x/o9dfwnes5qJYPz2p88eul5MJXusfvP09vmB1zLjG4mezP/dsCHymGCnPNRnadltFu9ua4XrCRl5vXpRSm6bfuy9fDM6Ld46ExhvvEf8l/AWwH+b6q/ooZAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/c6f74c824429862342e8c556830ae1aa/fcda8/pretrain_stage.png\"\n        srcset=\"/static/c6f74c824429862342e8c556830ae1aa/12f09/pretrain_stage.png 148w,\n/static/c6f74c824429862342e8c556830ae1aa/e4a3f/pretrain_stage.png 295w,\n/static/c6f74c824429862342e8c556830ae1aa/fcda8/pretrain_stage.png 590w,\n/static/c6f74c824429862342e8c556830ae1aa/efc66/pretrain_stage.png 885w,\n/static/c6f74c824429862342e8c556830ae1aa/c83ae/pretrain_stage.png 1180w,\n/static/c6f74c824429862342e8c556830ae1aa/b59fb/pretrain_stage.png 1285w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>위 이미지가 <code class=\"language-text\">PLM</code> 만드는 방법인데, <code class=\"language-text\">mT5</code> architecture 를 base 로 합니다. <code class=\"language-text\">mT5</code> vs <code class=\"language-text\">ByT5</code> 를 비교하는데, 다음과 같은 차이가 있습니다.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">architecture / features</th>\n<th align=\"center\">text</th>\n<th align=\"center\">mask</th>\n<th align=\"center\">enc/dec</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">mT5</td>\n<td align=\"center\">SentencePiece</td>\n<td align=\"center\">~ 3 subword tokens</td>\n<td align=\"center\">equal depth (<code class=\"language-text\">enc</code> = <code class=\"language-text\">dec</code>)</td>\n</tr>\n<tr>\n<td align=\"center\">ByT5</td>\n<td align=\"center\">raw text (utf-8 encoded)</td>\n<td align=\"center\">~ 20 bytes</td>\n<td align=\"center\"><code class=\"language-text\">enc</code> is <strong>3x</strong> deeper than <code class=\"language-text\">dec</code></td>\n</tr>\n</tbody>\n</table>\n<p>recipe 에 주목할 만한 차이점이면, 기존 (mT5) 에는 ~ 3 tokens 를 mask 했다면 이번 연구에선 성능상 더 이점이 있어서 더 긴 길이를 (~ 20 bytes) mask 했습니다.</p>\n<p>또한, encoder 가 decoder 보다 3x 더 깊은데 이것도 실험 결과 byte-level models 에선 encoder 가 더 깊은 게 좋다고 합니다.</p>\n<h3 id=\"design-and-costs\" style=\"position:relative;\"><a href=\"#design-and-costs\" aria-label=\"design and costs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Design and costs</h3>\n<p>token 에서 byte-level character 로 바뀌면서 architecture design &#x26; recipe 에 차이가 생길겁니다. 크게 3가지가 변경점이 있을 텐데,</p>\n<ol>\n<li>softmax-layer (output matrices) at the <code class=\"language-text\">Decoder</code></li>\n<li>sequence-length (~ attention)</li>\n<li>data efficiency</li>\n</ol>\n<h4 id=\"softmax-layer-at-the-code-classlanguage-textdecodercode\" style=\"position:relative;\"><a href=\"#softmax-layer-at-the-code-classlanguage-textdecodercode\" aria-label=\"softmax layer at the code classlanguage textdecodercode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>softmax-layer at the <code class=\"language-text\">Decoder</code></h4>\n<p><code class=\"language-text\">mT5-base</code> 기준으로 decoder 에 output matrices 부분의 parameter 가 전체 모델의 parameter 대비 66% 를 차지합니다 (토큰 수가 많아서).\n그런데, <code class=\"language-text\">ByT5</code> 는 byte-level output 을 주기 때문에 parameter 가 훨 작은데, 논문에서는 <em>동일한 parameter 규모를 가정</em>하면 transformer layer 를 더 쌓거나 hidden size 를 더 크게 가져가는 등 complexity 측면에서 이득을 볼 수 있다고 합니다.</p>\n<h4 id=\"sequence-length\" style=\"position:relative;\"><a href=\"#sequence-length\" aria-label=\"sequence length permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>sequence length</h4>\n<p>byte-level 로 가면서 token 보다 sequence length 가 길어질텐데, time &#x26; space complexity 가 heavy 해 질 수 있다. 무언가 이걸 해결하기 위한 가볍고 빠른 attention 을 utilize 하지는 않은 듯 합니다.</p>\n<h4 id=\"data-efficiency\" style=\"position:relative;\"><a href=\"#data-efficiency\" aria-label=\"data efficiency permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>data efficiency</h4>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0c8294b6b80a5a67ccf151707462d2ad/52576/per_language_compression_rates.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 28.37837837837838%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABNElEQVQY042QPUvDUBiF7y9x0EWQ/gZ/gaOjOOmiFFwKBcHSqVhqLSqhIA5FW4of2CapjYuDUlLTNCma749iFycli83XvbmSiBQ3H87wvu9Z3nPAec9CMMQ4SoQwgjAMwjAIgxn+Xzzfdz1/OnXB0h6zXR9e9N86L++s/TH5/PJhhP8BghCkcsxClp7LUPNZenH3LpVjlosPK0ePq0Rv7ZRdP+tv1AabtcFWnU83hHRD2GmKmatRnpTbwgQcd/jq/ajKiERXIBjxpCtUSO6Q4iu0UCb5A4ovtbkyPSy1uMINW7hm92+fiy0uf8k2nxQQR43QLDPGEfQxhsn808JvI9DD0MURjJ+OEEYBsMZjTTdeJVmSFcu2FVXTdcMwLU035HgxTCs+mollmJaq6ZKsKKrmOM43y4kre31TBEMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/0c8294b6b80a5a67ccf151707462d2ad/fcda8/per_language_compression_rates.png\"\n        srcset=\"/static/0c8294b6b80a5a67ccf151707462d2ad/12f09/per_language_compression_rates.png 148w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/e4a3f/per_language_compression_rates.png 295w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/fcda8/per_language_compression_rates.png 590w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/efc66/per_language_compression_rates.png 885w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/c83ae/per_language_compression_rates.png 1180w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/52576/per_language_compression_rates.png 1412w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>(mC4 dataset 기준) 언어 토큰 별 평균 byte 길이를 보여주는 건데, 2.5 ~ 9 bytes 에 평균 4 bytes 라고 합니다. 즉, 다른 모델과 같은 세팅으로 훈련하게 된다면 (fixed sequence length, training steps) 4 배 짧은 문장을 학습하게 됩니다. (e.g. 512 tokens -> 128 tokens)</p>\n<h2 id=\"performance\" style=\"position:relative;\"><a href=\"#performance\" aria-label=\"performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Performance</h2>\n<h3 id=\"glue-benchmark\" style=\"position:relative;\"><a href=\"#glue-benchmark\" aria-label=\"glue benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GLUE benchmark</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b26293e17b6cb2de0721cec3955702b7/8c557/glue_performance.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 68.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACIUlEQVQoz22S23KjMBBE/f8fluwDsbEDSKC7BAJBsI1AiIuJt7xbu3Gq0o9Tc3q6ZmZ3/6dxHOu6bv7IGMMYU0q1bVuWZZ7nUgjGmdb6fD5/fn7+RXb3J/2vWmuFEEVRbNvmvU+ShFLKGO2H4bntC16WBWNcFIVzjjE2ukFKWTeNtbYsy2EYhJTPY7/BfhwRQozxvreMsa6z4WGvlKprQwi9Xq/HMKyMmabp58kAwsv1uiwzQtmyrof9vii0cwMXYl3X/Vvwcb78HPt2W7Ms/fhoh75/C4JpmqSQ7flSmyqK43l+OPZufN7RF7yuC0L4tm22615ffy3LWuS5tb0pdXg8reuNEOKn6Wd48h4AUFWmaeowDC+XKyGkaRolxfF0ats2AUld1865r9je+77v1/U2L3M/9M65ruuGYbDWTt5bawfnvJ9G7/00XS7XruumeXLOzfO8q8oyCIJC61wpjDEhBCQgiiJKaZY+FCdJmmVKScpYnCRCCMbYexTlebHTpYYAAAARQmWpOeecPT4iTSEAEALAOTePayFCGCGEUarL8v39xDnfVVUVx3GGkJSq1DpOAISw0JozBmEaRZGQSggBIaSUIoSyLJNSAgCUUg8Yo4xQWhQ5pfSRmxDGmDEGEwxBkiFkjBGCAwgxxpRSznmhNWNsp6Q8hGGWpgCAIAg458fj8eXlJYqihynBURSlaUowhhAmSRIeDoSQ+/2+bdtv8r/+26+0wZwAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/b26293e17b6cb2de0721cec3955702b7/fcda8/glue_performance.png\"\n        srcset=\"/static/b26293e17b6cb2de0721cec3955702b7/12f09/glue_performance.png 148w,\n/static/b26293e17b6cb2de0721cec3955702b7/e4a3f/glue_performance.png 295w,\n/static/b26293e17b6cb2de0721cec3955702b7/fcda8/glue_performance.png 590w,\n/static/b26293e17b6cb2de0721cec3955702b7/8c557/glue_performance.png 700w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>small, base 모델은 <code class=\"language-text\">ByT5</code> model 이 좋은데, 커 질수록 <code class=\"language-text\">mT5</code> 가 더 좋다. 그런데, 작은 모델에서 <code class=\"language-text\">mT5</code> 가 성능이 좋지 못한 이유가 decoder output layer 크기가 압도적으로 커서 다른 부분이 집중을 못 하는 issue 가 있다라고 해서, 사실상 그냥 comparable 하다라 보는 게 적절하다 생각함</p>\n<h3 id=\"generation-benchmark\" style=\"position:relative;\"><a href=\"#generation-benchmark\" aria-label=\"generation benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generation benchmark</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/07a106d47a9f8fd4e991b12ebd45f82b/0fcea/generation_performance.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB60lEQVQozzXSyXKcMAAEUP7/02xXPCA2idHCKkaAVsQ2EytlJ3nnrupDd3Qch3Nu3/e+78uyvFcVpdR7P44jxvh+x8ba7YcxJsszjMm+7+u6nucZhf+u68qzNE5irXUIoWmaJAGMseM4/gaUkgghkKbneYYQvr6+om3b+Mi936RS8zxLKTnn+74Pw+DcyjmXcgkhTPM0zVMI4TiOruuccyGESCmVpuk0TZwPYvrGGDPGMEqNMVVVjeOolCSE9H2vtW7btiiKO8bHsUdKSYjQ6/WaJ+FW76ytqur361Wz+no+UwA4H6VcMCE1Y1IphGASx+8fH8dxREZrhNB5ntMkjLVa67Isz/Oq6/q6riwFnHOtNee873trbd93EJYApN5vkZQLZSyEIKWc50UpGce36/mEEF7Xd3PTdsuydF03DINffZ5ncZK8vb3/NBsDIdy2beSjmCYhRFEU3ntKidaaEMzqWinVdf29qoQQeZ5nWXa73ZxzkTbGWmuM8d7P8+yc27ZtkYuUcv3PWuucM9au67rv+7Zt/3aGsCyKUmsjxANC9BhHIUSWgoHzpmkwxkVZdH0HAPj8/IUxLssiy7KiKB6PR4QQbJqma1sAAESIUpLnOSG0bVtCCGOMUooJads2iWMAAKOUEHr8/OQP7phXBihh/hMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/07a106d47a9f8fd4e991b12ebd45f82b/fcda8/generation_performance.png\"\n        srcset=\"/static/07a106d47a9f8fd4e991b12ebd45f82b/12f09/generation_performance.png 148w,\n/static/07a106d47a9f8fd4e991b12ebd45f82b/e4a3f/generation_performance.png 295w,\n/static/07a106d47a9f8fd4e991b12ebd45f82b/fcda8/generation_performance.png 590w,\n/static/07a106d47a9f8fd4e991b12ebd45f82b/0fcea/generation_performance.png 851w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>generation task 에선 잘한다.</p>\n<h3 id=\"inference-speed\" style=\"position:relative;\"><a href=\"#inference-speed\" aria-label=\"inference speed permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inference Speed</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4add87609bc4a359a4f4d011bd229a01/ad12c/inference_speed.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.54054054054055%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACIUlEQVQoz02S2ZKbMBRE/f+/NZnkKbMFYdAuo81gkAViMRiUMJ5U0k+3SjpXra4+xBjHcfTet20bQqjrGiEkhLDWKq2v3ocQrLWMUSGE1sYYq5QaxzHGeIj/aVkWa4xSWkpZFLJxzbpu27ZJKY011hohRNO4ZVke9w8PZpqmeZ6da4QQ67qez5Zz3vf9PM9933PO+mEIoWOMNc7Nn/qC+xDe3t6V0lVVAQDatsUIMcYIIQ+HZ2sa57quQxBqrRjnXRe+4Hm+JUkSQrgvC2MsxqiVIoQYo+u6jjFyxkLoQ+gQxlVVGmOm6fbPNoTQuev9fscYr+tWVSVlTEpVVZd1XQnBn4F6Qqi1eyjTNH3B4zgmSXK73R5vzvPSeg8R4pydz+UwDK8vL+56FZwnABRFwTkfhr9phxAghGVZeu+V1s65c3kWQkhZaK0vdU0wLsvygSklT6dT17Y77FxzqS7TNLWfGobBOfcYvPfjMLTeT9Ot3X3v1odxV9M0XdcdtFbv7x+YECllmqYgBSAFeZ4jhLIsE5xjiAilSZL8+vgAICWECMERQmVZHmRR5DlECFlrX19+Ukoopd+fn0ECKKUI46I4EUL22nFBCMmyLN8Fm6Y54P1YKikJIUUhH7/69vT0/P2HMSZNj1l2TNOUC0EpASCllGqtxWmv2sFoTSnFGEEICymtNYTQ4zHjXJxO4nPX3laY55QSCGHbdjHGbdv+BPYbX1jGJwNL0kcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/4add87609bc4a359a4f4d011bd229a01/fcda8/inference_speed.png\"\n        srcset=\"/static/4add87609bc4a359a4f4d011bd229a01/12f09/inference_speed.png 148w,\n/static/4add87609bc4a359a4f4d011bd229a01/e4a3f/inference_speed.png 295w,\n/static/4add87609bc4a359a4f4d011bd229a01/fcda8/inference_speed.png 590w,\n/static/4add87609bc4a359a4f4d011bd229a01/ad12c/inference_speed.png 856w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>train은 조금 느리고, inference는 더 많이 느리다.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>개인적으론 <code class=\"language-text\">token-free</code> model 접근은 재밌었지만 (<code class=\"language-text\">token-free</code> 개념 자체는 처음이 아니지만), utf-8 encoded bytes 를 input 으로 넣어주면서 다른 <code class=\"language-text\">token-based</code> model 대비 상대적으로 짧은 sequences 를 다루게 되면서 이 부분은 아쉬웠고, 일반적인 상황에서의 사용성을 생각하면 현재 연구 자체로는 너무 specific 하다고 생각한다. short-medium length 의 multi-lingual tranlsation 에만 적합한 느낌.</p>\n<p>저자 왈 단점 때문에 속도가 느려지는 게 toeknizer 운영 cost 생각하면 괜찮지 않나? 라는 입장도 어느 정도 reasonable 하다 생각한다.</p>\n<p>그래도 후속 연구에서 generation &#x26; translation tasks 에 한정이 아닌 general manner 하면서 performance 도 comparable 한 무언가가 나오지 않을까?</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR paper : arXiv code : github Related Work CANINE mT5 paper Introduction 기존 LM 에서는 tokenizer 를 사용하고 있어 여러 측면에서 단점이 있는데, 이런 문제를 해결하기 위해 …","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#introduction\">Introduction</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li>\n<p><a href=\"#pretraining\">Pretraining</a></p>\n</li>\n<li>\n<p><a href=\"#design-and-costs\">Design and costs</a></p>\n<ul>\n<li><a href=\"#softmax-layer-at-the-code-classlanguage-textdecodercode\">softmax-layer at the <code class=\"language-text\">Decoder</code></a></li>\n<li><a href=\"#sequence-length\">sequence length</a></li>\n<li><a href=\"#data-efficiency\">data efficiency</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#performance\">Performance</a></p>\n<ul>\n<li><a href=\"#glue-benchmark\">GLUE benchmark</a></li>\n<li><a href=\"#generation-benchmark\">Generation benchmark</a></li>\n<li><a href=\"#inference-speed\">Inference Speed</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/byt5/"},"frontmatter":{"title":"ByT5 - Towards a Token-Free Future with Pre-trained Byte-to-Byte Models","date":"Aug 09, 2022","tags":["Deep-Learning"],"keywords":["T5","token-free"],"update":"Aug 09, 2022"},"timeToRead":4}},"pageContext":{"slug":"/byt5/","series":[],"lastmod":"2022-08-09"}},"staticQueryHashes":["2027115977","2744905544","694178885"]}