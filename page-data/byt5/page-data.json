{"componentChunkName":"component---src-templates-post-tsx","path":"/byt5/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<ul>\n<li>paper : <a href=\"https://arxiv.org/abs/2105.13626\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n<li>code : <a href=\"https://github.com/google-research/byt5\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></li>\n</ul>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2103.06874\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CANINE</a></li>\n<li><a href=\"https://arxiv.org/abs/2010.11934\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">mT5 paper</a></li>\n</ul>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>기존 LM 에서는 tokenizer 를 사용하고 있어 여러 측면에서 단점이 있는데, 이런 문제를 해결하기 위해 <code class=\"language-text\">token-free</code> LM 모델을 제안했습니다.</p>\n<p><code class=\"language-text\">token-free</code> model 은 말대로 tokenizer 를 활용하지 않고 byte or character-level (utf-8 encoded) raw text 를 input 으로 받는 형태인데, 여러 장점이 존재합니다.</p>\n<ol>\n<li>tokenize 하는 code or service 를 관리할 필요가 없다. (서비스 복잡도가 낮아지고 운영 부담 줄어든다.)</li>\n<li>OOV (Out-Of-Vocabular) case 가 없다.</li>\n</ol>\n<ul>\n<li>특히 <code class=\"language-text\">T5</code> 같이 multi-lingual LM 인 경우에 더 유리</li>\n</ul>\n<ol start=\"3\">\n<li>noisy-robust 하다.</li>\n</ol>\n<p>그래서 이번 논문의 contributions 은 크게 3가지 입니다.</p>\n<ol>\n<li><code class=\"language-text\">token-free</code> model 시도</li>\n<li>기존 <code class=\"language-text\">token-based</code> model 에서 최소한의 수정으로 가능하게끔 구현</li>\n<li>여러 metrics, measurements 에서 <code class=\"language-text\">token-based</code> 에 comparable (or outperform) 한 architecture design</li>\n</ol>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<h3 id=\"pretraining\" style=\"position:relative;\"><a href=\"#pretraining\" aria-label=\"pretraining permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pretraining</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/c6f74c824429862342e8c556830ae1aa/b59fb/pretrain_stage.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.94594594594595%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABmElEQVR42jWPyY7UMBiE8/5Pwitw4IIQBzQgBOqeIZ1l0okTL7EdO3G8+0c9A3WoU32qqgoA9n1XSgGAc06sBKOBLuO6Ms65lKLve8651vo9KYSA/6oAIOecUgKAAiDG55+fPrRPH73dU8rWWkqpc85aa8zpnHPmzD7kEHKMVUrpvURwrtmq5gn3N9Td3Gm0lFPTzH0/te3z5fJa16RtWdPgpkEvL4rSCkpZ17Xruq7thq7d7qNsWkloCiHnbIyZppESLBk7KD3n+UCID8PG2L/ZMUatNcaLFIIQzClJMZVSUnp4jMl7r5Q6jVFCbFyUGMrbzcoYM473GSGMkLf22PX22u94yW+y9lz5SilZ8eK9P5RSBO8zcoI/4PM8KaHbKsxuQogxlVMfzsWcSynFHIZgwgk1h0kp2pXJ/lWMkz/tA84533l/vf+ql+t2yKg7uTwd9IczBApIw2t0/TNd8IYeB4Oh6PfQft/YLedYlVKIXAbcjWw47B4MVqw+ROPtBgBUL9/qL18vn3t2KwVKycFb720IDqD8Bf58+QVrFIw3AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/c6f74c824429862342e8c556830ae1aa/fcda8/pretrain_stage.png\"\n        srcset=\"/static/c6f74c824429862342e8c556830ae1aa/12f09/pretrain_stage.png 148w,\n/static/c6f74c824429862342e8c556830ae1aa/e4a3f/pretrain_stage.png 295w,\n/static/c6f74c824429862342e8c556830ae1aa/fcda8/pretrain_stage.png 590w,\n/static/c6f74c824429862342e8c556830ae1aa/efc66/pretrain_stage.png 885w,\n/static/c6f74c824429862342e8c556830ae1aa/c83ae/pretrain_stage.png 1180w,\n/static/c6f74c824429862342e8c556830ae1aa/b59fb/pretrain_stage.png 1285w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>위 이미지가 <code class=\"language-text\">PLM</code> 만드는 방법인데, <code class=\"language-text\">mT5</code> architecture 를 base 로 합니다. <code class=\"language-text\">mT5</code> vs <code class=\"language-text\">ByT5</code> 를 비교하는데, 다음과 같은 차이가 있습니다.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">architecture / features</th>\n<th align=\"center\">text</th>\n<th align=\"center\">mask</th>\n<th align=\"center\">enc/dec</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">mT5</td>\n<td align=\"center\">SentencePiece</td>\n<td align=\"center\">~ 3 subword tokens</td>\n<td align=\"center\">equal depth (<code class=\"language-text\">enc</code> = <code class=\"language-text\">dec</code>)</td>\n</tr>\n<tr>\n<td align=\"center\">ByT5</td>\n<td align=\"center\">raw text (utf-8 encoded)</td>\n<td align=\"center\">~ 20 bytes</td>\n<td align=\"center\"><code class=\"language-text\">enc</code> is <strong>3x</strong> deeper than <code class=\"language-text\">dec</code></td>\n</tr>\n</tbody>\n</table>\n<p>recipe 에 주목할 만한 차이점이면, 기존 (mT5) 에는 ~ 3 tokens 를 mask 했다면 이번 연구에선 성능상 더 이점이 있어서 더 긴 길이를 (~ 20 bytes) mask 했습니다.</p>\n<p>또한, encoder 가 decoder 보다 3x 더 깊은데 이것도 실험 결과 byte-level models 에선 encoder 가 더 깊은 게 좋다고 합니다.</p>\n<h3 id=\"design-and-costs\" style=\"position:relative;\"><a href=\"#design-and-costs\" aria-label=\"design and costs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Design and costs</h3>\n<p>token 에서 byte-level character 로 바뀌면서 architecture design &#x26; recipe 에 차이가 생길겁니다. 크게 3가지가 변경점이 있을 텐데,</p>\n<ol>\n<li>softmax-layer (output matrices) at the <code class=\"language-text\">Decoder</code></li>\n<li>sequence-length (~ attention)</li>\n<li>data efficiency</li>\n</ol>\n<h4 id=\"softmax-layer-at-the-code-classlanguage-textdecodercode\" style=\"position:relative;\"><a href=\"#softmax-layer-at-the-code-classlanguage-textdecodercode\" aria-label=\"softmax layer at the code classlanguage textdecodercode permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>softmax-layer at the <code class=\"language-text\">Decoder</code></h4>\n<p><code class=\"language-text\">mT5-base</code> 기준으로 decoder 에 output matrices 부분의 parameter 가 전체 모델의 parameter 대비 66% 를 차지합니다 (토큰 수가 많아서).\n그런데, <code class=\"language-text\">ByT5</code> 는 byte-level output 을 주기 때문에 parameter 가 훨 작은데, 논문에서는 <em>동일한 parameter 규모를 가정</em>하면 transformer layer 를 더 쌓거나 hidden size 를 더 크게 가져가는 등 complexity 측면에서 이득을 볼 수 있다고 합니다.</p>\n<h4 id=\"sequence-length\" style=\"position:relative;\"><a href=\"#sequence-length\" aria-label=\"sequence length permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>sequence length</h4>\n<p>byte-level 로 가면서 token 보다 sequence length 가 길어질텐데, time &#x26; space complexity 가 heavy 해 질 수 있다. 무언가 이걸 해결하기 위한 가볍고 빠른 attention 을 utilize 하지는 않은 듯 합니다.</p>\n<h4 id=\"data-efficiency\" style=\"position:relative;\"><a href=\"#data-efficiency\" aria-label=\"data efficiency permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>data efficiency</h4>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0c8294b6b80a5a67ccf151707462d2ad/52576/per_language_compression_rates.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 28.37837837837838%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABQElEQVR42oWKO0/CUABG+1OM0cFJR3+Bm5txYzEhDu4aYhxYHDXxEeSV8FAmTUwEEYoB4gOVYqVCQh+3t22cdJBBSu+zppHdkzN8OfmEZEMbI+z7Pp/AOKecUUYJpYSSQEJwIA78w0PIdcfCQrS6lmmn7+Gl/NHUvvTPnxGmjPvc/wdCiDAfvZmJlKa2itOR0uz29dxOeXG3trTXXD68W4k9rMYfQ6nnUPppLfMSzkrhnLSelzYKnc3zbqEFhVxdOW32z5r9fF3JN3rZei8lykmxm759T4rdhKicVORETYlX345K0kGxfVx+jVXk/avORWsgMEoYxZziyWCEIJcRxCcRU4wYQT6jxHOxN6LY4yx4MoIE23GACQeqqmo6tGzdACaEJrSAaWq6AYBp2Y5uAMt2NANAyzKAqeqGphvfw+EvtVYsOpGzzfAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/0c8294b6b80a5a67ccf151707462d2ad/fcda8/per_language_compression_rates.png\"\n        srcset=\"/static/0c8294b6b80a5a67ccf151707462d2ad/12f09/per_language_compression_rates.png 148w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/e4a3f/per_language_compression_rates.png 295w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/fcda8/per_language_compression_rates.png 590w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/efc66/per_language_compression_rates.png 885w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/c83ae/per_language_compression_rates.png 1180w,\n/static/0c8294b6b80a5a67ccf151707462d2ad/52576/per_language_compression_rates.png 1412w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>(mC4 dataset 기준) 언어 토큰 별 평균 byte 길이를 보여주는 건데, 2.5 ~ 9 bytes 에 평균 4 bytes 라고 합니다. 즉, 다른 모델과 같은 세팅으로 훈련하게 된다면 (fixed sequence length, training steps) 4 배 짧은 문장을 학습하게 됩니다. (e.g. 512 tokens -> 128 tokens)</p>\n<h2 id=\"performance\" style=\"position:relative;\"><a href=\"#performance\" aria-label=\"performance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Performance</h2>\n<h3 id=\"glue-benchmark\" style=\"position:relative;\"><a href=\"#glue-benchmark\" aria-label=\"glue benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>GLUE benchmark</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/b26293e17b6cb2de0721cec3955702b7/8c557/glue_performance.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 68.91891891891892%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACH0lEQVR42nWS6W7iQBCEef8X20gQlAV7bs/p8YHBM+MDX8GsSJRklc3Wj1arpa+7SurN/UPDMNR17Zxz3ldVJYRI0zSEUJalMalWSkpZlmXTNJ/I5rNb13We59fX13Vd69oZY6y1y7J0XQcAkFJywduuu/+lL3ieJ8qotVnXdVLJruuUUlVVhRCKomjbRintnLvdbt/g9X6/X689IURr3baNECI0zW67TdO0KArOhXduv9+fqmqaph8uT9MEIWyaZhxHSum8LPv9vijKrm2U1vM875+fnQ/vAf+1PROCnXMh+N1uN46TUtJ7n9s0AnCaJsbIdRj/k3maCCG3dXWu/vX0tCzLW4TOpvr34TjPM6V0GKef4WEYMEbl6VSdTnEMvPdCiPP5bLQCEF4uF4xxVZ37vv+Cu7a91PU4jsMwhBDatnXONU0TQrj2vfe+bdtr3/f9o1wuF+d8/zYfhmGT2XS73RpjpJT0IQJAfDxGjDEIAYQwimJCiJCSJUkcRVIIzvnhcEjTdGOtxQhBiJIkybJMSiUEF1ISjBDGCEKldVkWCWOcS/ao3NrseDwYbTZ5ngMAKKXG6MymcQwIxlmeKykxxlEcvZvCGCcJZ4xSQpTWCKOPyxhTxozWlNIkSQghlLI8zwh5RECY5HnOOQcAEEIYpUKIh0elNlmWIYSUlJzzOI6tzRDCLy8v7G2dMYYxJpUyRgshE84RhNZm76/yB6ph/3qUhmi/AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/b26293e17b6cb2de0721cec3955702b7/fcda8/glue_performance.png\"\n        srcset=\"/static/b26293e17b6cb2de0721cec3955702b7/12f09/glue_performance.png 148w,\n/static/b26293e17b6cb2de0721cec3955702b7/e4a3f/glue_performance.png 295w,\n/static/b26293e17b6cb2de0721cec3955702b7/fcda8/glue_performance.png 590w,\n/static/b26293e17b6cb2de0721cec3955702b7/8c557/glue_performance.png 700w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>small, base 모델은 <code class=\"language-text\">ByT5</code> model 이 좋은데, 커 질수록 <code class=\"language-text\">mT5</code> 가 더 좋다. 그런데, 작은 모델에서 <code class=\"language-text\">mT5</code> 가 성능이 좋지 못한 이유가 decoder output layer 크기가 압도적으로 커서 다른 부분이 집중을 못 하는 issue 가 있다라고 해서, 사실상 그냥 comparable 하다라 보는 게 적절하다 생각함</p>\n<h3 id=\"generation-benchmark\" style=\"position:relative;\"><a href=\"#generation-benchmark\" aria-label=\"generation benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generation benchmark</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/07a106d47a9f8fd4e991b12ebd45f82b/0fcea/generation_performance.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAIAAADwazoUAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAB3klEQVR42jWR626jMBBGef83y6ptioOKbxhIE9tA8G1sTNK0dNvsnn/zaTQafadYlsVaG2OUUhKMRdNwzp334zC0bcs5v1wuABBC8N4TQhhnAcA5l1Iqtv/c73dM8H6/n6bLtm1aq7IshRAxpcdCCIFRihB6JF9fX8X1eh3HMcYIAOMwzPMslVrXVWtlrR2GYZqmbductVrrz8/PnLOU0jm3bVsBAFVVKaWGQWs9WGuFEN77ruu8c20rzudzCKFtu/Pp5EMYhgFj3DTNz9sRAGOcczZmno1Zc65rfL/f+75f1ysl+OeK95Syvusul7lp+H6/3+12AFDEGCmlS16tNcbYZVkO1eF2+3h/f7/ebozSrj8+6lRSOuumcSSEVFXlvS9CCJzzbdu890rrGOH56el6+6CU5LwyShjj1rm+76WUAYBS+vr6utv98SEUKcW6ximlaZqUUsYYhFBKS9u2xpi+7yhjzrnT6cQZ01pjXJeofH55McYUD4HOuRijMcZ7H2O01s7zDAAPC+EfHgBSSo8w51xwzjHG5qeumTGmpDSzwbg+/9J1HSFYSlnXNUJIiJZxVmOMMZFSFg3njRBKycPhgAnpuu7t7Y1zfjwehRDtL48RobJEqPkFAP56/ga471ZceJovOgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/07a106d47a9f8fd4e991b12ebd45f82b/fcda8/generation_performance.png\"\n        srcset=\"/static/07a106d47a9f8fd4e991b12ebd45f82b/12f09/generation_performance.png 148w,\n/static/07a106d47a9f8fd4e991b12ebd45f82b/e4a3f/generation_performance.png 295w,\n/static/07a106d47a9f8fd4e991b12ebd45f82b/fcda8/generation_performance.png 590w,\n/static/07a106d47a9f8fd4e991b12ebd45f82b/0fcea/generation_performance.png 851w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>generation task 에선 잘한다.</p>\n<h3 id=\"inference-speed\" style=\"position:relative;\"><a href=\"#inference-speed\" aria-label=\"inference speed permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inference Speed</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4add87609bc4a359a4f4d011bd229a01/ad12c/inference_speed.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 65.54054054054055%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAA7DAAAOwwHHb6hkAAACKUlEQVR42k2SyY7jMAxE8/+/1Tn0XCbTnXiTLImytdiOrEReZCfeBu4EmKkTCeIVyAIP27Z57621t9vNOWeMSdOUAyilpJTWWuec1poxyjkXUmit8zzvum7btsP2n+Z5vlZVnguR50JKY8w0zdu2FlpLKYtCZ1lmrR3HcV3XNzzP8/P5nOfZOQcA8zyb65Ux1vf9NE3DMACwtuv7vmeM1bWdfvSGvffn8znPc2NMEAT3uyOEUMoopUII731VlcbUXdchhJRSANA0zRuepim4XJxzy7JQQtZtK7ROCdFaXc11XdeM8/vdDcOAML5WlVLKD8MbXpYFY2SMWdcFYzzPizFXQqmQsqyqZVkZpdbarm1TQsqikFL8gx+PRxAGw7j3WqnH49l3LcYYOBRlOY7jn9OptlYKcblchBDAwHv/hvu+D8NQKdU0jRCirm1ZloRSAHgFkSSJLgrOOcZplmWMsdvttsNt29Z1PY5j13XOOe+9c65tmnEY2qbx3u/1Pm3btu3advjR/X7vuu6glPr6+iKE5LmI4ySKojAM4zjGOI2jGIBjjCiDMAjO399BEFBKs4wjhHRRHLTSCKEkSYpCn06/MUKUsV+fn0EQUkLTlGRZRglJEAIAQmjyI4RwXdcHRinnmVaKEMKzDACUlMePj+PxqJWK4jhJ9nUAgAGEYbjvKHIGYIw5KCkppRglUZwA5y+XIAjTlHAOL0fO+X5IiqMosnaP6vWefwE+zMVILBNbMQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/4add87609bc4a359a4f4d011bd229a01/fcda8/inference_speed.png\"\n        srcset=\"/static/4add87609bc4a359a4f4d011bd229a01/12f09/inference_speed.png 148w,\n/static/4add87609bc4a359a4f4d011bd229a01/e4a3f/inference_speed.png 295w,\n/static/4add87609bc4a359a4f4d011bd229a01/fcda8/inference_speed.png 590w,\n/static/4add87609bc4a359a4f4d011bd229a01/ad12c/inference_speed.png 856w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>train은 조금 느리고, inference는 더 많이 느리다.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>개인적으론 <code class=\"language-text\">token-free</code> model 접근은 재밌었지만 (<code class=\"language-text\">token-free</code> 개념 자체는 처음이 아니지만), utf-8 encoded bytes 를 input 으로 넣어주면서 다른 <code class=\"language-text\">token-based</code> model 대비 상대적으로 짧은 sequences 를 다루게 되면서 이 부분은 아쉬웠고, 일반적인 상황에서의 사용성을 생각하면 현재 연구 자체로는 너무 specific 하다고 생각한다. short-medium length 의 multi-lingual tranlsation 에만 적합한 느낌.</p>\n<p>저자 왈 단점 때문에 속도가 느려지는 게 toeknizer 운영 cost 생각하면 괜찮지 않나? 라는 입장도 어느 정도 reasonable 하다 생각한다.</p>\n<p>그래도 후속 연구에서 generation &#x26; translation tasks 에 한정이 아닌 general manner 하면서 performance 도 comparable 한 무언가가 나오지 않을까?</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR paper : arXiv code : github Related Work CANINE mT5 paper Introduction 기존 LM 에서는 tokenizer 를 사용하고 있어 여러 측면에서 단점이 있는데, 이런 문제를 해결하기 위해 …","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#introduction\">Introduction</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li>\n<p><a href=\"#pretraining\">Pretraining</a></p>\n</li>\n<li>\n<p><a href=\"#design-and-costs\">Design and costs</a></p>\n<ul>\n<li><a href=\"#softmax-layer-at-the-code-classlanguage-textdecodercode\">softmax-layer at the <code class=\"language-text\">Decoder</code></a></li>\n<li><a href=\"#sequence-length\">sequence length</a></li>\n<li><a href=\"#data-efficiency\">data efficiency</a></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#performance\">Performance</a></p>\n<ul>\n<li><a href=\"#glue-benchmark\">GLUE benchmark</a></li>\n<li><a href=\"#generation-benchmark\">Generation benchmark</a></li>\n<li><a href=\"#inference-speed\">Inference Speed</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/byt5/"},"frontmatter":{"title":"ByT5 - Towards a Token-Free Future with Pre-trained Byte-to-Byte Models","date":"Aug 09, 2022","tags":["Deep-Learning"],"keywords":["T5","token-free"],"update":"Aug 09, 2022"},"timeToRead":2}},"pageContext":{"slug":"/byt5/","series":[],"lastmod":"2022-08-09"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}