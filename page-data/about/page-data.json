{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/about/",
    "result": {"data":{"markdownRemark":{"html":"<h2 id=\"profile\" style=\"position:relative;\"><a href=\"#profile\" aria-label=\"profile permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Profile</h2>\n<p>Alternative Military Service Status : <strong>on duty</strong> (<code class=\"language-text\">2020/11/27 ~ 2023/09/26</code>)</p>\n<p>CV : <a href=\"http://kozistr.tech/cv.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">[PDF] (as of Dec. 2021)</a></p>\n<h2 id=\"links\" style=\"position:relative;\"><a href=\"#links\" aria-label=\"links permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Links</h2>\n<table>\n<thead>\n<tr>\n<th align=\"left\"></th>\n<th align=\"left\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Email</td>\n<td align=\"left\"><strong>kozistr</strong>@gmail.com</td>\n</tr>\n<tr>\n<td align=\"left\">Github</td>\n<td align=\"left\"><a href=\"https://github.com/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/kozistr</a></td>\n</tr>\n<tr>\n<td align=\"left\">Kaggle</td>\n<td align=\"left\"><a href=\"https://www.kaggle.com/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.kaggle.com/kozistr</a></td>\n</tr>\n<tr>\n<td align=\"left\">Linkedin</td>\n<td align=\"left\"><a href=\"https://www.linkedin.com/in/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.linkedin.com/in/kozistr</a></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"interests\" style=\"position:relative;\"><a href=\"#interests\" aria-label=\"interests permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Interests</h2>\n<ul>\n<li>Lots of challenges like <strong>Kaggle</strong></li>\n<li>Audio/Speech Domains\n<ul>\n<li>End to End Speaker Diarization (E2ESD)</li>\n<li>Speaker Verifications</li>\n</ul>\n</li>\n</ul>\n<p>Previously, I'm also interested in <strong>offensive security</strong>, kind of <em>Reverse Engineering</em>, <em>Linux Kernel Exploitation</em>.</p>\n<hr>\n<h2 id=\"challenges--awards\" style=\"position:relative;\"><a href=\"#challenges--awards\" aria-label=\"challenges  awards permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Challenges &#x26; Awards</h2>\n<h3 id=\"machine-learning\" style=\"position:relative;\"><a href=\"#machine-learning\" aria-label=\"machine learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine Learning</h3>\n<ul>\n<li>\n<p><strong>Kaggle Challenges</strong> :: Kaggle Challenges :: <strong>Competition Expert</strong></p>\n<blockquote>\n<ul>\n<li><a href=\"https://www.kaggle.com/c/ventilator-pressure-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google Brain - Ventilator Pressure Prediction</a> - <strong>team, top 1% (20 / 2605), Private 0.1171</strong> (2021.)</li>\n<li><a href=\"https://www.kaggle.com/c/siim-covid19-detection\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SIIM-FISABIO-RSNA COVID-19 Detection</a> - <strong>solo, top 4% (47 / 1305), Private 0.612</strong> (2021.)</li>\n<li><a href=\"https://www.kaggle.com/c/shopee-product-matching\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Shopee - Price Match Guarantee</a> - <strong>solo, top 7% (166 / 2426), Private 0.725</strong> (2021.)</li>\n<li><a href=\"https://www.kaggle.com/c/birdsong-recognition\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Cornell Birdcall Identification</a> - <strong>team, top 2% (24 / 1395), Private 0.631</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/alaska2-image-steganalysis\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ALASKA2 Image Steganalysis</a> - <strong>solo, top 9% (93 / 1095), Private 0.917</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/tweet-sentiment-extraction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Tweet Sentiment Extraction</a> - <strong>solo, top 4% (84 / 2227), Private 0.71796</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/flower-classification-with-tpus\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Flower Classification with TPUs</a> - <strong>solo, top 4% (27 / 848), Private 0.98734</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/bengaliai-cv19\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kaggle Bengali.AI Handwritten Grapheme Classification</a> - <strong>solo, top 4% (67 / 2059), Private 0.9372</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/Kannada-MNIST\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kaggle Kannada MNIST Challenge</a> - <strong>solo, top 3% (28 / 1214), Private 0.99100</strong> (2019.)</li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>NAVER NLP Challenge</strong> :: NAVER NLP Challenge 2018</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/naver/nlp-challenge\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Semantic Role Labeling (SRL)</em> <strong>6th place</strong></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>A.I R&#x26;D Challenge</strong> :: A.I R&#x26;D Challenge 2018</p>\n<blockquote>\n<ul>\n<li><a href=\"http://airndchallenge.com/g5\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Fake or Real Detection</em> - as <em>Digital Forensic</em> Team</li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>NAVER A.I Hackathon</strong> :: NAVER A.I Hackathon 2018</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/naver/ai-hackathon-2018\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Kin</em> <strong>4th place</strong>, <em>Movie Review</em> <strong>13th place</strong> :: <a href=\"https://github.com/kozistr/naver-ai-hackathon-2018\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>summary_paper</em></a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>TF-KR Challenge</strong> :: Facebook TF-KR MNIST Challenge</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/kozistr/MNIST-Competition\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">TF-KR MNIST Challenge</a> - <strong>Top 9, 3rd price, ACC 0.9964</strong></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"hacking\" style=\"position:relative;\"><a href=\"#hacking\" aria-label=\"hacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hacking</h3>\n<ul>\n<li>\n<p><strong>Boot2Root CTF 2018</strong> :: <strong>2nd place</strong> (Demon + alpha)</p>\n</li>\n<li>\n<p><strong>Harekaze CTF 2017</strong> :: <strong>3rd place</strong> (SeoulWesterns)</p>\n</li>\n<li>\n<p><strong>WhiteHat League 1 (2017)</strong> :: <strong>2nd place</strong> (Demon)</p>\n<blockquote>\n<ul>\n<li>Awarded by 한국정보기술연구원 Received an award of <strong>$3,000</strong></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<hr>\n<h2 id=\"work-experience\" style=\"position:relative;\"><a href=\"#work-experience\" aria-label=\"work experience permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Work Experience</h2>\n<h3 id=\"company\" style=\"position:relative;\"><a href=\"#company\" aria-label=\"company permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Company</h3>\n<h4 id=\"data-scientist-toss-core-20211206--present\" style=\"position:relative;\"><a href=\"#data-scientist-toss-core-20211206--present\" aria-label=\"data scientist toss core 20211206  present permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Data Scientist</em>, <strong>Toss core</strong>, <strong>(2021.12.06 ~ present)</strong></h4>\n<ul>\n<li>Working as a full time.</li>\n</ul>\n<h4 id=\"machine-learning-researcher-watcha-20200622--20211203\" style=\"position:relative;\"><a href=\"#machine-learning-researcher-watcha-20200622--20211203\" aria-label=\"machine learning researcher watcha 20200622  20211203 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Researcher</em>, <strong>Watcha</strong>, <strong>(2020.06.22 ~ 2021.12.03)</strong></h4>\n<ul>\n<li>Working as a full time.</li>\n<li>Developed a new sequential recommendation architecture. (named <code class=\"language-text\">Trans4Rec</code>)\n<ul>\n<li>Newly proposed transformer architecture to improve the performance in a genernal manner.</li>\n<li>Apply proper post-processing logic into the model.</li>\n<li>In A/B (online) test, <code class=\"language-text\">FutureFLAT</code> vs <code class=\"language-text\">Trans4Rec</code> (statistically significant <code class=\"language-text\">p-value &lt; 0.01</code>)\n<ul>\n<li><strong>Click Ratio</strong> : improved <strong>1.01%</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Developed a music recommendation system (prototype)</li>\n<li>Developed a training recipe to train sequential recommendation architecture. (named <code class=\"language-text\">FutureFLAT</code>)\n<ul>\n<li>Build <em>Future</em> module to understand better at the time of inference.</li>\n<li>Apply augmentations to the various features, leads to performance gain &#x26; robustness.</li>\n<li><strong>In A/B (online)</strong> test, <code class=\"language-text\">FLAT</code> vs <code class=\"language-text\">FutureFLAT</code> (statistically significant <code class=\"language-text\">p-value &lt; 0.05</code>)\n<ul>\n<li>Compared to the previous model (<code class=\"language-text\">FLAT</code>), there’s no (statistically significant) improvments.</li>\n<li>However, it still seems to be better on <code class=\"language-text\">the offline metrics</code> &#x26; <code class=\"language-text\">training stability</code>. So, we chose to use it.</li>\n</ul>\n</li>\n<li><strong>In A/B (online)</strong> test, <a href=\"https://arxiv.org/abs/2009.09588\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><code class=\"language-text\">Div2Vec</code></a> vs <code class=\"language-text\">FutureFLAT</code> (statistically significant <code class=\"language-text\">p-value &lt; 0.05</code>)\n<ul>\n<li><strong>*Viewing Days (mean)</strong> : improved <strong>1.012%</strong></li>\n<li><strong>*Viewing Minutes (median)</strong> : improved <strong>1.015%</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Developed a model to predict expected users' view-time of the contents.\n<ul>\n<li>Predict how many people going to watch, how much time people going to watch the content before the content is supplied.</li>\n<li>Find out which features impact users' watch.</li>\n</ul>\n</li>\n<li>Developed a pipeline to recognize main actors from the poster and still-cut images.\n<ul>\n<li>Utilize <strong>SOTA</strong> face detector &#x26; recognizer.</li>\n<li>Optimize pre/post processing routines for low <code class=\"language-text\">latency</code>.</li>\n</ul>\n</li>\n<li>Developed a novel sequential recommendation architecture to recommend what content to watch next. (named <code class=\"language-text\">FLAT</code>)\n<ul>\n<li><strong>In A/B (online)</strong> test, <code class=\"language-text\">previous algorithms</code> vs <code class=\"language-text\">FLAT</code> (statistically significant <code class=\"language-text\">p-value &lt; 0.05</code>)\n<ul>\n<li><strong>Paid Conversion</strong> : improved <strong>1.39%</strong></li>\n<li><strong>*Viewing Days (mean)</strong> : improved <strong>0.25%</strong></li>\n<li><strong>*Viewing Minutes (median)</strong> : improved <strong>4.10%</strong></li>\n<li><strong>Click Ratio</strong> : improved <strong>4.30%</strong></li>\n<li><strong>Play Ratio</strong> : improved <strong>2.32%</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Developed Image Super Resolution model to upscale movie &#x26; tv poster, still-cut images.\n<ul>\n<li>Optimize the codes for fast <code class=\"language-text\">inference time</code> &#x26; <code class=\"language-text\">memory-efficiency</code> on <em>cpu</em>.</li>\n<li>In internal evaluation (qualitative evaluation by the designers), it catches details better &#x26; handles higher resolution &#x26; takes a little time.</li>\n</ul>\n</li>\n</ul>\n<p>% <code class=\"language-text\">*Viewing Days</code> : how many days users active on an app each month.</p>\n<p>% <code class=\"language-text\">*Viewing Minutes</code> : how many minutes user watched the contents.</p>\n<h4 id=\"machine-learning-engineer-rainist-20191111--20200619\" style=\"position:relative;\"><a href=\"#machine-learning-engineer-rainist-20191111--20200619\" aria-label=\"machine learning engineer rainist 20191111  20200619 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Engineer</em>, <strong>Rainist</strong>, <strong>(2019.11.11 ~ 2020.06.19)</strong></h4>\n<ul>\n<li>Worked as a full time.</li>\n<li>Developed the card &#x26; bank account transaction category classification models, designed <em>light-weight purpose</em> for the low latency. (now on service)\n<ul>\n<li><strong>In A/B (online)</strong> test (statistically significant <code class=\"language-text\">p-value &lt; 0.05</code>)\n<ul>\n<li><strong>*Accuracy</strong> : improved <strong>about 25 ~ 30%p</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Developed the RESTful API server to serve (general purpose) machine learning models.\n<ul>\n<li>Deployed &#x26; managed with K8s, utilized open source project.</li>\n<li>Utilized inference-aware framework to reduce the latency.</li>\n<li>zero failure rate (<strong>0</strong> 40x, 50x errors)</li>\n</ul>\n</li>\n<li>Developed the classification model for forecasting possibility of loan overdue.</li>\n</ul>\n<p>% <code class=\"language-text\">*Accuracy</code> : how many people don't update/change their transactions' category.</p>\n<h4 id=\"machine-learning-engineer-voyagerx-20190107--20191004\" style=\"position:relative;\"><a href=\"#machine-learning-engineer-voyagerx-20190107--20191004\" aria-label=\"machine learning engineer voyagerx 20190107  20191004 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Engineer</em>, <strong>VoyagerX</strong>, <strong>(2019.01.07 ~ 2019.10.04)</strong></h4>\n<ul>\n<li>Worked as an intern.</li>\n<li>Developed speaker verification, diarization models &#x26; logic for recognizing the arbitrary speakers recorded from the noisy (real-world) environment.</li>\n<li>Developed a hair image semantic segmentation / image in-paint / i2i domain transfer model for swapping hair domain naturally.</li>\n</ul>\n<h4 id=\"penetration-tester-elcid-201607--201608\" style=\"position:relative;\"><a href=\"#penetration-tester-elcid-201607--201608\" aria-label=\"penetration tester elcid 201607  201608 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Penetration Tester</em>, <strong>ELCID</strong>, <strong>(2016.07 ~ 2016.08)</strong></h4>\n<ul>\n<li>Worked as a part-time job.</li>\n<li>Penetrated some products related to network firewall and anti-virus product.</li>\n</ul>\n<h3 id=\"out-sourcing\" style=\"position:relative;\"><a href=\"#out-sourcing\" aria-label=\"out sourcing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Out Sourcing</h3>\n<ul>\n<li>Developed Korean University Course Information Web Parser (About 40 Universities). <strong>2 times, (2017.7 ~ 2018.3)</strong></li>\n<li>Developed AWS CloudTrail logger analyzer / formatter. <strong>(2019.09 ~ 2019.10)</strong></li>\n</ul>\n<h3 id=\"lab\" style=\"position:relative;\"><a href=\"#lab\" aria-label=\"lab permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lab</h3>\n<p><a href=\"https://sites.google.com/view/hpclab/home\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HPC Lab</a>, KoreaTech, <strong>Undergraduate Researcher</strong>, <strong>(2018.09 ~ 2018.12)</strong></p>\n<ul>\n<li>Wrote a paper about improved TextCNN model to predict a movie rate.</li>\n</ul>\n<hr>\n<h2 id=\"publications\" style=\"position:relative;\"><a href=\"#publications\" aria-label=\"publications permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Publications</h2>\n<h3 id=\"paper\" style=\"position:relative;\"><a href=\"#paper\" aria-label=\"paper permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Paper</h3>\n<p>[1] <strong>Kim</strong> et al, <a href=\"http://ktccs.kips.or.kr/digital-library/23245\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CNN Architecture Predicting Movie Rating</a>, 2020. 01.</p>\n<ul>\n<li>Wrote about the CNN Architecture, which utilizes a channel-attention method (SE Module) to TextCNN model, brings performance gain over the task while keeping its latency, generally.</li>\n<li>Handling un-normalized text with various convolution kernel size and spatial dropout</li>\n<li>Selected as one of the <code class=\"language-text\">highlight papers</code> for the first half of 2020</li>\n</ul>\n<h3 id=\"conferencesworkshops\" style=\"position:relative;\"><a href=\"#conferencesworkshops\" aria-label=\"conferencesworkshops permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conferences/Workshops</h3>\n<p>[1] <code class=\"language-text\">kozistr_team</code>, <a href=\"https://bit.ly/3eneg2y\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">presentation</a> <em>NAVER NLP Challenge 2018 SRL Task</em></a></p>\n<ul>\n<li>SRL Task, challenging w/o any domain knowledge. Presented about trials &#x26; errors during the competition</li>\n</ul>\n<h3 id=\"journals\" style=\"position:relative;\"><a href=\"#journals\" aria-label=\"journals permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Journals</h3>\n<p>[1] zer0day, <a href=\"http://zer0day.tistory.com/335?category=505873\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>Windows Anti-Debugging Techniques</em></a> (CodeEngn 2016) Sep. 2016. <a href=\"/refs/Anti%20Revering%20Techniques%20%5Bzer0day%5D.pdf\">PDF</a></p>\n<ul>\n<li>Wrote about lots of anti-reversing / debugging (A to Z) techniques avail on window executable binary</li>\n</ul>\n<h3 id=\"posts\" style=\"position:relative;\"><a href=\"#posts\" aria-label=\"posts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Posts</h3>\n<p>[1] kozistr (as a part of team, <code class=\"language-text\">Dragonsong</code>) <a href=\"https://towardsdatascience.com/detecting-sounds-with-deep-learning-ed9a41909da0\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">towarddatascience</a></p>\n<ul>\n<li>Wrote about audio classifier with deep learning based on the kaggle challenge where we participated</li>\n</ul>\n<hr>\n<h2 id=\"educations\" style=\"position:relative;\"><a href=\"#educations\" aria-label=\"educations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Educations</h2>\n<p><strong>Senior</strong> in Computer Engineering from <a href=\"https://www.koreatech.ac.kr/eng.do\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">KUT</a></p>\n<hr>\n<h2 id=\"personal-projects\" style=\"position:relative;\"><a href=\"#personal-projects\" aria-label=\"personal projects permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Personal Projects</h2>\n<h3 id=\"computer-languages\" style=\"position:relative;\"><a href=\"#computer-languages\" aria-label=\"computer languages permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Computer Languages</h3>\n<blockquote>\n<p><strong>Python</strong></p>\n<p>C/C++</p>\n<p>Assembly (x86, x86-64, arm, ...)</p>\n<p><em>experienced with lots of languages</em></p>\n</blockquote>\n<h3 id=\"machinedeep-learning\" style=\"position:relative;\"><a href=\"#machinedeep-learning\" aria-label=\"machinedeep learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine/Deep Learning</h3>\n<h4 id=\"generative-models\" style=\"position:relative;\"><a href=\"#generative-models\" aria-label=\"generative models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generative Models</h4>\n<ul>\n<li>\n<p><strong>GANs-tensorflow</strong> :: Lots of GAN codes :) :: <a href=\"https://github.com/kozistr/Awesome-GANs\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Generative Adversary Networks</a></p>\n<blockquote>\n<ul>\n<li><strong>ACGAN-tensorflow</strong> :: Auxiliary Classifier GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/ACGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>StarGAN-tensorflow</strong> :: Unified GAN for multi-domain :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/StarGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>LAPGAN-tensorflow</strong> :: Laplacian Pyramid GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/LAPGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>BEGAN-tensorflow</strong> :: Boundary Equilibrium in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/BEGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>DCGAN-tensorflow</strong> :: Deep Convolutional GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/DCGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>SRGAN-tensorflow</strong> :: Super Resolution GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/SRGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>WGAN-GP-tensorflow</strong> :: Wasserstein GAN w/ gradient penalty in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/WGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li>... lots of GANs (over 20) :)</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"super-resolution\" style=\"position:relative;\"><a href=\"#super-resolution\" aria-label=\"super resolution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Super Resolution</h4>\n<ul>\n<li>\n<p><strong>Single Image Super Resolution</strong> :: Single Image Super Resolution (SISR)</p>\n<blockquote>\n<ul>\n<li><strong>rcan-tensorflow</strong> :: RCAN implementation in tensorflow :: <a href=\"https://github.com/kozistr/rcan-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>ESRGAN-tensorflow</strong> :: ESRGAN implementation in tensorflow :: <a href=\"https://github.com/kozistr/ESRGAN-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>NatSR-pytorch</strong> :: NatSR implementation in pytorch :: <a href=\"https://github.com/kozistr/NatSR-pytorch\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"i2i-translation\" style=\"position:relative;\"><a href=\"#i2i-translation\" aria-label=\"i2i translation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>I2I Translation</h4>\n<ul>\n<li><strong>Improved Content Disentanglement</strong> :: tuned version of 'Content Disentanglement' in pytorch :: <a href=\"https://github.com/kozistr/improved-ContentDisentanglement\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n<h4 id=\"style-transfer\" style=\"position:relative;\"><a href=\"#style-transfer\" aria-label=\"style transfer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Style Transfer</h4>\n<ul>\n<li>\n<p><strong>Image-Style-Transfer</strong> :: Image Neural Style Transfer</p>\n<blockquote>\n<ul>\n<li><strong>style-transfer-tensorflow</strong> :: Image Style-Transfer in tensorflow :: <a href=\"https://github.com/kozistr/style-transfer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"text-classificationgeneration\" style=\"position:relative;\"><a href=\"#text-classificationgeneration\" aria-label=\"text classificationgeneration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Text Classification/Generation</h4>\n<blockquote>\n<ul>\n<li><strong>movie-rate-prediction</strong> :: Korean sentences classification in tensorflow :: <a href=\"https://github.com/kozistr/naver-movie-rate-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>KoSpacing-tensorflow</strong> :: Automatic Korean sentences spacing in tensorflow :: <a href=\"https://github.com/kozistr/KoSpacing-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><del>code</del></a></li>\n<li><strong>text-tagging</strong> :: Automatic Korean articles categories classification in tensorflow :: <a href=\"https://github.com/sales-tagging/text-tagging-ml\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n<h4 id=\"speech-synthesis\" style=\"position:relative;\"><a href=\"#speech-synthesis\" aria-label=\"speech synthesis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Speech Synthesis</h4>\n<ul>\n<li>\n<p><strong>Tacotron-tensorflow</strong> :: Text To Sound (TTS)</p>\n<blockquote>\n<ul>\n<li><strong>tacotron-tensorflow</strong> :: lots of TTS models in tensorflow :: <a href=\"https://github.com/kozistr/tacotron-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><del>code</del></a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"optimizer\" style=\"position:relative;\"><a href=\"#optimizer\" aria-label=\"optimizer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Optimizer</h4>\n<ul>\n<li>\n<p><strong>pytorch-optimizer</strong> :: Bunch of optimizer implementations in PyTorch</p>\n<blockquote>\n<ul>\n<li><strong>pytorch_optimizer</strong> :: Bunch of optimizer implementations in PyTorch with clean-code, strict types. Also, including useful optimization ideas. Most of the implementations are based on the original paper, but I added some tweaks. :: <a href=\"https://github.com/kozistr/pytorch_optimizer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>AdaBound</strong> :: Optimizer that trains as fast as Adam and as good as SGD</p>\n<blockquote>\n<ul>\n<li><strong>AdaBound-tensorflow</strong> :: AdaBound Optimizer implementation in tensorflow :: <a href=\"https://github.com/kozistr/AdaBound-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>RAdam</strong> :: On The Variance Of The Adaptive Learning Rate And Beyond in tensorflow</p>\n<blockquote>\n<ul>\n<li><strong>RAdam-tensorflow</strong> :: RAdam Optimizer implementation in tensorflow :: <a href=\"https://github.com/kozistr/RAdam-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"rl\" style=\"position:relative;\"><a href=\"#rl\" aria-label=\"rl permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>R.L</h4>\n<ul>\n<li><strong>Rosseta Stone</strong> :: Hearthstone simulator using C++ with some reinforcement learning :: <a href=\"https://github.com/utilForever/RosettaStone\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n<h3 id=\"plug-ins\" style=\"position:relative;\"><a href=\"#plug-ins\" aria-label=\"plug ins permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Plug-Ins</h3>\n<p>IDA pro plug-in - Golang ELF binary (x86, x86-64), RTTI parser</p>\n<ul>\n<li>Recover stripped symbols &#x26; information and patch byte-codes for being able to hex-ray</li>\n</ul>\n<h3 id=\"open-source-contributions\" style=\"position:relative;\"><a href=\"#open-source-contributions\" aria-label=\"open source contributions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Open Source Contributions</h3>\n<ul>\n<li><a href=\"https://github.com/google/syzkaller\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">syzkaller</a> :: New Generation of Linux Kernel Fuzzer :: <a href=\"https://github.com/google/syzkaller/pull/575\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#575</a></li>\n<li><a href=\"https://github.com/https://github.com/ThilinaRajapakse/simpletransformers\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">simpletransformers</a> :: Transformers made simple w/ training, evaluating, and prediction possible w/ one line each. :: <a href=\"https://github.com/ThilinaRajapakse/simpletransformers/pull/290\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#290</a></li>\n<li><a href=\"https://github.com/rwightman/pytorch-image-models\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">pytorch-image-models</a> :: PyTorch image models, scripts, pretrained weights :: <a href=\"https://github.com/rwightman/pytorch-image-models/pull/1069\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#1069</a></li>\n<li><a href=\"https://github.com/rwightman/pytorch-image-models\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">pytorch-image-models</a> :: PyTorch image models, scripts, pretrained weights :: <a href=\"https://github.com/rwightman/pytorch-image-models/pull/1058\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#1058</a></li>\n<li><a href=\"https://github.com/facebookresearch/deit\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">deit</a> :: DeiT: Data-efficient Image Transformers :: <a href=\"https://github.com/facebookresearch/deit/pull/140\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#140</a></li>\n</ul>\n<h3 id=\"security-hacking\" style=\"position:relative;\"><a href=\"#security-hacking\" aria-label=\"security hacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Security, Hacking</h3>\n<h4 id=\"ctfs-conferences\" style=\"position:relative;\"><a href=\"#ctfs-conferences\" aria-label=\"ctfs conferences permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CTFs, Conferences</h4>\n<ul>\n<li><a href=\"http://powerofcommunity.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">POC</a> 2016 Conference Staff</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 15 CTF Staff, Challenge Maker</li>\n<li><a href=\"https://www.codegate.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CodeGate</a> 2017 OpenCTF Staff, Challenge Maker</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 16 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://www.powerofxx.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">POX</a> 2017 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://www.powerofxx.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">KID</a> 2017 CTF Staff, Challenge Maker</li>\n<li>Belluminar 2017 CTF Staff</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 17 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 18 CTF Staff, Challenge Maker</li>\n</ul>\n<h4 id=\"teams\" style=\"position:relative;\"><a href=\"#teams\" aria-label=\"teams permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Teams</h4>\n<p>Hacking Team, <a href=\"http://f1ay.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>Fl4y</strong></a>. <strong>Since 2017.07 ~</strong></p>\n<p>Hacking Team, <a href=\"https://demonteam.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>Demon</strong></a> by <a href=\"http://powerofcommunity.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>POC</em></a>. <strong>Since 2014.02 ~ 2018.08</strong></p>\n<hr>\n<h3 id=\"presentations\" style=\"position:relative;\"><a href=\"#presentations\" aria-label=\"presentations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Presentations</h3>\n<h4 id=\"2018\" style=\"position:relative;\"><a href=\"#2018\" aria-label=\"2018 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2018</h4>\n<p>[2] Artificial Intelligence ZeroToAll, Apr 2018.</p>\n<p>[1] Machine Learning ZeroToAll, Mar 2018.</p>\n<h4 id=\"2015\" style=\"position:relative;\"><a href=\"#2015\" aria-label=\"2015 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2015</h4>\n<p>[1] Polymorphic Virus VS AV Detection, Oct 2015.</p>\n<h4 id=\"2014\" style=\"position:relative;\"><a href=\"#2014\" aria-label=\"2014 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2014</h4>\n<p>[1] Network Sniffing &#x26; Detection, Oct, 2014.</p>","excerpt":"Profile Alternative Military Service Status : on duty () CV : [PDF] (as of Dec. 2021) Links   Email kozistr@gmail.com Github https://github…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#profile\">Profile</a></p>\n</li>\n<li>\n<p><a href=\"#links\">Links</a></p>\n</li>\n<li>\n<p><a href=\"#interests\">Interests</a></p>\n</li>\n<li>\n<p><a href=\"#challenges--awards\">Challenges &#x26; Awards</a></p>\n<ul>\n<li><a href=\"#machine-learning\">Machine Learning</a></li>\n<li><a href=\"#hacking\">Hacking</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#work-experience\">Work Experience</a></p>\n<ul>\n<li>\n<p><a href=\"#company\">Company</a></p>\n<ul>\n<li><a href=\"#data-scientist-toss-core-20211206--present\"><em>Data Scientist</em>, <strong>Toss core</strong>, <strong>(2021.12.06 ~ present)</strong></a></li>\n<li><a href=\"#machine-learning-researcher-watcha-20200622--20211203\"><em>Machine Learning Researcher</em>, <strong>Watcha</strong>, <strong>(2020.06.22 ~ 2021.12.03)</strong></a></li>\n<li><a href=\"#machine-learning-engineer-rainist-20191111--20200619\"><em>Machine Learning Engineer</em>, <strong>Rainist</strong>, <strong>(2019.11.11 ~ 2020.06.19)</strong></a></li>\n<li><a href=\"#machine-learning-engineer-voyagerx-20190107--20191004\"><em>Machine Learning Engineer</em>, <strong>VoyagerX</strong>, <strong>(2019.01.07 ~ 2019.10.04)</strong></a></li>\n<li><a href=\"#penetration-tester-elcid-201607--201608\"><em>Penetration Tester</em>, <strong>ELCID</strong>, <strong>(2016.07 ~ 2016.08)</strong></a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#out-sourcing\">Out Sourcing</a></p>\n</li>\n<li>\n<p><a href=\"#lab\">Lab</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#publications\">Publications</a></p>\n<ul>\n<li><a href=\"#paper\">Paper</a></li>\n<li><a href=\"#conferencesworkshops\">Conferences/Workshops</a></li>\n<li><a href=\"#journals\">Journals</a></li>\n<li><a href=\"#posts\">Posts</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#educations\">Educations</a></p>\n</li>\n<li>\n<p><a href=\"#personal-projects\">Personal Projects</a></p>\n<ul>\n<li>\n<p><a href=\"#computer-languages\">Computer Languages</a></p>\n</li>\n<li>\n<p><a href=\"#machinedeep-learning\">Machine/Deep Learning</a></p>\n<ul>\n<li><a href=\"#generative-models\">Generative Models</a></li>\n<li><a href=\"#super-resolution\">Super Resolution</a></li>\n<li><a href=\"#i2i-translation\">I2I Translation</a></li>\n<li><a href=\"#style-transfer\">Style Transfer</a></li>\n<li><a href=\"#text-classificationgeneration\">Text Classification/Generation</a></li>\n<li><a href=\"#speech-synthesis\">Speech Synthesis</a></li>\n<li><a href=\"#optimizer\">Optimizer</a></li>\n<li><a href=\"#rl\">R.L</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#plug-ins\">Plug-Ins</a></p>\n</li>\n<li>\n<p><a href=\"#open-source-contributions\">Open Source Contributions</a></p>\n</li>\n<li>\n<p><a href=\"#security-hacking\">Security, Hacking</a></p>\n<ul>\n<li><a href=\"#ctfs-conferences\">CTFs, Conferences</a></li>\n<li><a href=\"#teams\">Teams</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#presentations\">Presentations</a></p>\n<ul>\n<li><a href=\"#2018\">2018</a></li>\n<li><a href=\"#2015\">2015</a></li>\n<li><a href=\"#2014\">2014</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/about/"},"frontmatter":{"title":"About ME","date":"Dec 12, 2020","tags":["About"],"keywords":["kozistr","Hyeongchan Kim"],"update":"Jan 03, 2022"},"timeToRead":14}},"pageContext":{"slug":"/about/","series":[],"lastmod":"2022-01-03"}},
    "staticQueryHashes": ["2027115977","2744905544","694178885"]}