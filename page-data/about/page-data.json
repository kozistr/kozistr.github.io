{"componentChunkName":"component---src-templates-post-tsx","path":"/about/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"profile\" style=\"position:relative;\"><a href=\"#profile\" aria-label=\"profile permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Profile</h2>\n<p>Alternative Military Service Status : <strong>on duty</strong> (<code class=\"language-text\">2020/11/27 ~ 2023/09/26</code>)</p>\n<p>CV : <a href=\"http://kozistr.tech/cv.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">[PDF] (as of Nov. 2022)</a></p>\n<h2 id=\"links\" style=\"position:relative;\"><a href=\"#links\" aria-label=\"links permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Links</h2>\n<table>\n<thead>\n<tr>\n<th align=\"left\"></th>\n<th align=\"left\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Email</td>\n<td align=\"left\"><strong>kozistr</strong>@gmail.com</td>\n</tr>\n<tr>\n<td align=\"left\">Github</td>\n<td align=\"left\"><a href=\"https://github.com/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/kozistr</a></td>\n</tr>\n<tr>\n<td align=\"left\">Kaggle</td>\n<td align=\"left\"><a href=\"https://www.kaggle.com/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.kaggle.com/kozistr</a></td>\n</tr>\n<tr>\n<td align=\"left\">Linkedin</td>\n<td align=\"left\"><a href=\"https://www.linkedin.com/in/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.linkedin.com/in/kozistr</a></td>\n</tr>\n</tbody>\n</table>\n<h2 id=\"interests\" style=\"position:relative;\"><a href=\"#interests\" aria-label=\"interests permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Interests</h2>\n<ul>\n<li>Lots of real-world challenges like <strong>Kaggle</strong></li>\n<li>Audio/Speech Domains\n<ul>\n<li>End to End Speaker Diarization</li>\n<li>Speaker Verifications</li>\n</ul>\n</li>\n<li>Computer Vision Domains\n<ul>\n<li>especially the medical domain</li>\n</ul>\n</li>\n</ul>\n<p>Previously, I was also interested in <strong>offensive security</strong>, kind of <em>Reverse Engineering</em>, <em>Linux Kernel Exploitation</em>.</p>\n<hr>\n<h2 id=\"challenges--awards\" style=\"position:relative;\"><a href=\"#challenges--awards\" aria-label=\"challenges  awards permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Challenges &#x26; Awards</h2>\n<h3 id=\"machine-learning\" style=\"position:relative;\"><a href=\"#machine-learning\" aria-label=\"machine learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine Learning</h3>\n<ul>\n<li>\n<p><strong>Kaggle Challenges</strong> :: Kaggle Challenges :: <strong>Competition Expert</strong></p>\n<blockquote>\n<ul>\n<li><a href=\"https://www.kaggle.com/competitions/amex-default-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">American Express - Default Prediction</a> - <strong>solo, top 3% (135 / 4875), Private 0.80758</strong> - <a href=\"https://www.kaggle.com/competitions/amex-default-prediction/discussion/347996\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2022.)</li>\n<li><a href=\"https://www.kaggle.com/c/ventilator-pressure-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google Brain - Ventilator Pressure Prediction</a> - <strong>team, top 1% (20 / 2605), Private 0.1171</strong> - <a href=\"https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285295#1570360\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2021.)</li>\n<li><a href=\"https://www.kaggle.com/c/siim-covid19-detection\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SIIM-FISABIO-RSNA COVID-19 Detection</a> - <strong>solo, top 4% (47 / 1305), Private 0.612</strong> - <a href=\"https://www.kaggle.com/c/siim-covid19-detection/discussion/263830#1463830\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2021.)</li>\n<li><a href=\"https://www.kaggle.com/c/shopee-product-matching\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Shopee - Price Match Guarantee</a> - <strong>solo, top 7% (166 / 2426), Private 0.725</strong> (2021.)</li>\n<li><a href=\"https://www.kaggle.com/c/birdsong-recognition\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Cornell Birdcall Identification</a> - <strong>team, top 2% (24 / 1395), Private 0.631</strong> - <a href=\"https://towardsdatascience.com/detecting-sounds-with-deep-learning-ed9a41909da0\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">towarddatascience</a> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/alaska2-image-steganalysis\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ALASKA2 Image Steganalysis</a> - <strong>solo, top 9% (93 / 1095), Private 0.917</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/tweet-sentiment-extraction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Tweet Sentiment Extraction</a> - <strong>solo, top 4% (84 / 2227), Private 0.71796</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/flower-classification-with-tpus\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Flower Classification with TPUs</a> - <strong>solo, top 4% (27 / 848), Private 0.98734</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/bengaliai-cv19\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kaggle Bengali.AI Handwritten Grapheme Classification</a> - <strong>solo, top 4% (67 / 2059), Private 0.9372</strong> (2020.)</li>\n<li><a href=\"https://www.kaggle.com/c/Kannada-MNIST\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kaggle Kannada MNIST Challenge</a> - <strong>solo, top 3% (28 / 1214), Private 0.99100</strong> (2019.)</li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>NAVER NLP Challenge</strong> :: NAVER NLP Challenge 2018</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/naver/nlp-challenge\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Semantic Role Labeling (SRL)</em> <strong>6th place</strong> - <a href=\"https://bit.ly/3eneg2y\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">oral presentation</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>A.I R&#x26;D Challenge</strong> :: A.I R&#x26;D Challenge 2018</p>\n<blockquote>\n<ul>\n<li><a href=\"http://airndchallenge.com/g5\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Fake or Real Detection</em> - as <em>Digital Forensic</em> Team</li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>NAVER A.I Hackathon</strong> :: NAVER A.I Hackathon 2018</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/naver/ai-hackathon-2018\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Kin</em> <strong>4th place</strong>, <em>Movie Review</em> <strong>13th place</strong> - <a href=\"https://github.com/kozistr/naver-ai-hackathon-2018\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>TF-KR Challenge</strong> :: Facebook TF-KR MNIST Challenge</p>\n<blockquote>\n<ul>\n<li><a href=\"https://github.com/kozistr/MNIST-Competition\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">TF-KR MNIST Challenge</a> - <strong>Top 9, 3rd price, ACC 0.9964</strong></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"hacking\" style=\"position:relative;\"><a href=\"#hacking\" aria-label=\"hacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hacking</h3>\n<ul>\n<li>\n<p><strong>Boot2Root CTF 2018</strong> :: <strong>2nd place</strong> (Demon + alpha)</p>\n</li>\n<li>\n<p><strong>Harekaze CTF 2017</strong> :: <strong>3rd place</strong> (SeoulWesterns)</p>\n</li>\n<li>\n<p><strong>WhiteHat League 1 (2017)</strong> :: <strong>2nd place</strong> (Demon)</p>\n<blockquote>\n<ul>\n<li>Awarded by 한국정보기술연구원 Received an award of <strong>$3,000</strong></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<hr>\n<h2 id=\"work-experience\" style=\"position:relative;\"><a href=\"#work-experience\" aria-label=\"work experience permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Work Experience</h2>\n<h3 id=\"company\" style=\"position:relative;\"><a href=\"#company\" aria-label=\"company permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Company</h3>\n<h4 id=\"data-scientist-toss-core-toss-cb-20211206--present\" style=\"position:relative;\"><a href=\"#data-scientist-toss-core-toss-cb-20211206--present\" aria-label=\"data scientist toss core toss cb 20211206  present permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Data Scientist</em>, <strong>Toss core, Toss CB</strong>, <strong>(2021.12.06 ~ present)</strong></h4>\n<ul>\n<li>Perosnal CSS model for the CB.\n<ul>\n<li>Developed a more accurate &#x26; robust CSS model for more general targets like thin-filer and thick-filer.</li>\n<li>Outperformed about <strong>15%</strong> (on the primary metric) compared with the previous method.</li>\n</ul>\n</li>\n<li>Classify the category of the user review for the NPS (Net Performer Score) product.\n<ul>\n<li>Built the RESTful API server to infer the deep learning model for the batch job.</li>\n<li>Saved analysis time and labor of the NPS team a lot.</li>\n</ul>\n</li>\n<li>Captcha model to break captchas for the automation product.\n<ul>\n<li>Developed the lightweight model for inference in real-time (about <code class=\"language-text\">1000 TPS</code> for a batch transaction, <code class=\"language-text\">80 ~ 100 TPS</code> for a sample on the CPU).</li>\n<li>Built the RESTful API server to serve the model in real-time on the CPU.</li>\n<li>In the A/B test, <code class=\"language-text\">google vision OCR</code> vs <code class=\"language-text\">New Captcha Model</code>\n<ul>\n<li><strong>Accuracy</strong> : improved <strong>50%p</strong> (<code class=\"language-text\">45%</code> to <code class=\"language-text\">95%</code>)</li>\n<li><strong>latency (p95)</strong> : reduced by <strong>80x</strong> (about <code class=\"language-text\">1000ms</code> to <code class=\"language-text\">12ms</code>)</li>\n<li><strong>Revenue</strong> : reduced cost by about <strong>$7,000 / year</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>User consumption forecasting model for CDP Product.\n<ul>\n<li>Build an efficient pipeline to process and train lots of tabular data (about 500 GB).</li>\n<li>Developed a Transformer based sequential model that predicts what the users will consume in the next month.</li>\n<li>In the A/B test, the new model achieved...</li>\n</ul>\n</li>\n<li>CSS model for BNPL (Buy Now Pay Later) service.\n<ul>\n<li>Developed the CSS model (default prediction) targeted to the thin-filer.</li>\n<li>Achieved the targeted <strong>default rate of about 1%</strong>.</li>\n</ul>\n</li>\n<li>Transaction category classification model to boost the advertisement.\n<ul>\n<li>Developed the ads category classifier that increases revenue in a roundabout way.</li>\n</ul>\n</li>\n<li>Internal product, The Slack bot that summarizes the long slack threads\n<ul>\n<li>help people to understand the context quickly with minimum effort.</li>\n</ul>\n</li>\n<li>Working as full-time.</li>\n</ul>\n<h4 id=\"machine-learning-researcher-watcha-20200622--20211203\" style=\"position:relative;\"><a href=\"#machine-learning-researcher-watcha-20200622--20211203\" aria-label=\"machine learning researcher watcha 20200622  20211203 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Researcher</em>, <strong>Watcha</strong>, <strong>(2020.06.22 ~ 2021.12.03)</strong></h4>\n<ul>\n<li>Watcha recommendation system to offer a better user experience and increase <code class=\"language-text\">paid conversion</code>.\n<ul>\n<li>Developed the advanced the training recipe &#x26; architecture to improve training stability and offline performance. Also, worked on post-processing to recommend unseen content to users. In the A/B test, the new model boosts the <strong>Click Ratio</strong> online metric by about <strong>1.01%+</strong>.</li>\n<li>Developed the network to capture the time the user watches while the augmentations bring the training stability and performance gain. In the A/B test, the new model wins the online metrics by the followings. (compared with Div2Vec and the new model, previous deep learning model beats the current new model)</li>\n<li><strong>*Viewing Days (mean)</strong>: improved <strong>1.012%+</strong></li>\n<li><strong>*Viewing Minutes (median)</strong>: improved <strong>1.015%+</strong></li>\n<li>Developed the sequential recommendation architecture to recommend what content to watch next. It achieved SOTA performance compared to the previous SOTA architecture like BERT4Rec. In the A/B test, the new model outperforms by the following metrics. (A: previous algorithm, B: the new model)\n<ul>\n<li><strong>Paid Conversion</strong> : improved <strong>1.39%p+</strong></li>\n<li><strong>*Viewing Days (mean)</strong> : improved <strong>0.25%p+</strong></li>\n<li><strong>*Viewing Minutes (median)</strong> : improved <strong>4.10%p+</strong></li>\n<li><strong>Click Ratio</strong> : improved <strong>4.30%p+</strong></li>\n<li><strong>Play Ratio</strong> : improved <strong>2.32%p+</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Face recognition model to find actors from the poster &#x26; still-cut images for the WatchaPedia product.\n<ul>\n<li>Developed the pipeline to identify &#x26; recognizing actor faces from the images with the face detection &#x26; identification deep learning models (similarity-based searching).</li>\n<li>Built a daily job that runs on the CPU. Also, optimize CPU-intensive operations to run fast.</li>\n</ul>\n</li>\n<li>Internal product to predict expected users' view-time of the content.\n<ul>\n<li>Before the content is imported, the model gives an insight into the valuation of the content like expected view-time affecting the cost of the content.</li>\n</ul>\n</li>\n<li>Internal product to help designer's works\n<ul>\n<li>Developed the image super-resolution model to upscale the image more accurately and faster (e.g., waifu).</li>\n</ul>\n</li>\n<li>Music recommendation system for <code class=\"language-text\">Watcha Music</code> (prototype)</li>\n<li>Worked as full-time.</li>\n</ul>\n<p>% <code class=\"language-text\">*Viewing Days</code> : how many days users are active on an app each month.</p>\n<p>% <code class=\"language-text\">*Viewing Minutes</code> : how many minutes the user watched the content.</p>\n<h4 id=\"machine-learning-engineer-rainist-20191111--20200619\" style=\"position:relative;\"><a href=\"#machine-learning-engineer-rainist-20191111--20200619\" aria-label=\"machine learning engineer rainist 20191111  20200619 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Engineer</em>, <strong>Rainist</strong>, <strong>(2019.11.11 ~ 2020.06.19)</strong></h4>\n<ul>\n<li>Transaction category classification application to identify the category for the convenience of user experience.\n<ul>\n<li>Developed the lightweight transaction category classification model. <strong>In A/B test</strong>, the new model <strong>achieved 25 ~ 30%p+</strong> <code class=\"language-text\">*Accuracy</code> improvement.</li>\n<li>Developed the backends (e.g., model serving, business logic microservices) in Python.\n<ul>\n<li>Utilized inference-aware framework (ONNX) to goal stable and low latency.</li>\n<li>Achieved a target latency of about 7 ~ 10 TPS (p50) while handling <code class=\"language-text\">1M transactions/day</code> (1 transaction = 100 samples).</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>CSS model to forecast the possibility of loan overdue.</li>\n<li>Worked as full-time.</li>\n</ul>\n<p>% <code class=\"language-text\">*Accuracy</code> : how many users don't update their transactions' category.</p>\n<h4 id=\"machine-learning-engineer-voyagerx-20190107--20191004\" style=\"position:relative;\"><a href=\"#machine-learning-engineer-voyagerx-20190107--20191004\" aria-label=\"machine learning engineer voyagerx 20190107  20191004 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Engineer</em>, <strong>VoyagerX</strong>, <strong>(2019.01.07 ~ 2019.10.04)</strong></h4>\n<ul>\n<li><code class=\"language-text\">Proceedings</code> deep learning application which automatically recognizes speakers &#x26; speeches (speaker diarization).\n<ul>\n<li>Developed the backend to diarize the conversation.</li>\n<li>Developed the lightweight speaker verification model (served at AWS Lambda).</li>\n<li>Developed the on/offline speaker diarization based on clustering &#x26; E2E methods.</li>\n</ul>\n</li>\n<li><code class=\"language-text\">Hair Salon</code> project to swap the hair with what the user wants naturally.\n<ul>\n<li>Developed a hair/face image segmentation model to identify hair &#x26; face accurately.</li>\n<li>Developed image in-painting model to detach a hair.</li>\n<li>Developed an I2I translation model to change the hairstyle.</li>\n</ul>\n</li>\n<li>Worked as an intern.</li>\n</ul>\n<h4 id=\"penetration-tester-elcid-201607--201608\" style=\"position:relative;\"><a href=\"#penetration-tester-elcid-201607--201608\" aria-label=\"penetration tester elcid 201607  201608 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Penetration Tester</em>, <strong>ELCID</strong>, <strong>(2016.07 ~ 2016.08)</strong></h4>\n<ul>\n<li>Penetrated the network firewall and anti-virus products.</li>\n<li>Worked as a part-time job.</li>\n</ul>\n<h3 id=\"out-sourcing\" style=\"position:relative;\"><a href=\"#out-sourcing\" aria-label=\"out sourcing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Out Sourcing</h3>\n<ul>\n<li>Developed Korean University Course Information Web Parser (About 40 Universities). <strong>2 times, (2017.7 ~ 2018.3)</strong></li>\n<li>Developed AWS CloudTrail logger analyzer / formatter. <strong>(2019.09 ~ 2019.10)</strong></li>\n</ul>\n<h3 id=\"lab\" style=\"position:relative;\"><a href=\"#lab\" aria-label=\"lab permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lab</h3>\n<p><a href=\"https://sites.google.com/view/hpclab/home\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HPC Lab</a>, KoreaTech, <strong>Undergraduate Researcher</strong>, <strong>(2018.09 ~ 2018.12)</strong></p>\n<ul>\n<li>Wrote a paper about an improved TextCNN model to predict a movie rate.</li>\n</ul>\n<hr>\n<h2 id=\"publications\" style=\"position:relative;\"><a href=\"#publications\" aria-label=\"publications permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Publications</h2>\n<h3 id=\"paper\" style=\"position:relative;\"><a href=\"#paper\" aria-label=\"paper permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Paper</h3>\n<p>[1] <strong>Kim</strong> et al, <a href=\"http://ktccs.kips.or.kr/digital-library/23245\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CNN Architecture Predicting Movie Rating</a>, 2020. 01.</p>\n<ul>\n<li>Wrote about the CNN Architecture, which utilizes a channel-attention method (SE Module) to TextCNN model, brings performance gain over the task while keeping its latency, generally.</li>\n<li>Handling un-normalized text with various convolution kernel sizes and spatial dropout</li>\n<li>Selected as one of the <code class=\"language-text\">highlight papers</code> for the first half of 2020</li>\n</ul>\n<h3 id=\"conferencesworkshops\" style=\"position:relative;\"><a href=\"#conferencesworkshops\" aria-label=\"conferencesworkshops permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conferences/Workshops</h3>\n<p>[1] <code class=\"language-text\">kozistr_team</code>, <a href=\"https://bit.ly/3eneg2y\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">presentation</a> <em>NAVER NLP Challenge 2018 SRL Task</em></a></p>\n<ul>\n<li>SRL Task, challenging w/o any domain knowledge. Presented about trials &#x26; errors during the competition</li>\n</ul>\n<h3 id=\"journals\" style=\"position:relative;\"><a href=\"#journals\" aria-label=\"journals permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Journals</h3>\n<p>[1] zer0day, <a href=\"http://zer0day.tistory.com/335?category=505873\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>Windows Anti-Debugging Techniques</em></a> (CodeEngn 2016) Sep. 2016. <a href=\"/refs/Anti%20Revering%20Techniques%20%5Bzer0day%5D.pdf\">PDF</a></p>\n<ul>\n<li>Wrote about lots of anti-reversing / debugging (A to Z) techniques avail on window executable binary</li>\n</ul>\n<h3 id=\"posts\" style=\"position:relative;\"><a href=\"#posts\" aria-label=\"posts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Posts</h3>\n<p>[1] kozistr (as a part of team, <code class=\"language-text\">Dragonsong</code>) <a href=\"https://towardsdatascience.com/detecting-sounds-with-deep-learning-ed9a41909da0\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">towarddatascience</a></p>\n<ul>\n<li>Wrote about audio classifier with deep learning based on the Kaggle challenge where we participated</li>\n</ul>\n<hr>\n<h2 id=\"personal-projects\" style=\"position:relative;\"><a href=\"#personal-projects\" aria-label=\"personal projects permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Personal Projects</h2>\n<h3 id=\"machinedeep-learning\" style=\"position:relative;\"><a href=\"#machinedeep-learning\" aria-label=\"machinedeep learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine/Deep Learning</h3>\n<h4 id=\"generative-models\" style=\"position:relative;\"><a href=\"#generative-models\" aria-label=\"generative models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generative Models</h4>\n<ul>\n<li>\n<p><strong>GANs-tensorflow</strong> :: Lots of GAN codes :) :: <a href=\"https://github.com/kozistr/Awesome-GANs\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Generative Adversary Networks</a></p>\n<blockquote>\n<ul>\n<li><strong>ACGAN-tensorflow</strong> :: Auxiliary Classifier GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/ACGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>StarGAN-tensorflow</strong> :: Unified GAN for multi-domain :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/StarGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>LAPGAN-tensorflow</strong> :: Laplacian Pyramid GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/LAPGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>BEGAN-tensorflow</strong> :: Boundary Equilibrium in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/BEGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>DCGAN-tensorflow</strong> :: Deep Convolutional GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/DCGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>SRGAN-tensorflow</strong> :: Super-Resolution GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/SRGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>WGAN-GP-tensorflow</strong> :: Wasserstein GAN w/ gradient penalty in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/WGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li>... lots of GANs (over 20) :)</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"super-resolution\" style=\"position:relative;\"><a href=\"#super-resolution\" aria-label=\"super resolution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Super Resolution</h4>\n<ul>\n<li>\n<p><strong>Single Image Super Resolution</strong> :: Single Image Super-Resolution (SISR)</p>\n<blockquote>\n<ul>\n<li><strong>rcan-tensorflow</strong> :: RCAN implementation in tensorflow :: <a href=\"https://github.com/kozistr/rcan-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>ESRGAN-tensorflow</strong> :: ESRGAN implementation in tensorflow :: <a href=\"https://github.com/kozistr/ESRGAN-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>NatSR-pytorch</strong> :: NatSR implementation in pytorch :: <a href=\"https://github.com/kozistr/NatSR-pytorch\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"i2i-translation\" style=\"position:relative;\"><a href=\"#i2i-translation\" aria-label=\"i2i translation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>I2I Translation</h4>\n<ul>\n<li><strong>Improved Content Disentanglement</strong> :: tuned version of 'Content Disentanglement' in pytorch :: <a href=\"https://github.com/kozistr/improved-ContentDisentanglement\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n<h4 id=\"style-transfer\" style=\"position:relative;\"><a href=\"#style-transfer\" aria-label=\"style transfer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Style Transfer</h4>\n<ul>\n<li>\n<p><strong>Image-Style-Transfer</strong> :: Image Neural Style Transfer</p>\n<blockquote>\n<ul>\n<li><strong>style-transfer-tensorflow</strong> :: Image Style-Transfer in tensorflow :: <a href=\"https://github.com/kozistr/style-transfer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"text-classificationgeneration\" style=\"position:relative;\"><a href=\"#text-classificationgeneration\" aria-label=\"text classificationgeneration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Text Classification/Generation</h4>\n<blockquote>\n<ul>\n<li><strong>movie-rate-prediction</strong> :: Korean sentences classification in tensorflow :: <a href=\"https://github.com/kozistr/naver-movie-rate-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>KoSpacing-tensorflow</strong> :: Automatic Korean sentences spacing in tensorflow :: <a href=\"https://github.com/kozistr/KoSpacing-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><del>code</del></a></li>\n<li><strong>text-tagging</strong> :: Automatic Korean articles categories classification in tensorflow :: <a href=\"https://github.com/sales-tagging/text-tagging-ml\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n<h4 id=\"speech-synthesis\" style=\"position:relative;\"><a href=\"#speech-synthesis\" aria-label=\"speech synthesis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Speech Synthesis</h4>\n<ul>\n<li>\n<p><strong>Tacotron-tensorflow</strong> :: Text To Sound (TTS)</p>\n<blockquote>\n<ul>\n<li><strong>tacotron-tensorflow</strong> :: lots of TTS models in tensorflow :: <a href=\"https://github.com/kozistr/tacotron-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><del>code</del></a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"optimizer\" style=\"position:relative;\"><a href=\"#optimizer\" aria-label=\"optimizer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Optimizer</h4>\n<ul>\n<li>\n<p><strong>pytorch-optimizer</strong> :: Bunch of optimizer implementations in PyTorch</p>\n<blockquote>\n<ul>\n<li><strong>pytorch_optimizer</strong> :: Bunch of optimizer implementations in PyTorch with clean-code, strict types. Also, including useful optimization ideas. Most of the implementations are based on the original paper, but I added some tweaks. :: <a href=\"https://github.com/kozistr/pytorch_optimizer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>AdaBound</strong> :: Optimizer that trains as fast as Adam and as good as SGD</p>\n<blockquote>\n<ul>\n<li><strong>AdaBound-tensorflow</strong> :: AdaBound Optimizer implementation in tensorflow :: <a href=\"https://github.com/kozistr/AdaBound-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>RAdam</strong> :: On The Variance Of The Adaptive Learning Rate And Beyond in tensorflow</p>\n<blockquote>\n<ul>\n<li><strong>RAdam-tensorflow</strong> :: RAdam Optimizer implementation in tensorflow :: <a href=\"https://github.com/kozistr/RAdam-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"rl\" style=\"position:relative;\"><a href=\"#rl\" aria-label=\"rl permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>R.L</h4>\n<ul>\n<li><strong>Rosseta Stone</strong> :: Hearthstone simulator using C++ with some reinforcement learning :: <a href=\"https://github.com/utilForever/RosettaStone\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n<h3 id=\"open-source-contributions\" style=\"position:relative;\"><a href=\"#open-source-contributions\" aria-label=\"open source contributions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Open Source Contributions</h3>\n<ul>\n<li><a href=\"https://github.com/google/syzkaller\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">syzkaller</a> :: New Generation of Linux Kernel Fuzzer :: <a href=\"https://github.com/google/syzkaller/pull/575\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#575</a></li>\n<li><a href=\"https://github.com/https://github.com/ThilinaRajapakse/simpletransformers\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">simpletransformers</a> :: Transformers made simple w/ training, evaluating, and prediction possible w/ one line each. :: <a href=\"https://github.com/ThilinaRajapakse/simpletransformers/pull/290\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#290</a></li>\n<li><a href=\"https://github.com/rwightman/pytorch-image-models\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">pytorch-image-models</a> :: PyTorch image models, scripts, pretrained weights :: <a href=\"https://github.com/rwightman/pytorch-image-models/pull/1058\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#1058</a>, <a href=\"https://github.com/rwightman/pytorch-image-models/pull/1069\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#1069</a></li>\n<li><a href=\"https://github.com/facebookresearch/deit\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">deit</a> :: DeiT: Data-efficient Image Transformers :: <a href=\"https://github.com/facebookresearch/deit/pull/140\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#140</a>, <a href=\"https://github.com/facebookresearch/deit/pull/147\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#147</a>, <a href=\"https://github.com/facebookresearch/deit/pull/148\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#148</a></li>\n<li><a href=\"https://github.com/facebookresearch/madgrad\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MADGRAD</a> :: MADGRAD Optimization Method :: <a href=\"https://github.com/facebookresearch/madgrad/pull/11\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#11</a></li>\n<li><a href=\"https://github.com/martinsbruveris/tensorflow-image-models\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">tensorflow-image-models</a> :: TensorFlow Image Models (tfimm) is a collection of image models with pretrained weights, obtained by porting architectures from timm to TensorFlow :: <a href=\"https://github.com/martinsbruveris/tensorflow-image-models/pull/61\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#61</a></li>\n</ul>\n<h3 id=\"plug-ins\" style=\"position:relative;\"><a href=\"#plug-ins\" aria-label=\"plug ins permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Plug-Ins</h3>\n<p>IDA-pro plug-in - Golang ELF binary (x86, x86-64), RTTI parser</p>\n<ul>\n<li>Recover stripped symbols &#x26; information and patch byte-codes for being able to hex-ray</li>\n</ul>\n<h2 id=\"security-hacking\" style=\"position:relative;\"><a href=\"#security-hacking\" aria-label=\"security hacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Security, Hacking</h2>\n<h3 id=\"ctfs-conferences\" style=\"position:relative;\"><a href=\"#ctfs-conferences\" aria-label=\"ctfs conferences permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CTFs, Conferences</h3>\n<ul>\n<li><a href=\"http://powerofcommunity.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">POC</a> 2016 Conference Staff</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 15 CTF Staff, Challenge Maker</li>\n<li><a href=\"https://www.codegate.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CodeGate</a> 2017 OpenCTF Staff, Challenge Maker</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 16 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://www.powerofxx.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">POX</a> 2017 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://www.powerofxx.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">KID</a> 2017 CTF Staff, Challenge Maker</li>\n<li>Belluminar 2017 CTF Staff</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 17 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 18 CTF Staff, Challenge Maker</li>\n</ul>\n<h3 id=\"teams\" style=\"position:relative;\"><a href=\"#teams\" aria-label=\"teams permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Teams</h3>\n<p>Hacking Team, <a href=\"http://f1ay.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>Fl4y</strong></a>. <strong>Since 2017.07 ~</strong></p>\n<p>Hacking Team, <a href=\"https://demonteam.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>Demon</strong></a> by <a href=\"http://powerofcommunity.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>POC</em></a>. <strong>Since 2014.02 ~ 2018.08</strong></p>\n<hr>\n<h2 id=\"educations\" style=\"position:relative;\"><a href=\"#educations\" aria-label=\"educations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Educations</h2>\n<p><strong>Senior</strong> in Computer Engineering from <a href=\"https://www.koreatech.ac.kr/eng.do\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">KUT</a></p>\n<h2 id=\"presentations\" style=\"position:relative;\"><a href=\"#presentations\" aria-label=\"presentations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Presentations</h2>\n<h3 id=\"2018\" style=\"position:relative;\"><a href=\"#2018\" aria-label=\"2018 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2018</h3>\n<p>[2] Artificial Intelligence ZeroToAll, Apr 2018.</p>\n<p>[1] Machine Learning ZeroToAll, Mar 2018.</p>\n<h3 id=\"2015\" style=\"position:relative;\"><a href=\"#2015\" aria-label=\"2015 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2015</h3>\n<p>[1] Polymorphic Virus VS AV Detection, Oct 2015.</p>\n<h3 id=\"2014\" style=\"position:relative;\"><a href=\"#2014\" aria-label=\"2014 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2014</h3>\n<p>[1] Network Sniffing &#x26; Detection, Oct, 2014.</p>","excerpt":"Profile Alternative Military Service Status : on duty () CV : [PDF] (as of Nov. 2022) Links   Email kozistr@gmail.com Github https://github…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#profile\">Profile</a></p>\n</li>\n<li>\n<p><a href=\"#links\">Links</a></p>\n</li>\n<li>\n<p><a href=\"#interests\">Interests</a></p>\n</li>\n<li>\n<p><a href=\"#challenges--awards\">Challenges &#x26; Awards</a></p>\n<ul>\n<li><a href=\"#machine-learning\">Machine Learning</a></li>\n<li><a href=\"#hacking\">Hacking</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#work-experience\">Work Experience</a></p>\n<ul>\n<li>\n<p><a href=\"#company\">Company</a></p>\n<ul>\n<li><a href=\"#data-scientist-toss-core-toss-cb-20211206--present\"><em>Data Scientist</em>, <strong>Toss core, Toss CB</strong>, <strong>(2021.12.06 ~ present)</strong></a></li>\n<li><a href=\"#machine-learning-researcher-watcha-20200622--20211203\"><em>Machine Learning Researcher</em>, <strong>Watcha</strong>, <strong>(2020.06.22 ~ 2021.12.03)</strong></a></li>\n<li><a href=\"#machine-learning-engineer-rainist-20191111--20200619\"><em>Machine Learning Engineer</em>, <strong>Rainist</strong>, <strong>(2019.11.11 ~ 2020.06.19)</strong></a></li>\n<li><a href=\"#machine-learning-engineer-voyagerx-20190107--20191004\"><em>Machine Learning Engineer</em>, <strong>VoyagerX</strong>, <strong>(2019.01.07 ~ 2019.10.04)</strong></a></li>\n<li><a href=\"#penetration-tester-elcid-201607--201608\"><em>Penetration Tester</em>, <strong>ELCID</strong>, <strong>(2016.07 ~ 2016.08)</strong></a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#out-sourcing\">Out Sourcing</a></p>\n</li>\n<li>\n<p><a href=\"#lab\">Lab</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#publications\">Publications</a></p>\n<ul>\n<li><a href=\"#paper\">Paper</a></li>\n<li><a href=\"#conferencesworkshops\">Conferences/Workshops</a></li>\n<li><a href=\"#journals\">Journals</a></li>\n<li><a href=\"#posts\">Posts</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#personal-projects\">Personal Projects</a></p>\n<ul>\n<li>\n<p><a href=\"#machinedeep-learning\">Machine/Deep Learning</a></p>\n<ul>\n<li><a href=\"#generative-models\">Generative Models</a></li>\n<li><a href=\"#super-resolution\">Super Resolution</a></li>\n<li><a href=\"#i2i-translation\">I2I Translation</a></li>\n<li><a href=\"#style-transfer\">Style Transfer</a></li>\n<li><a href=\"#text-classificationgeneration\">Text Classification/Generation</a></li>\n<li><a href=\"#speech-synthesis\">Speech Synthesis</a></li>\n<li><a href=\"#optimizer\">Optimizer</a></li>\n<li><a href=\"#rl\">R.L</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#open-source-contributions\">Open Source Contributions</a></p>\n</li>\n<li>\n<p><a href=\"#plug-ins\">Plug-Ins</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#security-hacking\">Security, Hacking</a></p>\n<ul>\n<li><a href=\"#ctfs-conferences\">CTFs, Conferences</a></li>\n<li><a href=\"#teams\">Teams</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#educations\">Educations</a></p>\n</li>\n<li>\n<p><a href=\"#presentations\">Presentations</a></p>\n<ul>\n<li><a href=\"#2018\">2018</a></li>\n<li><a href=\"#2015\">2015</a></li>\n<li><a href=\"#2014\">2014</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/about/"},"frontmatter":{"title":"About ME","date":"Dec 12, 2020","tags":["About","CV"],"keywords":["cv","resume","aboutme"],"update":"Nov 25, 2022"},"timeToRead":16}},"pageContext":{"slug":"/about/","series":[],"lastmod":"2022-11-25"}},"staticQueryHashes":["2027115977","2744905544","694178885"]}