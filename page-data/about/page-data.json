{"componentChunkName":"component---src-templates-post-tsx","path":"/about/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"profile\" style=\"position:relative;\"><a href=\"#profile\" aria-label=\"profile permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Profile</h2>\n<ul>\n<li>\n<p>Service machine learning products in various domains, Audio &#x26; Speech, Vision, NLP, Recommendation Systems, Tabular, LLM applications in many startups.</p>\n</li>\n<li>\n<p>Kaggle 2x Expert. the highest competition rank is <strong>top 0.1%</strong>.</p>\n</li>\n<li>\n<p>Alternative Military Service Status : <strong>discharge</strong> (<code class=\"language-text\">2020/11/27 ~ 2023/09/26</code>)</p>\n</li>\n<li>\n<p>CV : <a href=\"http://kozistr.tech/cv.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">[PDF] (as of Nov. 2024)</a></p>\n</li>\n</ul>\n<h2 id=\"links\" style=\"position:relative;\"><a href=\"#links\" aria-label=\"links permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Links</h2>\n<table>\n<thead>\n<tr>\n<th align=\"left\"></th>\n<th align=\"left\"></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"left\">Email</td>\n<td align=\"left\"><strong>kozistr</strong>@gmail.com</td>\n</tr>\n<tr>\n<td align=\"left\">Github</td>\n<td align=\"left\"><a href=\"https://github.com/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://github.com/kozistr</a></td>\n</tr>\n<tr>\n<td align=\"left\">Kaggle</td>\n<td align=\"left\"><a href=\"https://www.kaggle.com/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.kaggle.com/kozistr</a></td>\n</tr>\n<tr>\n<td align=\"left\">Linkedin</td>\n<td align=\"left\"><a href=\"https://www.linkedin.com/in/kozistr\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.linkedin.com/in/kozistr</a></td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"challenges--awards\" style=\"position:relative;\"><a href=\"#challenges--awards\" aria-label=\"challenges  awards permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Challenges &#x26; Awards</h2>\n<h3 id=\"machine-learning\" style=\"position:relative;\"><a href=\"#machine-learning\" aria-label=\"machine learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine Learning</h3>\n<ul>\n<li>\n<p><strong>Kaggle Challenges</strong> :: Kaggle Challenges :: <strong>Competition Expert</strong></p>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/competitions/birdclef-2023\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">BirdCLEF 2023</a> - <strong>sole, top 2% (24 / 1189), Private 0.73641</strong> - <a href=\"https://www.kaggle.com/competitions/birdclef-2023/discussion/412996\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2023.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/competitions/asl-signs\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google - Isolated Sign Language Recognition</a> - <strong>sole, top 5% (63 / 1165), Private 0.8377</strong> - (2023.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/competitions/rsna-breast-cancer-detection\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">RSNA Screening Mammography Breast Cancer Detection</a> - <strong>solo, top 1% (16 / 1687), Private 0.49</strong> - <a href=\"https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/391133\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2023.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/competitions/g2net-detecting-continuous-gravitational-waves\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">G2Net Detecting Continuous Gravitational Waves</a> - <strong>solo, top 2% (22 / 936), Private 0.771</strong> - <a href=\"https://www.kaggle.com/competitions/g2net-detecting-continuous-gravitational-waves/discussion/375927\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2023.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/competitions/amex-default-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">American Express - Default Prediction</a> - <strong>solo, top 3% (135 / 4875), Private 0.80758</strong> - <a href=\"https://www.kaggle.com/competitions/amex-default-prediction/discussion/347996\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2022.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/ventilator-pressure-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Google Brain - Ventilator Pressure Prediction</a> - <strong>team, top 1% (20 / 2605), Private 0.1171</strong> - <a href=\"https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/285295#1570360\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2021.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/siim-covid19-detection\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">SIIM-FISABIO-RSNA COVID-19 Detection</a> - <strong>solo, top 4% (47 / 1305), Private 0.612</strong> - <a href=\"https://www.kaggle.com/c/siim-covid19-detection/discussion/263830#1463830\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a> (2021.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/shopee-product-matching\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Shopee - Price Match Guarantee</a> - <strong>solo, top 7% (166 / 2426), Private 0.725</strong> (2021.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/birdsong-recognition\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Cornell Birdcall Identification</a> - <strong>team, top 2% (24 / 1395), Private 0.631</strong> - <a href=\"https://towardsdatascience.com/detecting-sounds-with-deep-learning-ed9a41909da0\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">towarddatascience</a> (2020.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/alaska2-image-steganalysis\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ALASKA2 Image Steganalysis</a> - <strong>solo, top 9% (93 / 1095), Private 0.917</strong> (2020.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/tweet-sentiment-extraction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Tweet Sentiment Extraction</a> - <strong>solo, top 4% (84 / 2227), Private 0.71796</strong> (2020.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/flower-classification-with-tpus\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Flower Classification with TPUs</a> - <strong>solo, top 4% (27 / 848), Private 0.98734</strong> (2020.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/bengaliai-cv19\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kaggle Bengali.AI Handwritten Grapheme Classification</a> - <strong>solo, top 4% (67 / 2059), Private 0.9372</strong> (2020.)</p>\n</blockquote>\n<blockquote>\n<p><a href=\"https://www.kaggle.com/c/Kannada-MNIST\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kaggle Kannada MNIST Challenge</a> - <strong>solo, top 3% (28 / 1214), Private 0.99100</strong> (2019.)</p>\n</blockquote>\n</li>\n<li>\n<p><strong>NAVER NLP Challenge</strong> :: NAVER NLP Challenge 2018</p>\n<blockquote>\n<p><a href=\"https://github.com/naver/nlp-challenge\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Semantic Role Labeling (SRL)</em> <strong>6th place</strong> - <a href=\"https://bit.ly/3eneg2y\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">oral presentation</a></p>\n</blockquote>\n</li>\n<li>\n<p><strong>A.I R&#x26;D Challenge</strong> :: A.I R&#x26;D Challenge 2018</p>\n<blockquote>\n<p><a href=\"http://airndchallenge.com/g5\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Fake or Real Detection</em> - as <em>Digital Forensic</em> Team</p>\n</blockquote>\n</li>\n<li>\n<p><strong>NAVER A.I Hackathon</strong> :: NAVER A.I Hackathon 2018</p>\n<blockquote>\n<p><a href=\"https://github.com/naver/ai-hackathon-2018\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Final</a> - <em>Kin</em> <strong>4th place</strong>, <em>Movie Review</em> <strong>13th place</strong> - <a href=\"https://github.com/kozistr/naver-ai-hackathon-2018\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">solution</a></p>\n</blockquote>\n</li>\n<li>\n<p><strong>TF-KR Challenge</strong> :: Facebook TF-KR MNIST Challenge</p>\n<blockquote>\n<p><a href=\"https://github.com/kozistr/MNIST-Competition\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">TF-KR MNIST Challenge</a> - <strong>Top 9, 3rd price, ACC 0.9964</strong></p>\n</blockquote>\n</li>\n</ul>\n<h3 id=\"hacking\" style=\"position:relative;\"><a href=\"#hacking\" aria-label=\"hacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Hacking</h3>\n<ul>\n<li>\n<p><strong>Boot2Root CTF 2018</strong> :: <strong>2nd place</strong> (Demon + alpha)</p>\n</li>\n<li>\n<p><strong>Harekaze CTF 2017</strong> :: <strong>3rd place</strong> (SeoulWesterns)</p>\n</li>\n<li>\n<p><strong>WhiteHat League 1 (2017)</strong> :: <strong>2nd place</strong> (Demon)</p>\n<blockquote>\n<ul>\n<li>Awarded by 한국정보기술연구원 Received an award of <strong>$3,000</strong></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<hr>\n<h2 id=\"work-experience\" style=\"position:relative;\"><a href=\"#work-experience\" aria-label=\"work experience permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Work Experience</h2>\n<ul>\n<li><strong>2023 - 2024</strong> : Joined Sionic AI. Built enterprise-grade LLM applications.</li>\n<li><strong>2021 - 2023</strong> : Joined Viva Republica (Toss). Developed many products like BNPL, CSS, OCR, NPS, CDP, and in-house products.</li>\n<li><strong>2020 - 2021</strong> : Joined Watcha. Developed Watcha recommendation system, and contributed to other products like WatchaPedia, in-house applications.</li>\n<li><strong>2019 - 2020</strong> : Joined Rainist (Banksalad). Developed a transaction classifier service to analyze the categories with low latency, high accuracy, and in real-time.</li>\n<li><strong>2019</strong> : Joined VoyagerX. Developed a speaker diarization product that automatically recognizes the contents of the meeting.</li>\n<li><strong>- 2019</strong> : offensive security stuffs. Mainly researched and studied Linux kernel exploitation and reverse engineering.</li>\n</ul>\n<h3 id=\"company\" style=\"position:relative;\"><a href=\"#company\" aria-label=\"company permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Company</h3>\n<h4 id=\"machine-learning-engineer-sionic-ai-20231023--20240705\" style=\"position:relative;\"><a href=\"#machine-learning-engineer-sionic-ai-20231023--20240705\" aria-label=\"machine learning engineer sionic ai 20231023  20240705 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Engineer</em>, <strong>Sionic AI</strong>, <strong>(2023.10.23 ~ 2024.07.05)</strong></h4>\n<ul>\n<li>Search engine and LLM applications based on RAG for B2B products.\n<ul>\n<li>Developed advanced RAG algorithm that accurately handles multi-turns, huge and lots of documents, and is cost-efficient.</li>\n<li>Developed multi/cross-lingual text embedding and re-ranker models, which perform well in Korean.</li>\n<li>Developed and maintained backend services such as backends for business logic, model inference engines, and VectorDB.</li>\n</ul>\n</li>\n<li>Worked as a full-time (early start-up member)</li>\n</ul>\n<h4 id=\"data-scientist-toss-core-20211206--20230927\" style=\"position:relative;\"><a href=\"#data-scientist-toss-core-20211206--20230927\" aria-label=\"data scientist toss core 20211206  20230927 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Data Scientist</em>, <strong>Toss core</strong>, <strong>(2021.12.06 ~ 2023.09.27)</strong></h4>\n<ul>\n<li>Develop TPS (Toss Profile Service) product.</li>\n<li>Various models to boost Loan Comparison products.\n<ul>\n<li>Developed a CSS model only with non-financial data and it outperformed by about <strong>~ 4%p</strong> (on the primary metric) compared with the previous method.</li>\n<li>Developed models to predict loan approval and interest rate.</li>\n</ul>\n</li>\n<li>Various CSS models for the CB (Credit Bureau).\n<ul>\n<li>Developed a more accurate &#x26; robust CSS model that mainly targets the thin-filer and it outperformed about <strong>15%</strong> compared with the previous method.</li>\n<li>Developed a model that predicts consumer proposal status.</li>\n<li>Developed a transaction classifier with finance-relevant category to utilize at the feature engineering to boost the performance of CSS model.</li>\n</ul>\n</li>\n<li>Classify the category of the user review for the NPS (Net Performer Score) product.\n<ul>\n<li>Developed the RESTful API server to infer the deep learning model for the batch job.</li>\n<li>Saved analysis time and labor of the NPS team.</li>\n</ul>\n</li>\n<li>OCR model to break captchas for the automation product.\n<ul>\n<li>Developed the lightweight models (text detector &#x26; captcha classifier) for inference in real-time (about <code class=\"language-text\">1000 TPS</code> for a batch transaction, <code class=\"language-text\">80 ~ 100 TPS</code> for a sample on the CPU) and built the RESTful API server to serve the model in real-time on the CPU.</li>\n<li>In the A/B test, <code class=\"language-text\">google vision OCR</code> vs <code class=\"language-text\">New Captcha Model</code>\n<ul>\n<li><strong>Accuracy (top1)</strong> : improved <strong>50%p</strong> (<code class=\"language-text\">45%</code> to <code class=\"language-text\">95%</code>)</li>\n<li><strong>latency (p95)</strong> : reduced by <strong>80x</strong> (about <code class=\"language-text\">1000ms</code> to <code class=\"language-text\">12ms</code>)</li>\n<li><strong>Revenue</strong> reduced cost by about <strong>$7,000 ~ / year</strong></li>\n<li>It also elaborates on decreasing a funnel and increasing user conversion.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>User consumption forecasting model for the *CDP Product.\n<ul>\n<li>Developed the Transformer based sequential model that predicts what the users will consume in the next month.</li>\n<li>Built an efficient pipeline to process and train lots of tabular data.</li>\n</ul>\n</li>\n<li>CSS model for BNPL (Buy Now Pay Later) service.\n<ul>\n<li>Developed the <strong>CSS model</strong> (default prediction), mainly targeted to the <strong>thin-filer</strong>. The new model achieved the targeted <strong>default rate of about 1%</strong>.</li>\n<li>Developed the <strong>explainer</strong> to describe which factors <strong>affect the rejection</strong>.</li>\n</ul>\n</li>\n<li>Transaction category classification model to boost the advertisement.\n<ul>\n<li>Developed the ads category classifier that <strong>increases revenue</strong> in a roundabout way.</li>\n</ul>\n</li>\n<li>Internal product, The Slack bots that summarize the long threads.\n<ul>\n<li>help people to <strong>understand the context</strong> quickly with minimum effort.</li>\n<li>summarize the weekly mail using ChatGPT with prompt engineering.</li>\n</ul>\n</li>\n<li>Worked as full-time.</li>\n</ul>\n<p>% <code class=\"language-text\">*CDP</code>: Customer Data Platform. Lots of user segments generated by the ML models.</p>\n<h4 id=\"machine-learning-researcher-watcha-20200622--20211203\" style=\"position:relative;\"><a href=\"#machine-learning-researcher-watcha-20200622--20211203\" aria-label=\"machine learning researcher watcha 20200622  20211203 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Researcher</em>, <strong>Watcha</strong>, <strong>(2020.06.22 ~ 2021.12.03)</strong></h4>\n<ul>\n<li>\n<p>Watcha recommendation system to offer a better user experience and increase <code class=\"language-text\">paid conversion</code>.</p>\n<ul>\n<li>Developed the <strong>advanced the training recipe &#x26; architecture</strong> to improve training stability and the performance. Also, working on <strong>post-processing</strong> to recommend unseen content to users. In the A/B test, the new model boosts the <strong>Click Ratio</strong> by about <strong>1.01%+</strong>.</li>\n<li>Developed the network to capture the active time of user while the augmentations bring the training stability and performance gain. In the A/B/C test, the new model beats <code class=\"language-text\">Div2Vec</code> in the online metrics while achieving comparable performance with the previous model (A: <a href=\"https://arxiv.org/abs/2009.09588\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Div2Vec</a>, B: the previous model, C: the new model).\n<ul>\n<li><strong>*Viewing Days</strong> (mean): improved <strong>1.012%+</strong></li>\n<li><strong>*Viewing Minutes</strong> (median): improved <strong>1.015%+</strong></li>\n</ul>\n</li>\n<li>Developed the sequential recommendation architecture to recommend what content to watch next. It achieved SOTA performance compared to the previous SOTA architecture like BERT4Rec. In the A/B test, the new model outperforms by the following metrics (A: previous algorithm, B: the new model).\n<ul>\n<li><strong>Paid Conversion</strong> : improved <strong>1.39%p+</strong></li>\n<li><strong>*Viewing Days</strong> (mean): improved <strong>0.25%p+</strong></li>\n<li><strong>*Viewing Minutes</strong> (median): improved <strong>4.10%p+</strong></li>\n<li><strong>Click Ratio</strong> : improved <strong>4.30%p+</strong></li>\n<li><strong>Play Ratio</strong> : improved <strong>2.32%p+</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p>Face recognition architecture to find actors from the poster &#x26; still-cut images for the Watcha Pedia product.</p>\n<ul>\n<li>Developed the pipeline to identify &#x26; recognizing actor faces from the images with the face detection &#x26; identification deep learning models (similarity-based searching).</li>\n<li>Built a daily job that runs on the CPU. Also, optimize CPU-intensive operations to run fast.</li>\n</ul>\n</li>\n<li>\n<p>Internal product to predict expected users' view-time of the content.</p>\n<ul>\n<li>Before the content is imported, the model gives an insight into the valuation of the content, like expected view-time affecting the cost of the content.</li>\n</ul>\n</li>\n<li>\n<p>Internal product to help designer's works</p>\n<ul>\n<li>Developed the image super-resolution model to upscale the image more accurately and faster (e.g., waifu).</li>\n</ul>\n</li>\n<li>\n<p>Music recommendation system for <code class=\"language-text\">Watcha Music</code> (prototype)</p>\n</li>\n<li>\n<p>Worked as full-time.</p>\n</li>\n<li>\n<p>% <code class=\"language-text\">*Viewing Days</code> : how many days users are active on an app each month.</p>\n</li>\n<li>\n<p>% <code class=\"language-text\">*Viewing Minutes</code> : how many minutes the user watched the content.</p>\n</li>\n</ul>\n<h4 id=\"machine-learning-engineer-rainist-20191111--20200619\" style=\"position:relative;\"><a href=\"#machine-learning-engineer-rainist-20191111--20200619\" aria-label=\"machine learning engineer rainist 20191111  20200619 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Engineer</em>, <strong>Rainist</strong>, <strong>(2019.11.11 ~ 2020.06.19)</strong></h4>\n<ul>\n<li>Transaction category classification application to identify the category for the convenience of user experience.\n<ul>\n<li>Developed the lightweight transaction category classification model. In the A/B test, the new model <strong>achieved 25 ~ 30%p+</strong> <code class=\"language-text\">*Accuracy</code> improvement.</li>\n<li>Developed the backends (e.g., model serving, business logic microservices) in Python.\n<ul>\n<li>Utilized inference-aware framework (ONNX) to goal stable and low latency.</li>\n<li>Achieved a target latency of <strong>about 7 ~ 10 TPS (p50)</strong> while handling <code class=\"language-text\">1M transactions / day</code> (1 transaction = 100 samples).</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>CSS model to forecast the possibility of loan overdue.</li>\n<li>Worked as full-time.</li>\n</ul>\n<p>% <code class=\"language-text\">*Accuracy</code> : how many users don't update their transactions' category.</p>\n<h4 id=\"machine-learning-engineer-voyagerx-20190107--20191004\" style=\"position:relative;\"><a href=\"#machine-learning-engineer-voyagerx-20190107--20191004\" aria-label=\"machine learning engineer voyagerx 20190107  20191004 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Machine Learning Engineer</em>, <strong>VoyagerX</strong>, <strong>(2019.01.07 ~ 2019.10.04)</strong></h4>\n<ul>\n<li><code class=\"language-text\">Proceedings</code> deep learning application which automatically recognizes speakers &#x26; speeches (speaker diarization).\n<ul>\n<li>Developed the backend to diarize the conversation.</li>\n<li>Developed the lightweight speaker verification model (served at AWS Lambda).</li>\n<li>Developed the on/offline speaker diarization based on clustering &#x26; E2E methods.</li>\n</ul>\n</li>\n<li><code class=\"language-text\">Hair Salon</code> project to swap the hair with what the user wants naturally.\n<ul>\n<li>Developed a hair/face image segmentation model to identify hair &#x26; face accurately.</li>\n<li>Developed image in-painting model to detach a hair.</li>\n<li>Developed an I2I translation model to change the hairstyle.</li>\n</ul>\n</li>\n<li>Worked as an intern.</li>\n</ul>\n<h4 id=\"penetration-tester-elcid-201607--201608\" style=\"position:relative;\"><a href=\"#penetration-tester-elcid-201607--201608\" aria-label=\"penetration tester elcid 201607  201608 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a><em>Penetration Tester</em>, <strong>ELCID</strong>, <strong>(2016.07 ~ 2016.08)</strong></h4>\n<ul>\n<li>Penetrated the network firewall and anti-virus products.</li>\n<li>Worked as a part-time job.</li>\n</ul>\n<h3 id=\"out-sourcing\" style=\"position:relative;\"><a href=\"#out-sourcing\" aria-label=\"out sourcing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Out Sourcing</h3>\n<ul>\n<li>Developed Korean University Course Information Web Parser (about 40 universities). <strong>2 times, (2017.07, 2018.03)</strong></li>\n<li>Developed AWS CloudTrail logger analyzer. <strong>(2019.09 ~ 2019.10)</strong></li>\n</ul>\n<h3 id=\"lab\" style=\"position:relative;\"><a href=\"#lab\" aria-label=\"lab permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Lab</h3>\n<p><a href=\"https://sites.google.com/view/hpclab/home\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HPC Lab</a>, KoreaTech, <strong>Undergraduate Researcher</strong>, <strong>(2018.09 ~ 2018.12)</strong></p>\n<ul>\n<li>Wrote a paper about an improved TextCNN model to predict a movie rate.</li>\n</ul>\n<hr>\n<h2 id=\"publications\" style=\"position:relative;\"><a href=\"#publications\" aria-label=\"publications permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Publications</h2>\n<h3 id=\"paper\" style=\"position:relative;\"><a href=\"#paper\" aria-label=\"paper permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Paper</h3>\n<p>[1] <strong>Kim</strong> et al, <a href=\"http://ktccs.kips.or.kr/digital-library/23245\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CNN Architecture Predicting Movie Rating</a>, 2020. 01.</p>\n<ul>\n<li>Wrote about the CNN Architecture, which utilizes a channel-attention method (SE Module) to the TextCNN model, bringing performance gain over the task while keeping its latency, generally.</li>\n<li>Handling un-normalized text with various convolution kernel sizes and spatial dropout</li>\n<li>Selected as one of the <code class=\"language-text\">highlight papers</code> for the first half of 2020</li>\n</ul>\n<h3 id=\"conferencesworkshops\" style=\"position:relative;\"><a href=\"#conferencesworkshops\" aria-label=\"conferencesworkshops permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conferences/Workshops</h3>\n<p>[1] <code class=\"language-text\">kozistr_team</code>, <a href=\"https://bit.ly/3eneg2y\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">presentation</a> <em>NAVER NLP Challenge 2018 SRL Task</em></p>\n<ul>\n<li>SRL Task, challenging w/o any domain knowledge. Presented about trials &#x26; errors during the competition</li>\n</ul>\n<h3 id=\"journals\" style=\"position:relative;\"><a href=\"#journals\" aria-label=\"journals permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Journals</h3>\n<p>[1] zer0day, <a href=\"http://zer0day.tistory.com/335?category=505873\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>Windows Anti-Debugging Techniques</em></a> (CodeEngn 2016) Sep. 2016. <a href=\"https://t1.daumcdn.net/cfile/tistory/21611F5057EC7DCD2F\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">PDF</a></p>\n<ul>\n<li>Wrote about lots of anti-reversing / debugging (A to Z) techniques avail on window executable binary</li>\n</ul>\n<h3 id=\"posts\" style=\"position:relative;\"><a href=\"#posts\" aria-label=\"posts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Posts</h3>\n<p>[1] kozistr (as a part of team, <code class=\"language-text\">Dragonsong</code>) <a href=\"https://towardsdatascience.com/detecting-sounds-with-deep-learning-ed9a41909da0\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">towarddatascience</a></p>\n<ul>\n<li>Wrote about audio classifier with deep learning based on the Kaggle challenge where we participated</li>\n</ul>\n<hr>\n<h2 id=\"personal-projects\" style=\"position:relative;\"><a href=\"#personal-projects\" aria-label=\"personal projects permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Personal Projects</h2>\n<h3 id=\"machinedeep-learning\" style=\"position:relative;\"><a href=\"#machinedeep-learning\" aria-label=\"machinedeep learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Machine/Deep Learning</h3>\n<h4 id=\"generative-models\" style=\"position:relative;\"><a href=\"#generative-models\" aria-label=\"generative models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Generative Models</h4>\n<ul>\n<li>\n<p><strong>GANs-tensorflow</strong> :: Lots of GAN :: <a href=\"https://github.com/kozistr/Awesome-GANs\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Generative Adversary Networks</a></p>\n<blockquote>\n<ul>\n<li><strong>ACGAN-tensorflow</strong> :: Auxiliary Classifier GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/ACGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>StarGAN-tensorflow</strong> :: Unified GAN for multi-domain :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/StarGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>LAPGAN-tensorflow</strong> :: Laplacian Pyramid GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/LAPGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>BEGAN-tensorflow</strong> :: Boundary Equilibrium in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/BEGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>DCGAN-tensorflow</strong> :: Deep Convolutional GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/DCGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>SRGAN-tensorflow</strong> :: Super-Resolution GAN in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/SRGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>WGAN-GP-tensorflow</strong> :: Wasserstein GAN w/ gradient penalty in tensorflow :: <a href=\"https://github.com/kozistr/Awesome-GANs/tree/master/WGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li>... lots of GANs (over 20) :)</li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"super-resolution\" style=\"position:relative;\"><a href=\"#super-resolution\" aria-label=\"super resolution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Super Resolution</h4>\n<ul>\n<li>\n<p><strong>Single Image Super Resolution</strong> :: Single Image Super-Resolution (SISR)</p>\n<blockquote>\n<ul>\n<li><strong>rcan-tensorflow</strong> :: RCAN implementation in tensorflow :: <a href=\"https://github.com/kozistr/rcan-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>ESRGAN-tensorflow</strong> :: ESRGAN implementation in tensorflow :: <a href=\"https://github.com/kozistr/ESRGAN-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>NatSR-pytorch</strong> :: NatSR implementation in pytorch :: <a href=\"https://github.com/kozistr/NatSR-pytorch\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"i2i-translation\" style=\"position:relative;\"><a href=\"#i2i-translation\" aria-label=\"i2i translation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>I2I Translation</h4>\n<ul>\n<li><strong>Improved Content Disentanglement</strong> :: tuned version of 'Content Disentanglement' in pytorch :: <a href=\"https://github.com/kozistr/improved-ContentDisentanglement\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n<h4 id=\"style-transfer\" style=\"position:relative;\"><a href=\"#style-transfer\" aria-label=\"style transfer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Style Transfer</h4>\n<ul>\n<li>\n<p><strong>Image-Style-Transfer</strong> :: Image Neural Style Transfer</p>\n<blockquote>\n<ul>\n<li><strong>style-transfer-tensorflow</strong> :: Image Style-Transfer in tensorflow :: <a href=\"https://github.com/kozistr/style-transfer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"text-classificationgeneration\" style=\"position:relative;\"><a href=\"#text-classificationgeneration\" aria-label=\"text classificationgeneration permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Text Classification/Generation</h4>\n<blockquote>\n<ul>\n<li><strong>movie-rate-prediction</strong> :: Korean sentences classification in tensorflow :: <a href=\"https://github.com/kozistr/naver-movie-rate-prediction\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n<li><strong>KoSpacing-tensorflow</strong> :: Automatic Korean sentences spacing in tensorflow :: <a href=\"https://github.com/kozistr/KoSpacing-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><del>code</del></a></li>\n<li><strong>text-tagging</strong> :: Automatic Korean articles categories classification in tensorflow :: <a href=\"https://github.com/sales-tagging/text-tagging-ml\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n<h4 id=\"speech-synthesis\" style=\"position:relative;\"><a href=\"#speech-synthesis\" aria-label=\"speech synthesis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Speech Synthesis</h4>\n<ul>\n<li>\n<p><strong>Tacotron-tensorflow</strong> :: Text To Sound (TTS)</p>\n<blockquote>\n<ul>\n<li><strong>tacotron-tensorflow</strong> :: lots of TTS models in tensorflow :: <a href=\"https://github.com/kozistr/tacotron-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><del>code</del></a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"optimizer\" style=\"position:relative;\"><a href=\"#optimizer\" aria-label=\"optimizer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Optimizer</h4>\n<ul>\n<li>\n<p><strong>pytorch-optimizer</strong> :: optimizer &#x26; lr scheduler collections in PyTorch</p>\n<blockquote>\n<ul>\n<li><strong>pytorch_optimizer</strong> :: pytorch-optimizer is optimizer &#x26; lr scheduler collections in PyTorch. I just re-implemented (speed &#x26; memory tweaks, plug-ins) the algorithm while based on the original paper. Also, It includes useful and practical optimization ideas. :: <a href=\"https://github.com/kozistr/pytorch_optimizer\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>AdaBound</strong> :: Optimizer that trains as fast as Adam and as good as SGD</p>\n<blockquote>\n<ul>\n<li><strong>AdaBound-tensorflow</strong> :: AdaBound Optimizer implementation in tensorflow :: <a href=\"https://github.com/kozistr/AdaBound-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n<li>\n<p><strong>RAdam</strong> :: On The Variance Of The Adaptive Learning Rate And Beyond in tensorflow</p>\n<blockquote>\n<ul>\n<li><strong>RAdam-tensorflow</strong> :: RAdam Optimizer implementation in tensorflow :: <a href=\"https://github.com/kozistr/RAdam-tensorflow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n</blockquote>\n</li>\n</ul>\n<h4 id=\"rl\" style=\"position:relative;\"><a href=\"#rl\" aria-label=\"rl permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>R.L</h4>\n<ul>\n<li><strong>Rosseta Stone</strong> :: Hearthstone simulator using C++ with some reinforcement learning :: <a href=\"https://github.com/utilForever/RosettaStone\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">code</a></li>\n</ul>\n<h3 id=\"open-source-contributions\" style=\"position:relative;\"><a href=\"#open-source-contributions\" aria-label=\"open source contributions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Open Source Contributions</h3>\n<ul>\n<li><a href=\"https://github.com/google/syzkaller\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">syzkaller</a> :: New Generation of Linux Kernel Fuzzer :: <a href=\"https://github.com/google/syzkaller/pull/575\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#575</a></li>\n<li><a href=\"https://github.com/https://github.com/ThilinaRajapakse/simpletransformers\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">simpletransformers</a> :: Transformers made simple w/ training, evaluating, and prediction possible w/ one line each. :: <a href=\"https://github.com/ThilinaRajapakse/simpletransformers/pull/290\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#290</a></li>\n<li><a href=\"https://github.com/rwightman/pytorch-image-models\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">pytorch-image-models</a> :: PyTorch image models, scripts, pretrained weights :: <a href=\"https://github.com/rwightman/pytorch-image-models/pull/1058\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#1058</a>, <a href=\"https://github.com/rwightman/pytorch-image-models/pull/1069\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#1069</a></li>\n<li><a href=\"https://github.com/facebookresearch/deit\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">deit</a> :: DeiT: Data-efficient Image Transformers :: <a href=\"https://github.com/facebookresearch/deit/pull/140\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#140</a>, <a href=\"https://github.com/facebookresearch/deit/pull/147\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#147</a>, <a href=\"https://github.com/facebookresearch/deit/pull/148\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#148</a></li>\n<li><a href=\"https://github.com/facebookresearch/madgrad\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">MADGRAD</a> :: MADGRAD Optimization Method :: <a href=\"https://github.com/facebookresearch/madgrad/pull/11\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#11</a></li>\n<li><a href=\"https://github.com/martinsbruveris/tensorflow-image-models\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">tensorflow-image-models</a> :: TensorFlow Image Models (tfimm) is a collection of image models with pretrained weights, obtained by porting architectures from timm to TensorFlow :: <a href=\"https://github.com/martinsbruveris/tensorflow-image-models/pull/61\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#61</a></li>\n<li><a href=\"https://github.com/PINTO0309/onnx2tf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">onnx2tf</a> :: Self-Created Tools to convert ONNX files (NCHW) to TensorFlow/TFLite/Keras format (NHWC). The purpose of this tool is to solve the massive Transpose extrapolation problem in onnx-tensorflow (onnx-tf) :: <a href=\"https://github.com/PINTO0309/onnx2tf/pull/259\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#259</a></li>\n<li><a href=\"https://github.com/facebookresearch/dadaptation\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">dadaptation</a> :: D-Adaptation for SGD, Adam and AdaGrad :: <a href=\"https://github.com/facebookresearch/dadaptation/pull/21\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#21</a></li>\n<li><a href=\"https://github.com/dabeaz-course/python-mastery\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">python-mastery</a> :: Advanced Python Mastery :: <a href=\"https://github.com/dabeaz-course/python-mastery/pull/14\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#14</a></li>\n<li><a href=\"https://github.com/huggingface/text-embeddings-inference\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">text-embedding-inference</a> :: A blazing fast inference solution for text embeddings model :: <a href=\"https://github.com/huggingface/text-embeddings-inference/pull/62\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#62</a>, <a href=\"https://github.com/huggingface/text-embeddings-inference/pull/285\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#285</a>, <a href=\"https://github.com/huggingface/text-embeddings-inference/pull/343\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#343</a>, <a href=\"https://github.com/huggingface/text-embeddings-inference/pull/360\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#360</a>, <a href=\"https://github.com/huggingface/text-embeddings-inference/pull/361\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#361</a>, <a href=\"https://github.com/huggingface/text-embeddings-inference/pull/441\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#441</a></li>\n<li><a href=\"https://github.com/langchain-ai/langchain\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">langchain-ai</a> :: Build context-aware reasoning applications :: <a href=\"https://github.com/langchain-ai/langchain/pull/18839\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#18839</a>, <a href=\"https://github.com/langchain-ai/langchain/pull/20057\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#20057</a></li>\n<li><a href=\"https://github.com/qdrant/qdrant\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">qdrant</a> :: Qdrant - High-performance, massive-scale Vector Database for the next generation of AI :: <a href=\"https://github.com/qdrant/qdrant/pull/3982\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#3982</a></li>\n<li><a href=\"https://github.com/qdrant/bfb\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">bfb</a> :: <em>high-load</em> benchmarking tool :: <a href=\"https://github.com/qdrant/bfb/pull/37\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#37</a></li>\n<li><a href=\"https://github.com/qdrant/qdrant-web-ui\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">qdrant-web-ui</a> :: Self-hosted web UI for Qdrant :: <a href=\"https://github.com/qdrant/qdrant-web-ui/pull/191\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">#191</a></li>\n</ul>\n<h3 id=\"plug-ins\" style=\"position:relative;\"><a href=\"#plug-ins\" aria-label=\"plug ins permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Plug-Ins</h3>\n<p>IDA-pro plug-in - Golang ELF binary (x86, x86-64), RTTI parser</p>\n<ul>\n<li>Recover stripped symbols &#x26; information and patch byte-codes for being able to hex-ray</li>\n</ul>\n<h2 id=\"security-hacking\" style=\"position:relative;\"><a href=\"#security-hacking\" aria-label=\"security hacking permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Security, Hacking</h2>\n<h3 id=\"ctfs-conferences\" style=\"position:relative;\"><a href=\"#ctfs-conferences\" aria-label=\"ctfs conferences permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CTFs, Conferences</h3>\n<ul>\n<li><a href=\"http://powerofcommunity.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">POC</a> 2016 Conference Staff</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 15 CTF Staff, Challenge Maker</li>\n<li><a href=\"https://www.codegate.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">CodeGate</a> 2017 OpenCTF Staff, Challenge Maker</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 16 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://www.powerofxx.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">POX</a> 2017 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://www.powerofxx.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">KID</a> 2017 CTF Staff, Challenge Maker</li>\n<li>Belluminar 2017 CTF Staff</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 17 CTF Staff, Challenge Maker</li>\n<li><a href=\"http://hackingcamp.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">HackingCamp</a> 18 CTF Staff, Challenge Maker</li>\n</ul>\n<h3 id=\"teams\" style=\"position:relative;\"><a href=\"#teams\" aria-label=\"teams permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Teams</h3>\n<p>Hacking Team, <a href=\"http://f1ay.com/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>Fl4y</strong></a>. <strong>Since 2017.07 ~</strong></p>\n<p>Hacking Team, <a href=\"https://demonteam.org/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><strong>Demon</strong></a> by <a href=\"http://powerofcommunity.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\"><em>POC</em></a>. <strong>Since 2014.02 ~ 2018.08</strong></p>\n<hr>\n<h2 id=\"educations\" style=\"position:relative;\"><a href=\"#educations\" aria-label=\"educations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Educations</h2>\n<p>BS in Computer Engineering from <a href=\"https://www.koreatech.ac.kr/eng.do\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">KUT</a></p>\n<h2 id=\"presentations\" style=\"position:relative;\"><a href=\"#presentations\" aria-label=\"presentations permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Presentations</h2>\n<h3 id=\"2018\" style=\"position:relative;\"><a href=\"#2018\" aria-label=\"2018 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2018</h3>\n<p>[2] Artificial Intelligence ZeroToAll, Apr 2018.</p>\n<p>[1] Machine Learning ZeroToAll, Mar 2018.</p>\n<h3 id=\"2015\" style=\"position:relative;\"><a href=\"#2015\" aria-label=\"2015 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2015</h3>\n<p>[1] Polymorphic Virus VS AV Detection, Oct 2015.</p>\n<h3 id=\"2014\" style=\"position:relative;\"><a href=\"#2014\" aria-label=\"2014 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2014</h3>\n<p>[1] Network Sniffing &#x26; Detection, Oct, 2014.</p>","excerpt":"Profile Service machine learning products in various domains, Audio & Speech, Vision, NLP, Recommendation Systems, Tabular, LLM application…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#profile\">Profile</a></p>\n</li>\n<li>\n<p><a href=\"#links\">Links</a></p>\n</li>\n<li>\n<p><a href=\"#challenges--awards\">Challenges &#x26; Awards</a></p>\n<ul>\n<li><a href=\"#machine-learning\">Machine Learning</a></li>\n<li><a href=\"#hacking\">Hacking</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#work-experience\">Work Experience</a></p>\n<ul>\n<li>\n<p><a href=\"#company\">Company</a></p>\n<ul>\n<li><a href=\"#machine-learning-engineer-sionic-ai-20231023--20240705\"><em>Machine Learning Engineer</em>, <strong>Sionic AI</strong>, <strong>(2023.10.23 ~ 2024.07.05)</strong></a></li>\n<li><a href=\"#data-scientist-toss-core-20211206--20230927\"><em>Data Scientist</em>, <strong>Toss core</strong>, <strong>(2021.12.06 ~ 2023.09.27)</strong></a></li>\n<li><a href=\"#machine-learning-researcher-watcha-20200622--20211203\"><em>Machine Learning Researcher</em>, <strong>Watcha</strong>, <strong>(2020.06.22 ~ 2021.12.03)</strong></a></li>\n<li><a href=\"#machine-learning-engineer-rainist-20191111--20200619\"><em>Machine Learning Engineer</em>, <strong>Rainist</strong>, <strong>(2019.11.11 ~ 2020.06.19)</strong></a></li>\n<li><a href=\"#machine-learning-engineer-voyagerx-20190107--20191004\"><em>Machine Learning Engineer</em>, <strong>VoyagerX</strong>, <strong>(2019.01.07 ~ 2019.10.04)</strong></a></li>\n<li><a href=\"#penetration-tester-elcid-201607--201608\"><em>Penetration Tester</em>, <strong>ELCID</strong>, <strong>(2016.07 ~ 2016.08)</strong></a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#out-sourcing\">Out Sourcing</a></p>\n</li>\n<li>\n<p><a href=\"#lab\">Lab</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#publications\">Publications</a></p>\n<ul>\n<li><a href=\"#paper\">Paper</a></li>\n<li><a href=\"#conferencesworkshops\">Conferences/Workshops</a></li>\n<li><a href=\"#journals\">Journals</a></li>\n<li><a href=\"#posts\">Posts</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#personal-projects\">Personal Projects</a></p>\n<ul>\n<li>\n<p><a href=\"#machinedeep-learning\">Machine/Deep Learning</a></p>\n<ul>\n<li><a href=\"#generative-models\">Generative Models</a></li>\n<li><a href=\"#super-resolution\">Super Resolution</a></li>\n<li><a href=\"#i2i-translation\">I2I Translation</a></li>\n<li><a href=\"#style-transfer\">Style Transfer</a></li>\n<li><a href=\"#text-classificationgeneration\">Text Classification/Generation</a></li>\n<li><a href=\"#speech-synthesis\">Speech Synthesis</a></li>\n<li><a href=\"#optimizer\">Optimizer</a></li>\n<li><a href=\"#rl\">R.L</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#open-source-contributions\">Open Source Contributions</a></p>\n</li>\n<li>\n<p><a href=\"#plug-ins\">Plug-Ins</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#security-hacking\">Security, Hacking</a></p>\n<ul>\n<li><a href=\"#ctfs-conferences\">CTFs, Conferences</a></li>\n<li><a href=\"#teams\">Teams</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#educations\">Educations</a></p>\n</li>\n<li>\n<p><a href=\"#presentations\">Presentations</a></p>\n<ul>\n<li><a href=\"#2018\">2018</a></li>\n<li><a href=\"#2015\">2015</a></li>\n<li><a href=\"#2014\">2014</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/about/"},"frontmatter":{"title":"About ME","date":"Dec 12, 2020","tags":["About","CV"],"keywords":["cv","resume","aboutme"],"update":"Nov 30, 2024"},"timeToRead":9}},"pageContext":{"slug":"/about/","series":[],"lastmod":"2024-11-30"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}