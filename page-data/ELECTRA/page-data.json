{"componentChunkName":"component---src-templates-post-tsx","path":"/ELECTRA/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>이번에 리뷰할 논문은 <em>ELECTRA</em> 란 google ai 에서 3월에 발표한 논문인데, 재밌는 approach 를 하고 있어서 가져와 봤습니다.</p>\n<p>ELECTRA paper : <a href=\"https://openreview.net/pdf?id=r1xMH1BtvB\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">OpenReview</a></p>\n<p>google ai blog : <a href=\"https://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">blog</a></p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>이전 trend 들 5 개 정도만...</p>\n<p>BERT : <a href=\"https://arxiv.org/pdf/1810.04805.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a></p>\n<p>XLNET : <a href=\"https://arxiv.org/pdf/1906.08237.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a></p>\n<p>RoBERTa : <a href=\"https://arxiv.org/pdf/1907.11692.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a></p>\n<p>ALBERT : <a href=\"https://arxiv.org/pdf/1909.11942.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a></p>\n<p>T5 : <a href=\"https://arxiv.org/pdf/1910.10683.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a></p>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>간단하게 이번 <em>ELECTRA</em> paper 에서 이전과 다른 점 3 가지를 정리하면</p>\n<ol>\n<li>\n<p>input 을 masking 하는게 아닌 generator 로 token 생성 (masking 효과)</p>\n</li>\n<li>\n<p>token ID 를 예측하는 게 아닌 discriminator 로 각 token 이 generated 됐는지 예측</p>\n</li>\n<li>\n<p>기존 MLM 보다 더 좋음. (small MLM, ...)</p>\n</li>\n</ol>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<h3 id=\"previous-story\" style=\"position:relative;\"><a href=\"#previous-story\" aria-label=\"previous story permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Previous Story</h3>\n<p>이전 LM 들을 보면 DAE 형태로 학습을 하고 (masked input 을 복원), <em>BERT</em> 같은 경우에는 masking 때문에 example 당 token 의 15% 밖에 학습이 안돼서\n학습 비용이 꽤 컸어요.</p>\n<p>그래서 위 문제를 해결하려고 <em>ELECTRA</em>에서 replaced token detection task 를 제안했는데,\nmasking 하는 대신, 작은 MLM (masked language model ~ generator) 으로 생성된 output 으로 일부 교체 하고 discriminator 를 둬서 이게 replaced token or not 인지를 예측하게 학습했습니다.</p>\n<p>장점 으로는</p>\n<ul>\n<li>MLM 자제가 작은걸 사용 -> 연산이 더 빨라짐</li>\n<li>masked 된 부분만이 아닌 전체 token 에 대해서 discriminate -> 학습 효율 증가</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ba24ab4614d13b7326c0087955f7257e/c5394/disc_gen_overview.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 27.027027027027025%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAA4klEQVQY0zXQwW6DMBAEUP7/s5oLHDglt5AFbIzXaztgy2tcQGrV0r7zSKOZ6jzPsm055xhjzjmltO/7cRyZGQDe3pdSrLXMHGNMKa3r6r2/ktVnKRqRiMZxJKKu65xzxhjr/iil9Dx//dv3HQCGcZCTrAziNE2I2AMgIgDc74+6rn9q328immfdPZ9t2zZN83G7SSEBAF6voe+rGKPW2lprjFmWVQgxSdkPg1LKe28tGSLn3LZt67qEGEspUkrxq2Jm51wIgYiWZVFKMWdmDiFcCxFRa32e5/VFSkkIgVqTtd998BMlY9VfjQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/ba24ab4614d13b7326c0087955f7257e/fcda8/disc_gen_overview.png\"\n        srcset=\"/static/ba24ab4614d13b7326c0087955f7257e/12f09/disc_gen_overview.png 148w,\n/static/ba24ab4614d13b7326c0087955f7257e/e4a3f/disc_gen_overview.png 295w,\n/static/ba24ab4614d13b7326c0087955f7257e/fcda8/disc_gen_overview.png 590w,\n/static/ba24ab4614d13b7326c0087955f7257e/efc66/disc_gen_overview.png 885w,\n/static/ba24ab4614d13b7326c0087955f7257e/c83ae/disc_gen_overview.png 1180w,\n/static/ba24ab4614d13b7326c0087955f7257e/c5394/disc_gen_overview.png 1535w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"method\" style=\"position:relative;\"><a href=\"#method\" aria-label=\"method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Method</h3>\n<p>generator / discriminator 로 GAN 과 유사해 보이는데, 해당 network 구조만 그렇고\n실제로 <em>adversarial</em> 하게 훈련하지는 않습니다.</p>\n<p>각 network encoder 는 transformer 로 구성되어있고,</p>\n<p>generator 는 각 token 에 대한 softmax 값을 output 로 주고</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>p</mi><mi>G</mi></msub><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><mi mathvariant=\"normal\">∥</mi><mi>x</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mo stretchy=\"false\">(</mo><msub><mi>x</mi><mi>t</mi></msub><msup><mo stretchy=\"false\">)</mo><mi>T</mi></msup><msub><mi>h</mi><mi>G</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><msub><mo stretchy=\"false\">)</mo><mi>t</mi></msub><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><msub><mo>∑</mo><mover accent=\"true\"><mi>x</mi><mo>˙</mo></mover></msub><mi>e</mi><mi>x</mi><mi>p</mi><mo stretchy=\"false\">(</mo><mi>e</mi><mo stretchy=\"false\">(</mo><mover accent=\"true\"><mi>x</mi><mo>˙</mo></mover><msup><mo stretchy=\"false\">)</mo><mi>T</mi></msup><msub><mi>h</mi><mi>G</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><msub><mo stretchy=\"false\">)</mo><mi>t</mi></msub></mrow><annotation encoding=\"application/x-tex\">p_G(x_t\\|x) = exp(e(x_t)^T h_G(x)_t) / \\sum_{\\dot{x}} exp(e(\\dot{x})^T h_G(x)_t</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">p</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">G</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∥</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.141em;vertical-align:-0.2997em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">G</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mord\">/</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mop\"><span class=\"mop op-symbol small-op\" style=\"position:relative;top:0em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1678em;\"><span style=\"top:-2.4003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord accent mtight\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6679em;\"><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"mord mathnormal mtight\">x</span></span><span style=\"top:-2.7em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"accent-body\" style=\"left:-0.1111em;\"><span class=\"mord mtight\">˙</span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">e</span><span class=\"mord mathnormal\">x</span><span class=\"mord mathnormal\">p</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">e</span><span class=\"mopen\">(</span><span class=\"mord accent\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.6679em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord mathnormal\">x</span></span><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.1111em;\"><span class=\"mord\">˙</span></span></span></span></span></span></span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">G</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span></span></p>\n</blockquote>\n<p>discriminator 는 각 token 에 대해 replaced / not replaced 를 예측합니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi><mo stretchy=\"false\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>t</mi><mo stretchy=\"false\">)</mo><mo>=</mo><mi>s</mi><mi>i</mi><mi>g</mi><mi>m</mi><mi>o</mi><mi>i</mi><mi>d</mi><mo stretchy=\"false\">(</mo><msup><mi>w</mi><mi>T</mi></msup><msub><mi>h</mi><mi>D</mi></msub><mo stretchy=\"false\">(</mo><mi>x</mi><msub><mo stretchy=\"false\">)</mo><mi>t</mi></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">D(x, t) = sigmoid(w^T h_D(x)_t)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">D</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">t</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0913em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">s</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">o</span><span class=\"mord mathnormal\">i</span><span class=\"mord mathnormal\">d</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.13889em;\">T</span></span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathnormal\">h</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3283em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">x</span><span class=\"mclose\"><span class=\"mclose\">)</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">t</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n</blockquote>\n<h3 id=\"model-extensions\" style=\"position:relative;\"><a href=\"#model-extensions\" aria-label=\"model extensions permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model Extensions</h3>\n<h4 id=\"weight-sharing\" style=\"position:relative;\"><a href=\"#weight-sharing\" aria-label=\"weight sharing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Weight Sharing</h4>\n<ul>\n<li>generator 하고 discriminator 크기가 같으면 weight sharing</li>\n<li>그런데 실험 결과로는 크기가 같지 않고 small generator 를 사용하는게 훨 좋았음</li>\n<li>그래서 small generator 를 사용하는 경우엔 token embedding table 만 weight sharing 을 함</li>\n</ul>\n<h4 id=\"small-generators-mlm\" style=\"position:relative;\"><a href=\"#small-generators-mlm\" aria-label=\"small generators mlm permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Small Generators (MLM)</h4>\n<ul>\n<li>generator / discriminator 크기가 같으면 기존 MLM 보다 2 배 커짐</li>\n<li>주로 generator 가 discriminator 크기의 x0.25 ~ x0.5 일 때 괜춘함</li>\n<li>간단한 uni-gram generator 도 시도를 해봄</li>\n<li>adversarial 하게 훈련하는 건 discriminator 에게 꽤 challenging 한 일이여서, 실제 실험결과도 성능이 덜 좋음</li>\n</ul>\n<h4 id=\"training-algorithms\" style=\"position:relative;\"><a href=\"#training-algorithms\" aria-label=\"training algorithms permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Training Algorithms</h4>\n<ol>\n<li>처음 n steps 는 generator 만 훈련</li>\n<li>generator weight 로 discriminator 초기화 -> generator freezing 후 discriminator 만 훈련</li>\n</ol>\n<h3 id=\"small-models\" style=\"position:relative;\"><a href=\"#small-models\" aria-label=\"small models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Small Models</h3>\n<p>효과적으로 훈련하려고 아래와 같은 hyper-parameters 사용</p>\n<ol>\n<li>sequence length (512 -> 128)</li>\n<li>batch size (256 -> 128)</li>\n<li>hidden dims (768 -> 256)</li>\n<li>token embedding (768 -> 128)</li>\n</ol>\n<p>아래 Exp Result 에 결과첨부</p>\n<h3 id=\"large-models\" style=\"position:relative;\"><a href=\"#large-models\" aria-label=\"large models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Large Models</h3>\n<p>BERT-large 와 똑같은 size, 하지만 training time 은 더 오래걸림.</p>\n<p>batch size 는 2048, XLNET pre-training data 도 사용했다고 하네요. (RoBERTa 훈련할 때 사용한 데이터와 비슷)</p>\n<h3 id=\"efficiency-analysis\" style=\"position:relative;\"><a href=\"#efficiency-analysis\" aria-label=\"efficiency analysis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Efficiency Analysis</h3>\n<p>크게 3 가지인데</p>\n<ol>\n<li>\n<p>ELECTRA 15% : discriminator loss 를 전체 token 이 아니라 masking 된 15% 에만 계산</p>\n</li>\n<li>\n<p>Replace MLM : 마스킹 할 token 을 <code class=\"language-text\">[MASK]</code> token 으로 replace 함</p>\n</li>\n<li>\n<p>All-Token MLM : 위에서 masking 된 token 을 predict, discriminator 에선 mask 에 대해서만 예측이 아닌 모든 token 에 대해 예측</p>\n</li>\n</ol>\n<h2 id=\"experiment-result\" style=\"position:relative;\"><a href=\"#experiment-result\" aria-label=\"experiment result permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiment Result</h2>\n<h3 id=\"small-models-on-the-glue-dev-set\" style=\"position:relative;\"><a href=\"#small-models-on-the-glue-dev-set\" aria-label=\"small models on the glue dev set permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>small models on the GLUE dev set</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/275f1d030323eac3e06b4514e83eacd1/3a188/small_models_glue_dev_set.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 32.43243243243243%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAIAAABM9SnKAAAACXBIWXMAAA7DAAAOwwHHb6hkAAABFUlEQVQY0yWP23KDMBBD+f8vy1u6hhIuttf4EjNuEsNMCCYsQ0uqJ430cKQMAJRS0zSFEIqiAADGmJCyLEsAcM6dz19KqTzPAaAoitPpxDmvq9p7nzVNE0LYDpGUknNujNn3vfdeKTWOI0o5TZMQoq4bABBSzPPsvV/XNaurijEWY0wpdapDxOv1SkR9399utyUlRByGwRiLiE3TTK8XEVlrl2XJnHNCcEQZ4+CsU6oLIRCRc857P89zp/Xz+dRaG60vl8vjEdd1NcaklLJxHKuq4pwTrfqjn5/bvu///jNHLe83ImrdMWD3+/041fdEdJC/y5KxI+W8bTl31m7bZq3VH2bbtnEY2qNrWZ4/4kHWWv/N/gUe9UM2xO9OlQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/275f1d030323eac3e06b4514e83eacd1/fcda8/small_models_glue_dev_set.png\"\n        srcset=\"/static/275f1d030323eac3e06b4514e83eacd1/12f09/small_models_glue_dev_set.png 148w,\n/static/275f1d030323eac3e06b4514e83eacd1/e4a3f/small_models_glue_dev_set.png 295w,\n/static/275f1d030323eac3e06b4514e83eacd1/fcda8/small_models_glue_dev_set.png 590w,\n/static/275f1d030323eac3e06b4514e83eacd1/efc66/small_models_glue_dev_set.png 885w,\n/static/275f1d030323eac3e06b4514e83eacd1/c83ae/small_models_glue_dev_set.png 1180w,\n/static/275f1d030323eac3e06b4514e83eacd1/3a188/small_models_glue_dev_set.png 1623w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>가성비 굳!</p>\n<h3 id=\"squad\" style=\"position:relative;\"><a href=\"#squad\" aria-label=\"squad permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>SQuAD</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/272890c0090ddb1019fcc99f3caf28d0/701e9/squad_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 40.54054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAIAAAB2/0i6AAAACXBIWXMAAA7DAAAOwwHHb6hkAAABVUlEQVQY0zXQ0W6DMAxAUf7/31rGUCGQBgglCEIcxyRANzYxlWrn0bKlK0ecl51SROSc6/u+KArOueoU57xpmvgaZ1lW1zVj7HK5pGl6Dq9Jktxut6gsirZt13X9+flFa4WoqqoyxrRSaq1Vp/SkjTHuXwhBa+2cm+c5+kySPGfLshzHQeSyLJNSErm7uCNaALDWOnSISETocF1XYyZr7euYl69OIjqOA61ljFVVhYhCCGutniYi8j68t7XW27Ytp+fzGSVJEscfnPNt24goy3IhBCIyxvxJn0II3gfVdSEsFiwieu+jSoiyLL33+74jWimbYRiInJQSALTW7/JpmgBgHEd0bjohYpTn+fvD31/f3nvOed/38zzXde2cMwAWX8EAMM8EYPZ9P/5Fny9pfL1K2QJAmqZCCGNMnudd1zVS9n0/jmNRFFLKgrFhGB6Ph1LKGPMHwpiyhilcmUEAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/272890c0090ddb1019fcc99f3caf28d0/fcda8/squad_benchmark.png\"\n        srcset=\"/static/272890c0090ddb1019fcc99f3caf28d0/12f09/squad_benchmark.png 148w,\n/static/272890c0090ddb1019fcc99f3caf28d0/e4a3f/squad_benchmark.png 295w,\n/static/272890c0090ddb1019fcc99f3caf28d0/fcda8/squad_benchmark.png 590w,\n/static/272890c0090ddb1019fcc99f3caf28d0/efc66/squad_benchmark.png 885w,\n/static/272890c0090ddb1019fcc99f3caf28d0/c83ae/squad_benchmark.png 1180w,\n/static/272890c0090ddb1019fcc99f3caf28d0/701e9/squad_benchmark.png 1780w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"efficiency\" style=\"position:relative;\"><a href=\"#efficiency\" aria-label=\"efficiency permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Efficiency</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/22fdafaae9820ae0b5973b665aad055c/087e3/efficiency_exp_glue_score.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 14.18918918918919%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAIAAAAcOLh5AAAACXBIWXMAAA7DAAAOwwHHb6hkAAAAl0lEQVQI1yXLQQ6DIBAAQP//NS9arUIs0aWLwKLRpVYvkDRt5z5FWZbOuRDCsixPretbLaUcx7FpGiFE13VKPdqvu1Kq7/u2bYdhmGCqqqoQUj4Rmfk8zxACIl7X5ZzznmKMx/Emonme4ysy74hm2zZmXtcVAIqcc0op52yMoUDWWgBtfoi81hoRvffWWiICmHbe/yWl9AHgZaH3slVM9AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/22fdafaae9820ae0b5973b665aad055c/fcda8/efficiency_exp_glue_score.png\"\n        srcset=\"/static/22fdafaae9820ae0b5973b665aad055c/12f09/efficiency_exp_glue_score.png 148w,\n/static/22fdafaae9820ae0b5973b665aad055c/e4a3f/efficiency_exp_glue_score.png 295w,\n/static/22fdafaae9820ae0b5973b665aad055c/fcda8/efficiency_exp_glue_score.png 590w,\n/static/22fdafaae9820ae0b5973b665aad055c/efc66/efficiency_exp_glue_score.png 885w,\n/static/22fdafaae9820ae0b5973b665aad055c/c83ae/efficiency_exp_glue_score.png 1180w,\n/static/22fdafaae9820ae0b5973b665aad055c/087e3/efficiency_exp_glue_score.png 1575w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>결론 : 굳</p>","excerpt":"TL;DR 이번에 리뷰할 논문은 ELECTRA 란 google ai 에서 3월에 발표한 논문인데, 재밌는 approach 를 하고 있어서 가져와 봤습니다. ELECTRA paper : OpenReview google ai blog : blog Rel…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#introduction\">Introduction</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li>\n<p><a href=\"#previous-story\">Previous Story</a></p>\n</li>\n<li>\n<p><a href=\"#method\">Method</a></p>\n</li>\n<li>\n<p><a href=\"#model-extensions\">Model Extensions</a></p>\n<ul>\n<li><a href=\"#weight-sharing\">Weight Sharing</a></li>\n<li><a href=\"#small-generators-mlm\">Small Generators (MLM)</a></li>\n<li><a href=\"#training-algorithms\">Training Algorithms</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#small-models\">Small Models</a></p>\n</li>\n<li>\n<p><a href=\"#large-models\">Large Models</a></p>\n</li>\n<li>\n<p><a href=\"#efficiency-analysis\">Efficiency Analysis</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#experiment-result\">Experiment Result</a></p>\n<ul>\n<li><a href=\"#small-models-on-the-glue-dev-set\">small models on the GLUE dev set</a></li>\n<li><a href=\"#squad\">SQuAD</a></li>\n<li><a href=\"#efficiency\">Efficiency</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/ELECTRA/"},"frontmatter":{"title":"ELECTRA Pre-training Text Encoders as Discriminators Rather Than Generators","date":"Apr 11, 2020","tags":["Deep-Learning"],"keywords":["NLP","LM","PreTrained"],"update":"Apr 11, 2020"},"timeToRead":2}},"pageContext":{"slug":"/ELECTRA/","series":[],"lastmod":"2020-04-11"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}