{"componentChunkName":"component---src-templates-post-tsx","path":"/ConSinGAN/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>이전에 리뷰했던 SinGAN 후속 논문이 나왔는데, 우연히 github 메인 페이지 오른쪽에 보면 Explore repositories가 있는데, 여기에 추천 repo로 떠서 우연히 보게 됐습니다.</p>\n<p>저자분께서 짧은 요약을 블로그에 정리해서, 논문 대신 아래 글을 읽어도 충분할 듯하고, SinGAN 이랑 비교/대조하는 부분이 있어서 SinGAN 논문도 읽어보시는 걸 추천드려요.</p>\n<p>official summary : <a href=\"https://www.tobiashinz.com/2020/03/24/improved-techniques-for-training-single-image-gans.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">blog</a></p>\n<p>paper : <a href=\"https://openaccess.thecvf.com/content/WACV2021/papers/Hinz_Improved_Techniques_for_Training_Single-Image_GANs_WACV_2021_paper.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">WACV21</a></p>\n<p>code : <a href=\"https://github.com/tohinz/ConSinGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>요 논문과 관련높은 references</p>\n<ol>\n<li>SinGAN : <a href=\"https://arxiv.org/pdf/1905.01164.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a>, <a href=\"https://kozistr.tech/SinGAN/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">my review</a></li>\n<li>ProGAN : <a href=\"https://arxiv.org/pdf/1710.10196.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a></li>\n</ol>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>논문을 읽기 전, 전반적인 느낌은 논문 제목부터 Con<strong>SinGAN</strong>인 것처럼, SinGAN에 여러 techniques를 추가해 성능을 improved 한 느낌입니다.\n또, Con (Concurrent)라 명칭 한걸 보니, 각 generators 를 concurrent 하게 학습한다는 느낌을 받았는데, 자세한 건 논문을 읽어봐야겠어요.</p>\n<p>이 논문에서, 크게 <strong>3가지의 main contributions</strong> 이 있습니다.</p>\n<ol>\n<li>architecture &#x26; optimization</li>\n<li>이미지 rescaling (for multi-stage training)</li>\n<li>fine-tuning</li>\n</ol>\n<h2 id=\"methodology\" style=\"position:relative;\"><a href=\"#methodology\" aria-label=\"methodology permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Methodology</h2>\n<h3 id=\"multi-stage-training\" style=\"position:relative;\"><a href=\"#multi-stage-training\" aria-label=\"multi stage training permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Multi-Stage Training</h3>\n<h4 id=\"random-noise\" style=\"position:relative;\"><a href=\"#random-noise\" aria-label=\"random noise permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Random Noise</h4>\n<p>model architecture 같은 경우 <strong>SinGAN</strong>과 대조를 하는데,\n<strong>SinGAN</strong>도 multi-stage generators 를 가지고 있는데, 가장 낮은 resolution에 해당하는 generator만 unconditional generator 라고 말하고 있습니다.</p>\n<p>즉, <strong>SinGAN</strong> 은 최초에만 noise (~= z latent vector)로 부터 이미지를 생성하고, 이후 stages 는 random 한 요소가 들어가지 않는다는 말입니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a092b4cf0345ae01d0296df7f9598f0d/f8544/architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 40.54054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABx0lEQVQoz22Sy2sTYRTF87+KG3XnUgQXLgQpLqRQELUUdNWFWmhau4gxbWLVijYxtXYyzzTJZOK8m3lkZn5+MzVUwQuXy/c695xzvxoi4jgmDEPMqUW79Y56+zubjR4HjSa6MS6vkGcZRZGzjKK4rJnYH5sWnu9X69rlYcFisSBOElzH5txyUcYOI31IPL/g75hHEVEUU2QpaZqKxzk9eYIXzq8AkxLIdbFth37vG+1jheZRH8s8ZetQY6++y8rDVYIo4/HKKk+ebbKx8wVNNIyiOb9sHz8IrgBL2iXDQMg+/dGnO5jw9afOUO/z9pPE4X6H9bUNoiTj5fMXvH61Q6ur43ueAEwIbIX5xR/JxdKM/0QuLCvSfyWXLnqhAIlyorSo7ixClUUSVr7WlkMpJVvWjKOPHXY7J7xpfmY66vJ0+xhn0mN9q4VkTHG8kPt37nLj+k329rtVk9HYxBVsK4a5aFHKLbOctDw440Q16Q2GmKMztg/6BK5BvSUaCK/CIOTBvUfcvnaL940PFYiqqoKMVVlXm81mSJKELMsYhoGm6eiagqGpDGQVXZGqqgwkVEVmPJkINr5QFIj0cBxHDNOuFPri6/wGO7pOaswLYwoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"architecture\"\n        title=\"architecture\"\n        src=\"/static/a092b4cf0345ae01d0296df7f9598f0d/fcda8/architecture.png\"\n        srcset=\"/static/a092b4cf0345ae01d0296df7f9598f0d/12f09/architecture.png 148w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/e4a3f/architecture.png 295w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/fcda8/architecture.png 590w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/efc66/architecture.png 885w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/c83ae/architecture.png 1180w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/f8544/architecture.png 1811w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>위는 ConSinGAN 의 model architecture 인데, <strong>diversity</strong>를 높히기 위해 매 stage 마다 이전 stage 의 생성 결과와 random noise가 같이 합쳐서 들어가고 있습니다.</p>\n<h4 id=\"freeze-previous-generator\" style=\"position:relative;\"><a href=\"#freeze-previous-generator\" aria-label=\"freeze previous generator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Freeze Previous Generator</h4>\n<p>그리고, 현재 (n) stage를 훈련할 때 이전 (n - 1) stage의 generator를 freeze 한다는 차이도 있습니다.</p>\n<p>이런 방식으로 concurrently 하게 한 번에 여러 stages 의 generator 를 학습하는데, 한 번에 모든 stages의 generator를 학습하면 overfitting 가능성이 커지니,\n<strong>적당히 한 번에 3 stages</strong> 를 훈련한다고 합니다.</p>\n<h4 id=\"learning-rate\" style=\"position:relative;\"><a href=\"#learning-rate\" aria-label=\"learning rate permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Learning Rate</h4>\n<p>또한, 한 번에 3개의 generators 를 훈련하는데, 각 stage 마다 다른 learning rate 를 사용했습니다.</p>\n<p>예를 들어, Generator (n - 2), (n - 1), (n) 을 학습한다면, (0.01 * lr), (0.1 * lr), (lr) 식으로 (10배 씩 decay 해) 사용했다 합니다.</p>\n<p>물론, 이렇게 learning rate 를 사용하는 것에 대한 이야기도 했는데, </p>\n<ol>\n<li>lower generators 에서 higher learning rate 사용 : training image 에 더 similar 한 image 를 만들겠다.</li>\n<li>lower generators 에서 lower learning rate 사용   : 더 높은 diversity 를 가져가겠다 (~= maybe leads to worse quality) </li>\n</ol>\n<p>이렇게 말하면서, learning rate 란 artifact 에 대한 sample 변화도 보여줬습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8604db43f1177d6edb47bf4183d11a0c/7da7d/changing_by_lr.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 36.486486486486484%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB3ElEQVQozyWQW28SARCF+ak+6Is+GH2qPmi0tdpiAV2oFbCAFCgNsNzpLstlt+WW3oTSrkA0DYmmalCxUPpQ83VbJjnJnGTmy5kx/fx7zj1HhA+bFSzxbZ74kpSP+twye2h0v3HbGiBaaXI2HLBoncfj/0gqKzJvfsGS3YrFbjFkw2ZfxO1fwzT4N+bh+wi+fA17qspcKEfxsM8di49K5zt3hTCJepvR8BezL2ewrTjYEAM8eHzfgM4y9+oRzxae83RuBsG5jOny/yVZpUFC3kFMq7jDKmuREs6gQlCsIKxmKNWPuK5y7RDHukax0eFtoIgrso0/UUMIllmN1/DGq5iuBxtKhlRcRIqu4RLe4HNYCLhXWDXOcdpeo6pbN8DdZov1eAqtvkM4kSEQFRFzMqFYglguT1JSpsBCeYdoqkgqv4fTv4nbG8MVUoyfJI2ESbTGNOH2vo49lEeutlgOF3gXzuNLaEav4E1uGSnVKbClptFkYzG9QcRlJuJeIuoTiHkE/I4Faqp0A2y1m8gFid1Pe8hFiWRGpKgVyMoZJMOXtNIUOJ6MmFyMGY3P6PR0PnePDbXpdHUDcsCXrz1OT3/Q6x2j6wecnHTRj/fp9ztMJn8M/eb8fMDFxZAr/8m9VQIxICYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"lr\"\n        title=\"lr\"\n        src=\"/static/8604db43f1177d6edb47bf4183d11a0c/fcda8/changing_by_lr.png\"\n        srcset=\"/static/8604db43f1177d6edb47bf4183d11a0c/12f09/changing_by_lr.png 148w,\n/static/8604db43f1177d6edb47bf4183d11a0c/e4a3f/changing_by_lr.png 295w,\n/static/8604db43f1177d6edb47bf4183d11a0c/fcda8/changing_by_lr.png 590w,\n/static/8604db43f1177d6edb47bf4183d11a0c/efc66/changing_by_lr.png 885w,\n/static/8604db43f1177d6edb47bf4183d11a0c/c83ae/changing_by_lr.png 1180w,\n/static/8604db43f1177d6edb47bf4183d11a0c/7da7d/changing_by_lr.png 2120w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h4 id=\"discriminator\" style=\"position:relative;\"><a href=\"#discriminator\" aria-label=\"discriminator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Discriminator</h4>\n<p>Discriminator로 Patch Discriminator 를 사용하는 것에 대해, 이미지의 일부로만 판단하면 global perspective 에서 real or fake 확인이 어렵다는 점을 언급합니다.</p>\n<h3 id=\"rescaling-image\" style=\"position:relative;\"><a href=\"#rescaling-image\" aria-label=\"rescaling image permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Rescaling Image</h3>\n<p>각 generators 에 들어가는 image resolution 에 대한 내용인데, multi-stage scheme 으로 여러 resolution 으로 progressive 하게 generate 하는 것은 좋은데,\n그럼 이걸 얼마나 해야 하냐? 라는 의문을 제기합니다.</p>\n<p>SinGAN 같은 경우엔 주로 8 ~ 10 stages 를 통과하는데, 아래와 같은 formulation 으로 써 볼 수 있습니다.</p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>=</mo><msub><mi>x</mi><mi>N</mi></msub><mo>×</mo><msup><mi>r</mi><mrow><mi>N</mi><mi mathvariant=\"normal\">−</mi><mi>n</mi></mrow></msup><mo separator=\"true\">,</mo><mi>r</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding=\"application/x-tex\">x_{n} = x_{N} × r^{N−n}, r = 0.75</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mord mtight\">−</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">7</span><span class=\"mord\">5</span></span></span></span></p>\n</blockquote>\n<p>논문에선 8 ~ 10 stages 는 좀 많다라고 이야기하면서, 적절한 scaling factor &#x26; stages 를 찾는 시도를 합니다.</p>\n<ol>\n<li>scaling factor 가 높고 stages 가 많아지면, 훈련의 안정성이나 (image) global coherence 가 높은 장점이 있겠지만, 그만큼 학습이 느려지고,</li>\n<li>scaling factor 가 낮고 stages 가 적어지면, 학습이 빨라지는 대신, global coherence 를 잃는 문제가 발생하겠죠.</li>\n</ol>\n<p>또한, high resolution 에서는 많은 stages 가 필요하지 않다는 점을 언급하면서, 이런 요소를 반영해 다음과 같은 formulation 을 제안했습니다.</p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>=</mo><msub><mi>x</mi><mi>N</mi></msub><mo>×</mo><msup><mi>r</mi><mrow><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>∗</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo>−</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo separator=\"true\">,</mo><mi>n</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x_{n} = x_{N} × r^{((N - 1) / log(N)) * log(N - n + 1)}, n \\in [0, N)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">(</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mord mtight\">/</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose mtight\">)</span><span class=\"mclose mtight\">)</span><span class=\"mbin mtight\">∗</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen mtight\">(</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9d4663aa3a0f123a3490b1932b3a2b37/efa1a/rescale.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAACUUlEQVQozz2R6y+bYRjG+3ctsVmytIrRvlqW/QdkmUT1hLbenl8tuqpDbIYsFbQMQxzmVITZhEwy52Tbhy0M8Wk+SPrb09fiSe68z/Nc13Nf13W/Gv6v6+trzs/Pubj4w9XVpbrP3d2tLNlsltvbWxW/vLy4r7OzM25u/t7zNPtHa7QmKukfttPdZ+Vt0kZ3by2v+230vLMS66hiKTPEx5UecfeSto5aEp0W+gYt9A5Y6HpjoX/QQUu8ku8/v6JZ30xTbcnD11SMo6EAt1+P06WjrlGHy1tIjT2PkfcxUuMytvp8gRfQGNbhdGtx+XXUewrwKU+pevGAbwfraDa/jAuiFiVuwuMzEohKyEEj3rCEv0nCKRpPTLaTGgtideoIt0qiDHhDOY4ROSDOsXLsdVoOjzfQ7OzN4BQq0cQz/BEToRaT+g1EzGJfjjtQyIfpTqbmFeSwnlh3BS1dZnxhE8GoWXDNROPP1TRHp5/QbO9OYxcOcw38IUkQhXJQwuM34lfKqFcddjA6EcLq0BJqNtKckERUg3BWRoNsIBKrwO7Us3+4iWZ1Iy0cisivhKpiFLPMVSle5S5+naxlcibBwFCQWvsTGsU4ZKWUUEwIRgzCWQlNbSZcAT2HJyLy5+0pamyP8EVKhVoRLp9ePCrC7SsSMyrB4njI2ESc5KBMgzefgPh5SkIv5p3Di/EEC4m2G6muecz+gWh4crrH3HySldVRllZSZNZGWVweZjkzIs5pZgW2s7vG1tYis3MDLKnYMAsLKfXNciat1sxckl+/f/APrJ7vnuIgM3UAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"scale\"\n        title=\"scale\"\n        src=\"/static/9d4663aa3a0f123a3490b1932b3a2b37/fcda8/rescale.png\"\n        srcset=\"/static/9d4663aa3a0f123a3490b1932b3a2b37/12f09/rescale.png 148w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/e4a3f/rescale.png 295w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/fcda8/rescale.png 590w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/efc66/rescale.png 885w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/c83ae/rescale.png 1180w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/efa1a/rescale.png 2040w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>차이는 아래와 같습니다. (scaling factor 0.55 &#x3C;- 논문에서 언급한 값)</p>\n<ol>\n<li>old scaling : 25×34, 38×50, 57×75, 84×112, 126×167, 188×250</li>\n<li>new scaling : 25×34, 32×42, 42×56, 63×84, 126×167, 188×250</li>\n</ol>\n<p>scale factor를 0.55로 논문에선 설정했는데, 계산해 보면 scaling factor 값이 조금 이상하네요.</p>\n<h3 id=\"fine-tune\" style=\"position:relative;\"><a href=\"#fine-tune\" aria-label=\"fine tune permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Fine-Tune</h3>\n<p>마지막으로, image harmonization task를 위한 fine-tuning에 대해서도 언급합니다.</p>\n<p>간단하게 설명하면, 먼저 source image에 대해 학습을 하고, 이후에 reference image에 대해 학습을 하면 더 좋은 성능을 낼 수 있다고 캅니다.</p>\n<h2 id=\"benchmark\" style=\"position:relative;\"><a href=\"#benchmark\" aria-label=\"benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Benchmark</h2>\n<h3 id=\"confusion--sifid\" style=\"position:relative;\"><a href=\"#confusion--sifid\" aria-label=\"confusion  sifid permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Confusion &#x26; SIFID</h3>\n<p>SinGAN 하고 비교했을 때, SIFID 가 더 좋아진 걸 볼 수 있었고, 훈련 시간, 학습해야 하는 모델 파라메터 수도 2배 정도 줄었음을 확인</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9184f649c8c35cf7ae04bae4cc6df427/46e30/place_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 18.243243243243242%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAuUlEQVQY0zVPyQqFQAyb//8xQVBB3B2Xg4rgghuoB8kjgTdQpmRpU5MkCZZlwXmeGMcRRVEgz3P0fY/jONSnaaq+aRrx1lp0XSe8bVtpOacsS5g4jgVO04R5nkVQzOIQiuq6FreuK7IsE3fftziGuK4LYRiCs4zrukrxPI+SsufPJfxpGoZBxvd9ZWIiPob4vk/FtI7jwOz7rq00EuSm/5k0R1EE3/fheZ7ODYJAGvIMQ5xYVVXYtg0/e/Ih7Xr0U/IAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"perf\"\n        title=\"perf\"\n        src=\"/static/9184f649c8c35cf7ae04bae4cc6df427/fcda8/place_benchmark.png\"\n        srcset=\"/static/9184f649c8c35cf7ae04bae4cc6df427/12f09/place_benchmark.png 148w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/e4a3f/place_benchmark.png 295w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/fcda8/place_benchmark.png 590w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/efc66/place_benchmark.png 885w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/c83ae/place_benchmark.png 1180w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/46e30/place_benchmark.png 1303w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ae71eeadf38193f7a5721b756070199b/4ca46/lsun_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 14.864864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAnklEQVQI1z2PywqFMAxE/f8/c+WiqNT3o2hbSxEUBRFGJnDvIhAmMydJ0vc9qqrCvu+o6xp5niOEAGMMiqKQnrOyLNE0DZxzUEphHEd0XQetNaZpEo2sZBgGpGkqQQ4YWtdVimZrrUCWZRHIeZ6ib9uG67rgvcf7vsiyTDzJcRyIMeJ5nj+QAS7ixSxqvLZtW+l/Hn42zzPu+wY5XPYBmVnbAXjrJJYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"perf\"\n        title=\"perf\"\n        src=\"/static/ae71eeadf38193f7a5721b756070199b/fcda8/lsun_benchmark.png\"\n        srcset=\"/static/ae71eeadf38193f7a5721b756070199b/12f09/lsun_benchmark.png 148w,\n/static/ae71eeadf38193f7a5721b756070199b/e4a3f/lsun_benchmark.png 295w,\n/static/ae71eeadf38193f7a5721b756070199b/fcda8/lsun_benchmark.png 590w,\n/static/ae71eeadf38193f7a5721b756070199b/efc66/lsun_benchmark.png 885w,\n/static/ae71eeadf38193f7a5721b756070199b/c83ae/lsun_benchmark.png 1180w,\n/static/ae71eeadf38193f7a5721b756070199b/4ca46/lsun_benchmark.png 1944w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"diversity\" style=\"position:relative;\"><a href=\"#diversity\" aria-label=\"diversity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Diversity</h3>\n<p>논문에서 중요하게 생각하던 Diversity 도 보면, SinGAN 대비 comparable 하거나 low 한 diversity score 가 나왔습니다.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">DataSet\\Model</th>\n<th align=\"center\">SinGAN</th>\n<th align=\"center\">ConSinGAN</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Place</td>\n<td align=\"center\">0.52</td>\n<td align=\"center\">0.50 (0.43)</td>\n</tr>\n<tr>\n<td align=\"center\">LSUN</td>\n<td align=\"center\">0.64</td>\n<td align=\"center\">0.54</td>\n</tr>\n</tbody>\n</table>\n<p>Place dataset benchmark 중 괄호는 learning rate scaling factor 를 0.1 에서 0.5로 올렸을 때, diversity 감소가 발생했다는 걸 보여주고 있습니다.</p>\n<p>LSUN dataset 에선 global structure 를 catch 하지 못한 게 낮은 diversity score를 얻었다는 것으로 해석합니다.</p>\n<h3 id=\"image-harmonization\" style=\"position:relative;\"><a href=\"#image-harmonization\" aria-label=\"image harmonization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Harmonization</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a12301b7315ec7baead786eb1762c529/0e199/harmonization.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.21621621621622%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAACGklEQVQoz1XSzU/SARjAcf+rDp2qU651qC61Li2XlZe2DlTqjNXIWWOaKPEmqAx+Y4k/xcC3hUnJiyIo70GoIGKJgwHLNYVvKF58Ts/2PPvseZ49LTTi5Pgfu8kg4dVv/M4k2N8KEwt8p5DPUD7ME193kQz5OKqWyDdqm14nyfAa6egaIZ+T/WzqlKFer9NymvytFHF+HsY09AaHoMQtDiEoevgxP0kyuMy0vo/RASm5XxFc0yOYh6TMCp/wzZsYlb/CaRPOwFqt1gSPKwVUL+6i67lPfK4fdddDXrdfJ7EiEP5qobftKnPKp1RyIbTdD+jtuEFwqheDtB15RyvRRdU5eNIEqwc5zJJWXAO3SNm7MXXeYeT5ZXJ+HQGbFuHZJfz6e1R21zBJbmJ+eY24TYKl6zaTnVfIuvqaK9eOz8FqGeuEDLPuMSueSewz/Zi1bcRiy0SibsbU7UxZ31I43GNa7EPQP8HjE/lik2PUPiKwMXtxwspRFbVdw8iUCrtXZGxhHJVVgTu8hDexyvDEIEaHhuxBBv2cAZ2oxO4RGV80om70OddnL96wVC3y0fQeo2jA5rGi0crQ6uV44yss+RdQjMowOQzs/NlmePwdBouCGbeI2vwBnTCIM7DQBOsNsFgscnBYIBD2E41vktpJsRENnOXb2S1SW0mCIT+xnxH29vfO+iKNWiKdYDPaeLXYBulMmlKxRLlc5j+ckgelpLb8KAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"harmonization\"\n        title=\"harmonization\"\n        src=\"/static/a12301b7315ec7baead786eb1762c529/fcda8/harmonization.png\"\n        srcset=\"/static/a12301b7315ec7baead786eb1762c529/12f09/harmonization.png 148w,\n/static/a12301b7315ec7baead786eb1762c529/e4a3f/harmonization.png 295w,\n/static/a12301b7315ec7baead786eb1762c529/fcda8/harmonization.png 590w,\n/static/a12301b7315ec7baead786eb1762c529/efc66/harmonization.png 885w,\n/static/a12301b7315ec7baead786eb1762c529/c83ae/harmonization.png 1180w,\n/static/a12301b7315ec7baead786eb1762c529/0e199/harmonization.png 2067w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>개인적으로 새로운 idea를 제안하는 논문도 좋아하지만, 이런 training recipe 튜닝하는 걸 좋아해서 개인적으로 가볍고 재밌게 읽었습니다.</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR 이전에 리뷰했던 SinGAN 후속 논문이 나왔는데, 우연히 github 메인 페이지 오른쪽에 보면 Explore repositories가 있는데, 여기에 추천 repo로 떠서 우연히 보게 됐습니다. 저자분께서 짧은 요약을 블로그에 정리해서…","tableOfContents":"<ul>\n<li><a href=\"/ConSinGAN/#tldr\">TL;DR</a></li>\n<li><a href=\"/ConSinGAN/#related-work\">Related Work</a></li>\n<li><a href=\"/ConSinGAN/#introduction\">Introduction</a></li>\n<li>\n<p><a href=\"/ConSinGAN/#methodology\">Methodology</a></p>\n<ul>\n<li><a href=\"/ConSinGAN/#multi-stage-training\">Multi-Stage Training</a></li>\n<li><a href=\"/ConSinGAN/#rescaling-image\">Rescaling Image</a></li>\n<li><a href=\"/ConSinGAN/#fine-tune\">Fine-Tune</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/ConSinGAN/#benchmark\">Benchmark</a></p>\n<ul>\n<li><a href=\"/ConSinGAN/#confusion--sifid\">Confusion &#x26; SIFID</a></li>\n<li><a href=\"/ConSinGAN/#diversity\">Diversity</a></li>\n<li><a href=\"/ConSinGAN/#image-harmonization\">Image Harmonization</a></li>\n</ul>\n</li>\n<li><a href=\"/ConSinGAN/#conclusion\">Conclusion</a></li>\n</ul>","fields":{"slug":"/ConSinGAN/"},"frontmatter":{"title":"ConSinGAN - Improved Techniques for Training Single-Image GANs","date":"Mar 25, 2021","tags":["Deep-Learning"],"keywords":["GAN","one-shot","Concurrent","Generative-Models"],"update":"Mar 25, 2021"},"timeToRead":5}},"pageContext":{"slug":"/ConSinGAN/","series":[],"lastmod":"2021-03-25"}},"staticQueryHashes":["2027115977","694178885"]}