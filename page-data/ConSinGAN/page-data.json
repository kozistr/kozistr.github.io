{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/ConSinGAN/",
    "result": {"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>이전에 리뷰했던 SinGAN 후속 논문이 나왔는데, 우연히 github 메인 페이지 오른쪽에 보면 Explore repositories가 있는데, 여기에 추천 repo로 떠서 우연히 보게 됐습니다.</p>\n<p>저자분께서 짧은 요약을 블로그에 정리해서, 논문 대신 아래 글을 읽어도 충분할 듯하고, SinGAN 이랑 비교/대조하는 부분이 있어서 SinGAN 논문도 읽어보시는 걸 추천드려요.</p>\n<p>official summary : <a href=\"https://www.tobiashinz.com/2020/03/24/improved-techniques-for-training-single-image-gans.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">blog</a></p>\n<p>paper : <a href=\"https://openaccess.thecvf.com/content/WACV2021/papers/Hinz_Improved_Techniques_for_Training_Single-Image_GANs_WACV_2021_paper.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">WACV21</a></p>\n<p>code : <a href=\"https://github.com/tohinz/ConSinGAN\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">github</a></p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>요 논문과 관련높은 references</p>\n<ol>\n<li>SinGAN : <a href=\"https://arxiv.org/pdf/1905.01164.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a>, <a href=\"https://kozistr.tech/SinGAN/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">my review</a></li>\n<li>ProGAN : <a href=\"https://arxiv.org/pdf/1710.10196.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">paper</a></li>\n</ol>\n<h2 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Introduction</h2>\n<p>논문을 읽기 전, 전반적인 느낌은 논문 제목부터 Con<strong>SinGAN</strong>인 것처럼, SinGAN에 여러 techniques를 추가해 성능을 improved 한 느낌입니다.\r\n또, Con (Concurrent)라 명칭 한걸 보니, 각 generators 를 concurrent 하게 학습한다는 느낌을 받았는데, 자세한 건 논문을 읽어봐야겠어요.</p>\n<p>이 논문에서, 크게 <strong>3가지의 main contributions</strong> 이 있습니다.</p>\n<ol>\n<li>architecture &#x26; optimization</li>\n<li>이미지 rescaling (for multi-stage training)</li>\n<li>fine-tuning</li>\n</ol>\n<h2 id=\"methodology\" style=\"position:relative;\"><a href=\"#methodology\" aria-label=\"methodology permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Methodology</h2>\n<h3 id=\"multi-stage-training\" style=\"position:relative;\"><a href=\"#multi-stage-training\" aria-label=\"multi stage training permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Multi-Stage Training</h3>\n<h4 id=\"random-noise\" style=\"position:relative;\"><a href=\"#random-noise\" aria-label=\"random noise permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Random Noise</h4>\n<p>model architecture 같은 경우 <strong>SinGAN</strong>과 대조를 하는데,\r\n<strong>SinGAN</strong>도 multi-stage generators 를 가지고 있는데, 가장 낮은 resolution에 해당하는 generator만 unconditional generator 라고 말하고 있습니다.</p>\n<p>즉, <strong>SinGAN</strong> 은 최초에만 noise (~= z latent vector)로 부터 이미지를 생성하고, 이후 stages 는 random 한 요소가 들어가지 않는다는 말입니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a092b4cf0345ae01d0296df7f9598f0d/f8544/architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 40.54054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABw0lEQVQoz22RzWsTURTF87+KG3XnUgQXLgQpLqQgiFoKuupCLTStXcSYNrHaijYxte1kPmOSycT5fM2bmczMT2ZiqYIHLpfHvZx3zrk1gDiOEUJgTx3arffU29/ZaPTYbzQxrXG5Qp5lFEXOJYpi2bMsY2w7BGFYvWvLYcFisSBOEnzP5afjo409RuaQeH7B35hLiZQxRZaSpikUOT11QiDmV4RJSeT7uK5Hv/eN9rFG86iPY5+yeWCwW99h5eEqkcx4vLLK0+cbrG9/wTCHSDnnlxsSRtEVYSm7VBgJwemPPt3BhK9nJkOzz7vPCgd7HdaerCOTjFcvXvLm9TatrkkYBEiZELka84s/lovLMP6DPIci/ddymWIgEiKZI9Oi2lkInUUiqlxrl0cpLTvOjKNPHXY6J7xtHjIddXm2dYw36bG22UKxpniB4P6du9y4fpPdvW71yWhs4wfBUmGe55XdsspLq4NzTnSb3mCIPTpna79P5FvUW4dM3RARCR7ce8Tta7f40PhYkei6juM4VXS12WyGoiioqoplWRiGiWloWIbOQNUxNaXq2kBB11TGkwl+EOL7Eb4f4HkerutWDsMw5Dc7uk5ql8wwAQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"architecture\"\n        title=\"architecture\"\n        src=\"/static/a092b4cf0345ae01d0296df7f9598f0d/fcda8/architecture.png\"\n        srcset=\"/static/a092b4cf0345ae01d0296df7f9598f0d/12f09/architecture.png 148w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/e4a3f/architecture.png 295w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/fcda8/architecture.png 590w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/efc66/architecture.png 885w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/c83ae/architecture.png 1180w,\n/static/a092b4cf0345ae01d0296df7f9598f0d/f8544/architecture.png 1811w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>위는 ConSinGAN 의 model architecture 인데, <strong>diversity</strong>를 높히기 위해 매 stage 마다 이전 stage 의 생성 결과와 random noise가 같이 합쳐서 들어가고 있습니다.</p>\n<h4 id=\"freeze-previous-generator\" style=\"position:relative;\"><a href=\"#freeze-previous-generator\" aria-label=\"freeze previous generator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Freeze Previous Generator</h4>\n<p>그리고, 현재 (n) stage를 훈련할 때 이전 (n - 1) stage의 generator를 freeze 한다는 차이도 있습니다.</p>\n<p>이런 방식으로 concurrently 하게 한 번에 여러 stages 의 generator 를 학습하는데, 한 번에 모든 stages의 generator를 학습하면 overfitting 가능성이 커지니,\r\n<strong>적당히 한 번에 3 stages</strong> 를 훈련한다고 합니다.</p>\n<h4 id=\"learning-rate\" style=\"position:relative;\"><a href=\"#learning-rate\" aria-label=\"learning rate permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Learning Rate</h4>\n<p>또한, 한 번에 3개의 generators 를 훈련하는데, 각 stage 마다 다른 learning rate 를 사용했습니다.</p>\n<p>예를 들어, Generator (n - 2), (n - 1), (n) 을 학습한다면, (0.01 * lr), (0.1 * lr), (lr) 식으로 (10배 씩 decay 해) 사용했다 합니다.</p>\n<p>물론, 이렇게 learning rate 를 사용하는 것에 대한 이야기도 했는데,</p>\n<ol>\n<li>lower generators 에서 higher learning rate 사용 : training image 에 더 similar 한 image 를 만들겠다.</li>\n<li>lower generators 에서 lower learning rate 사용   : 더 높은 diversity 를 가져가겠다 (~= maybe leads to worse quality)</li>\n</ol>\n<p>이렇게 말하면서, learning rate 란 artifact 에 대한 sample 변화도 보여줬습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/8604db43f1177d6edb47bf4183d11a0c/7da7d/changing_by_lr.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 36.486486486486484%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAAB2klEQVQozyXOzVMSAQCGcf7UDnWpQ1Mn61BTEqXkSu1CBoQSX+IAC4uou8DCrnwOfgQiCEyNw0yN1ViRIh5snkZ5z8/85rX8+HPBPWeMD1tlhGSJJ36F4uGQW/Zl6v2v3F4MES83ORudMr9oYznwkfSGjM3+ggVpEUESECQHDmkebyCI5fTvmIfvY/izVaR0BWtkE/1gyB3BT7n3jbtilFStzfnoJ7MvZ3AsOVmTQzx4fB+bfRbrq0c8m3vOU+sMotuF5erfFRu5Oimtgbxu4I0aBGMF3OEcYbmM6MtQqB1yvWL1AOeqiV7v8Tak44mVCKSqiOEivmSVlWQFy3VYz2VIJ2XUeBCP+Aa/UyDkXcInCbgdrzGM7Rtwp9liNZnGrDWIpjKE4jLypkYkkSKxmUVRc1MwX2wQT+uks7u4A1t4VxJ4Ijm8AQXRp2DWpw9Le12kSBat0sIVzfMumsWfMnFFc6wo2/iSxhRsGeuYmoK5vkbMYyfmXSDuF0ksiwScc1QN9QZstZtoeZWdT7touoqSkdHNPBtaBlVXKZiFKTienDO5HHM+PqM36HLU73DUb9Prd2m19/n8ZcDJyXcGgw7d7j7Hx326nT2Gwx6TyW8mk19cXJxyeTniP//JvVXsbUU2AAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"lr\"\n        title=\"lr\"\n        src=\"/static/8604db43f1177d6edb47bf4183d11a0c/fcda8/changing_by_lr.png\"\n        srcset=\"/static/8604db43f1177d6edb47bf4183d11a0c/12f09/changing_by_lr.png 148w,\n/static/8604db43f1177d6edb47bf4183d11a0c/e4a3f/changing_by_lr.png 295w,\n/static/8604db43f1177d6edb47bf4183d11a0c/fcda8/changing_by_lr.png 590w,\n/static/8604db43f1177d6edb47bf4183d11a0c/efc66/changing_by_lr.png 885w,\n/static/8604db43f1177d6edb47bf4183d11a0c/c83ae/changing_by_lr.png 1180w,\n/static/8604db43f1177d6edb47bf4183d11a0c/7da7d/changing_by_lr.png 2120w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4 id=\"discriminator\" style=\"position:relative;\"><a href=\"#discriminator\" aria-label=\"discriminator permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Discriminator</h4>\n<p>Discriminator로 Patch Discriminator 를 사용하는 것에 대해, 이미지의 일부로만 판단하면 global perspective 에서 real or fake 확인이 어렵다는 점을 언급합니다.</p>\n<h3 id=\"rescaling-image\" style=\"position:relative;\"><a href=\"#rescaling-image\" aria-label=\"rescaling image permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Rescaling Image</h3>\n<p>각 generators 에 들어가는 image resolution 에 대한 내용인데, multi-stage scheme 으로 여러 resolution 으로 progressive 하게 generate 하는 것은 좋은데,\r\n그럼 이걸 얼마나 해야 하냐? 라는 의문을 제기합니다.</p>\n<p>SinGAN 같은 경우엔 주로 8 ~ 10 stages 를 통과하는데, 아래와 같은 formulation 으로 써 볼 수 있습니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>=</mo><msub><mi>x</mi><mi>N</mi></msub><mo>×</mo><msup><mi>r</mi><mrow><mi>N</mi><mo>−</mo><mi>n</mi></mrow></msup><mo separator=\"true\">,</mo><mi>r</mi><mo>=</mo><mn>0.75</mn></mrow><annotation encoding=\"application/x-tex\">x_{n} = x_{N} × r^{N−n}, r = 0.75</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.035771em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\">n</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">0.75</span></span></span></span></span></p>\n</blockquote>\n<p>논문에선 8 ~ 10 stages 는 좀 많다라고 이야기하면서, 적절한 scaling factor &#x26; stages 를 찾는 시도를 합니다.</p>\n<ol>\n<li>scaling factor 가 높고 stages 가 많아지면, 훈련의 안정성이나 (image) global coherence 가 높은 장점이 있겠지만, 그만큼 학습이 느려지고,</li>\n<li>scaling factor 가 낮고 stages 가 적어지면, 학습이 빨라지는 대신, global coherence 를 잃는 문제가 발생하겠죠.</li>\n</ol>\n<p>또한, high resolution 에서는 많은 stages 가 필요하지 않다는 점을 언급하면서, 이런 요소를 반영해 다음과 같은 formulation 을 제안했습니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>=</mo><msub><mi>x</mi><mi>N</mi></msub><mo>×</mo><msup><mi>r</mi><mrow><mo stretchy=\"false\">(</mo><mo stretchy=\"false\">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy=\"false\">)</mo><mi mathvariant=\"normal\">/</mi><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo><mo>∗</mo><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy=\"false\">(</mo><mi>N</mi><mo>−</mo><mi>n</mi><mo>+</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow></msup><mo separator=\"true\">,</mo><mi>n</mi><mo>∈</mo><mo stretchy=\"false\">[</mo><mn>0</mn><mo separator=\"true\">,</mo><mi>N</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">x_{n} = x_{N} × r^{((N - 1) / log(N)) * log(N - n + 1)}, n \\in [0, N)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.58056em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.73333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">x</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0824399999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8879999999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mopen mtight\">((</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span><span class=\"mord mtight\">/</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose mtight\">))</span><span class=\"mbin mtight\">∗</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathnormal mtight\">o</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mopen mtight\">(</span><span class=\"mord mathnormal mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">−</span><span class=\"mord mathnormal mtight\">n</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight\">)</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\">n</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord\">0</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">N</span><span class=\"mclose\">)</span></span></span></span></span></p>\n</blockquote>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9d4663aa3a0f123a3490b1932b3a2b37/efa1a/rescale.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAACU0lEQVQozz2P6y9bARjGz9+1xGbJ0guGUy3L/gOyTKK0qtfTc9qe0xZd1SXMkKWClmGIy6hrmE3IJHMZybYPWxji03yQ+C2OxZM8ed+8z/O+eR+B/7i8vOT09JSzsz9cXJzr/e3sDjfc3NxwfX2t6+fnZ/c8OTnh6urvvU/YO1ylOVVJ35CTzt463qQddPbU0tXnoPttHYm2KnLLg3xY6qar7yUtbbWk2u30Dtjp6bfT8dpO30A9TclKvv/8grC2kaXanoccLaLeY8KnmHF5jTQEjHiDBdQ48xh+lyAzJuFw5+NTTARUIy6fAa9ixO03IWtPqXrxgK/7awgbn8dwuA1oSSt+WSQUtyCFRYKqBSVqwRUwMj7RSmY0TJ3LiNpsQW0uJRi59YhIIQtqohxng4GDb+sI27vTuPwm4qlnKDErkSarXkMxG5GmcnyhAt5PtTM5pyGpZhKdFTR12JBVK+G4DSVmI558rqc5PP6IsLUzhdNt0A8oEQuyKhIMW/ArIopWhlv/sI2R8Qh19QYijSKNKQtufylqogyPVEosUYHTZWbvYANhZT2Ly29Ae2VD1kTk6C1LCGp38RskAxPTKfoHw9Q6nxAIi0haCZGEiBIrxRssJtpixRsyc3C0jvBpa5IaxyPkWAkeqRCvbCYQLsQnFxJUi7HXP2R0PEl6QMITzCcULUJLmfHrehH+cAHxVpHqmsfs7a8jHB3vMjuXZmllhNxShuXVERYWh1hcHia3lGVmLs32ziqbmwvMzPaT07Uh5ucz+s7iclbn9GyaX79/8A+snu+eZvKUaAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"scale\"\n        title=\"scale\"\n        src=\"/static/9d4663aa3a0f123a3490b1932b3a2b37/fcda8/rescale.png\"\n        srcset=\"/static/9d4663aa3a0f123a3490b1932b3a2b37/12f09/rescale.png 148w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/e4a3f/rescale.png 295w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/fcda8/rescale.png 590w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/efc66/rescale.png 885w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/c83ae/rescale.png 1180w,\n/static/9d4663aa3a0f123a3490b1932b3a2b37/efa1a/rescale.png 2040w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>차이는 아래와 같습니다. (scaling factor 0.55 &#x3C;- 논문에서 언급한 값)</p>\n<ol>\n<li>old scaling : 25×34, 38×50, 57×75, 84×112, 126×167, 188×250</li>\n<li>new scaling : 25×34, 32×42, 42×56, 63×84, 126×167, 188×250</li>\n</ol>\n<p>scale factor를 0.55로 논문에선 설정했는데, 계산해 보면 scaling factor 값이 조금 이상하네요.</p>\n<h3 id=\"fine-tune\" style=\"position:relative;\"><a href=\"#fine-tune\" aria-label=\"fine tune permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Fine-Tune</h3>\n<p>마지막으로, image harmonization task를 위한 fine-tuning에 대해서도 언급합니다.</p>\n<p>간단하게 설명하면, 먼저 source image에 대해 학습을 하고, 이후에 reference image에 대해 학습을 하면 더 좋은 성능을 낼 수 있다고 캅니다.</p>\n<h2 id=\"benchmark\" style=\"position:relative;\"><a href=\"#benchmark\" aria-label=\"benchmark permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Benchmark</h2>\n<h3 id=\"confusion--sifid\" style=\"position:relative;\"><a href=\"#confusion--sifid\" aria-label=\"confusion  sifid permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Confusion &#x26; SIFID</h3>\n<p>SinGAN 하고 비교했을 때, SIFID 가 더 좋아진 걸 볼 수 있었고, 훈련 시간, 학습해야 하는 모델 파라메터 수도 2배 정도 줄었음을 확인</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/9184f649c8c35cf7ae04bae4cc6df427/46e30/place_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 18.243243243243242%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAuUlEQVQY0zVPyQqFQAyb//8xQVBB3B2Xg4rgghuoB8kjgTdQpmRpU5MkCZZlwXmeGMcRRVEgz3P0fY/jONSnaaq+aRrx1lp0XSe8bVtpOacsS5g4jgVO04R5nkVQzOIQiuq6FreuK7IsE3fftziGuK4LYRiCs4zrukrxPI+SsufPJfxpGoZBxvd9ZWIiPob4vk/FtI7jwOz7rq00EuSm/5k0R1EE3/fheZ7ODYJAGvIMQ5xYVVXYtg0/e/Ih7Xr0U/IAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"perf\"\n        title=\"perf\"\n        src=\"/static/9184f649c8c35cf7ae04bae4cc6df427/fcda8/place_benchmark.png\"\n        srcset=\"/static/9184f649c8c35cf7ae04bae4cc6df427/12f09/place_benchmark.png 148w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/e4a3f/place_benchmark.png 295w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/fcda8/place_benchmark.png 590w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/efc66/place_benchmark.png 885w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/c83ae/place_benchmark.png 1180w,\n/static/9184f649c8c35cf7ae04bae4cc6df427/46e30/place_benchmark.png 1303w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/ae71eeadf38193f7a5721b756070199b/4ca46/lsun_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 14.864864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAnklEQVQI1z2PywqFMAxE/f8/c+WiqNT3o2hbSxEUBRFGJnDvIhAmMydJ0vc9qqrCvu+o6xp5niOEAGMMiqKQnrOyLNE0DZxzUEphHEd0XQetNaZpEo2sZBgGpGkqQQ4YWtdVimZrrUCWZRHIeZ6ib9uG67rgvcf7vsiyTDzJcRyIMeJ5nj+QAS7ixSxqvLZtW+l/Hn42zzPu+wY5XPYBmVnbAXjrJJYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"perf\"\n        title=\"perf\"\n        src=\"/static/ae71eeadf38193f7a5721b756070199b/fcda8/lsun_benchmark.png\"\n        srcset=\"/static/ae71eeadf38193f7a5721b756070199b/12f09/lsun_benchmark.png 148w,\n/static/ae71eeadf38193f7a5721b756070199b/e4a3f/lsun_benchmark.png 295w,\n/static/ae71eeadf38193f7a5721b756070199b/fcda8/lsun_benchmark.png 590w,\n/static/ae71eeadf38193f7a5721b756070199b/efc66/lsun_benchmark.png 885w,\n/static/ae71eeadf38193f7a5721b756070199b/c83ae/lsun_benchmark.png 1180w,\n/static/ae71eeadf38193f7a5721b756070199b/4ca46/lsun_benchmark.png 1944w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"diversity\" style=\"position:relative;\"><a href=\"#diversity\" aria-label=\"diversity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Diversity</h3>\n<p>논문에서 중요하게 생각하던 Diversity 도 보면, SinGAN 대비 comparable 하거나 low 한 diversity score 가 나왔습니다.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">DataSet\\Model</th>\n<th align=\"center\">SinGAN</th>\n<th align=\"center\">ConSinGAN</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">Place</td>\n<td align=\"center\">0.52</td>\n<td align=\"center\">0.50 (0.43)</td>\n</tr>\n<tr>\n<td align=\"center\">LSUN</td>\n<td align=\"center\">0.64</td>\n<td align=\"center\">0.54</td>\n</tr>\n</tbody>\n</table>\n<p>Place dataset benchmark 중 괄호는 learning rate scaling factor 를 0.1 에서 0.5로 올렸을 때, diversity 감소가 발생했다는 걸 보여주고 있습니다.</p>\n<p>LSUN dataset 에선 global structure 를 catch 하지 못한 게 낮은 diversity score를 얻었다는 것으로 해석합니다.</p>\n<h3 id=\"image-harmonization\" style=\"position:relative;\"><a href=\"#image-harmonization\" aria-label=\"image harmonization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Image Harmonization</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/a12301b7315ec7baead786eb1762c529/0e199/harmonization.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 41.21621621621622%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAACGElEQVQoz1XQz0/SARzGcf+rDp2qU651qC61Li2XlZe2DlbqzNXMWWOaqIEgKAy+c4lfxRDUhUnJD0UQvvwKAgVRSxgMWK4hvJvgxdtzePba5/O0AJxW/7Ef9yNtfuN3OsZRSiLi+07uME0pf0h020E86OGkUuQwJRFw24lLWyTDWwQ9do4yiTOGer1Oy1n4Wy5g/zyGYfQNS8I4TnEUQd7Lj+U54v51FjSDTA33kf0VwrEwiXG0D6vwCc+ygSnZK+xmoQHWarUmWC3nULy4i7r3PlHbEMruh7xuv05sQ0D6OsNA21Vs408pZ4Ooeh4w0HED//wA2r52ZB2thFcV5+BpE6wcZzF2tuIYvkXC0oOh6w6Tzy+T9arxmVUIzy7h1dyjvL+FofMmxpfXiJo7mem+zVzXFTKOwebLteo5WClhmu3HqH7MhmsOy+IQRlUbkcg6obCTaWU786a35PIHLIiDCJonuDwiX8wy9KpH+HasFy8sn1RQWiaYnFdgcYtMr+hQmOQ4pTXcsU3GZkfQL02QOU6jsWlRi+NYXCK6VT1Kkxz7tvXihsVKgY+G9+hFLWaXiQlVPyqNDHd0gzXvCvKpfgxLWvb+7DKme4d2Rs6iU0Rp/IBaGMHuW2mC9RothUKB43wOn+QlHA2Q2EuwE/Y18m4mRSIVxx/0EvkZ4uDooNELRQPEkjECYT9SZIdkOkmxUKRUKvEfnJIHpaFROjUAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"harmonization\"\n        title=\"harmonization\"\n        src=\"/static/a12301b7315ec7baead786eb1762c529/fcda8/harmonization.png\"\n        srcset=\"/static/a12301b7315ec7baead786eb1762c529/12f09/harmonization.png 148w,\n/static/a12301b7315ec7baead786eb1762c529/e4a3f/harmonization.png 295w,\n/static/a12301b7315ec7baead786eb1762c529/fcda8/harmonization.png 590w,\n/static/a12301b7315ec7baead786eb1762c529/efc66/harmonization.png 885w,\n/static/a12301b7315ec7baead786eb1762c529/c83ae/harmonization.png 1180w,\n/static/a12301b7315ec7baead786eb1762c529/0e199/harmonization.png 2067w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>개인적으로 새로운 idea를 제안하는 논문도 좋아하지만, 이런 training recipe 튜닝하는 걸 좋아해서 개인적으로 가볍고 재밌게 읽었습니다.</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR 이전에 리뷰했던 SinGAN 후속 논문이 나왔는데, 우연히 github 메인 페이지 오른쪽에 보면 Explore repositories가 있는데, 여기에 추천 repo로 떠서 우연히 보게 됐습니다. 저자분께서 짧은 요약을 블로그에 정리해서…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#introduction\">Introduction</a></p>\n</li>\n<li>\n<p><a href=\"#methodology\">Methodology</a></p>\n<ul>\n<li><a href=\"#multi-stage-training\">Multi-Stage Training</a></li>\n<li><a href=\"#rescaling-image\">Rescaling Image</a></li>\n<li><a href=\"#fine-tune\">Fine-Tune</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#benchmark\">Benchmark</a></p>\n<ul>\n<li><a href=\"#confusion--sifid\">Confusion &#x26; SIFID</a></li>\n<li><a href=\"#diversity\">Diversity</a></li>\n<li><a href=\"#image-harmonization\">Image Harmonization</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/ConSinGAN/"},"frontmatter":{"title":"ConSinGAN - Improved Techniques for Training Single-Image GANs","date":"Mar 25, 2021","tags":["Deep-Learning"],"keywords":["GAN","one-shot","Concurrent","Generative-Models"],"update":"Mar 25, 2021"},"timeToRead":5}},"pageContext":{"slug":"/ConSinGAN/","series":[],"lastmod":"2021-03-25"}},
    "staticQueryHashes": ["2027115977","2744905544","694178885"]}