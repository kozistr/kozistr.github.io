{"componentChunkName":"component---src-templates-post-tsx","path":"/Cotatron/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다.</p>\n<p>간단하게 요약하면, 유명한 google 의 TTS model 인 <em>tacotron2</em> 기반으로 given transcription 와 mel alignment 를 활용해서 speaker-independent linguistic representation 을 뽑는 concept(?) 입니다.</p>\n<p>결론은 VCTK dataset 에서 최근 paper 인 <em>Blow</em> 보다 높은 MOS, DMOS 를 달성했습니다. 아래 링크에 들어가면 모델이 생성한 sample 들을 들어볼 수 있어요.</p>\n<p>paper : <a href=\"https://arxiv.org/pdf/2005.03295.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></p>\n<p>demo : <a href=\"https://mindslab-ai.github.io/cotatron/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">link</a></p>\n<p>code : 아직 official code / pre-trained model은 없는데, 곧 나올 예정인 듯합니다</p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>이전 SOTA 였던 paper</p>\n<ul>\n<li>Blow : <a href=\"https://arxiv.org/pdf/1906.00794.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p><em>Cotatron</em>의 전체적인 architecture 는 아래와 같습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 88.51351351351352%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEc0lEQVQ4y22TWXDTVRSH/wrqODz44Pjogw++MfDgKMso0tKWqqgguziOPsAoUgUFREBGZ9wQh0rZWtLShi4UytLKYjcoBdrSNm2StlmadE2zL02TNEmTNP28+ZfOOKNn5jf3zLn3fvece++RXIEI+Z0WTjT1odB66DQMEvD7cHv82MZaiIT+RtdzAaO+DIOuFJOhnF6tEpvlGkPmS9jHrjMZbCAebcDrMSM5A2FOd1jIbdKRr3HR1tvPuMeFw+llzPKAqXAt/XoBMpah71MKYBnqriKctmpx4DWc9moik40kphrwuE1Iielp/IEQml49Ht8E/7ZoOIjfaxdZegkHPbIiIR/a7jY0XW0CrkHfqxIHavC5rcRjUaTURpN9lB+rS1APGvC63egNBpHdKAb7OA0mF/U6Kw1Gu6xGo4PLrX1ceqDlSpuOmq4BalQm7g76cPhDs8DqjmbWK3+jpOkWo0PDtHd2MjxgEovNnOq08Xutml9udvDrLRVH67ScfGhG0e3gxD0jfzT0cKxOTUGvj74x9ywwFk+iMuuJxmMkE3FiU1G55FgygV/4oekEQREPJmJMilhnXy+mMQvG0RHGYxF53h+YJDGdRAoFvYz7hmFmWoboR2zoh62ybzXZUd1Wo67X0i0y667V0CWyratopO1mO3cqm2itakVzR4fWYiYY8SDZrR0MDZQSCjmJRONc1Lmp0rlkYOlPVzh1+BzXL9ygSlHNjfJaKvKusubZD0mT1pI5fzOrXvyIlct3sOylbdRV3kFyObow95cSFfTpGVC0GDh/XycDlT9c5vDGnzm++wy5u/M5ufccRz/OJfu5baxYuJ30tM/JWPwJGQu2sEJ6h/qyu0hWSzsdj84QDNgJhCIoHhpQNPUI3AxnvylhkbSS5dLbLJUyeU16iyUvbCH9zc9Ie/lTVs3bSIb0AZnSBgF8n8aL90TJtk7UqgIcdjNDwxYKW/spbjEyPuHm9NfFvCG9S/YzW0lbuJNVGTlkLtouIBuE1gmtJ+OJDWQ+uVGse0/caTOSw64SwHNEo165zILmXgrv9ch+4f5yXpfWkLXsC9Jf2UnWgq2sFpCseZvIemozq+dvkpX99GZxp+tmgXbrIwx9CiJhF+FIjBKNjYoepww8tbeYhc+vYenTa0W56bwqZYlx9X+0RMpmsZTG7eJ6JJ/4Mg7bIwGcYEY8yn2TlRazTQZqDTrOHqvk/L5yig5VUPRdBYUHyinYp0TxbRnn9l8QKpX9M3uKGdAOI6UgiQQyLGWJqQhuhw2Px0MoEJD7M5aMEk9O4fW7sdhGGBodwDvh4f9MSr3mnGYeU6eTSeJx0RmhEL7AhOiCgCyXOGTEYqFLrcbmdBKYnCQUiRAMh8UPCcl7pBRkTilLjcnHfpWqmR3K4+xS/klOWR5fXTzNvuoidipzySnNI6c8j12lJ9hTlc+XV/NpN+tme3kONAdNigxTVtP1kL2VZzlUVcjh68V8X13Mkb+UHKxScKCyQMTOy/EjNSUcFOoeNPIP3c94u9azR2QAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png\"\n        srcset=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/12f09/cotatron-architecture.png 148w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e4a3f/cotatron-architecture.png 295w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png 590w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png 861w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"1-speaker-independent-linguistic-features-from-tts\" style=\"position:relative;\"><a href=\"#1-speaker-independent-linguistic-features-from-tts\" aria-label=\"1 speaker independent linguistic features from tts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. speaker-independent linguistic features from TTS</h3>\n<p>이번에 제안한 <em>cotatron</em> 은 google 의 <em>tacotron2</em> 를 기반으로 합니다. </p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><msub><mi>M</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>^</mo></mover><mo separator=\"true\">,</mo><msub><mi>A</mi><mi>i</mi></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>M</mi><mrow><mn>0</mn><mo>:</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msup><mi>z</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{M_{1:i}} , A_i = Decoder (Encoder(T), M_{0:i-1}, z^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1412099999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9467699999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.099108em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mrel mtight\">:</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p><em>T</em> 는 Transcription, <em>M</em> 은 log mel-spectogram, <em>z</em> 는 speaker representation.</p>\n<p>요거로부터 mel alignment + given transcription + speaker representation 으로 새로운 speech 를 생성합니다.</p>\n<p>이 이후가 중요(?)한데, TTS 훈련 후에,\nDecoder output 으로 transcription 과 mel-spectogram 사이의 <em>Alignment</em> 가 나오는데, 요 부분을 training 할 때 <em>teacher-forcing</em> 기술을 사용해서 훈련했다고 합니다.</p>\n<p>그래서 최종적으로 Speaker-Independent linguistic features 는 다음과 같습니다.</p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>t</mi><mi>m</mi><mi>u</mi><mi>l</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo separator=\"true\">,</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L = matmul(A, Encoder_{text}(T))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">u</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mord mathdefault mtight\">x</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p>그런데 한 가지 짚어야 할 점은,\n<em>T</em> 는 speaker 에 대한 정보가 없는 text 고,\n<em>A</em> 는 간단히 text 와 mel spectogram 과의 coef 라 할 수 있는데,\n즉, <em>L</em> 이 speaker 에 대한 정보를 담고 있지 않다는 점이다. 이 부분은 아래에</p>\n<p><em>Cotatron</em>은 이미 <em>Tacotron2</em> 기반의 모델이라 multi-speaker speech synthesis 에 well-optimized 됐을 거지만,\n조금 더 잘해 보려고(?) 기존의 embedding table 을 걷어내고, speaker representation encoder 를 하나 만들어 넣었다고 합니다.</p>\n<p>해당 encoder 구조는 2d cnn 6 layers + gru 구조로 구성.</p>\n<h4 id=\"speaker-disentanglement-issue-\" style=\"position:relative;\"><a href=\"#speaker-disentanglement-issue-\" aria-label=\"speaker disentanglement issue  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>speaker disentanglement issue ?</h4>\n<p>그래서 이런 speaker disentanglement 에 대한 issue 를 해결하기 위해 speaker classifier 를 추가로 붙여 줬다고 캅니다.</p>\n<p>이 때 사용된 모델은 간단한 1d cnn 4 layers + temporal max-pooling + fc 로 구성.</p>\n<h3 id=\"2-voice-conversion\" style=\"position:relative;\"><a href=\"#2-voice-conversion\" aria-label=\"2 voice conversion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. voice conversion</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.972972972972975%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBklEQVQoz4WST2/TQBDF/YH5Ahw5cEGCMwfEAVqQoEVCQohSEKLQFmhDS9rEjh07tlOn/pPUiZ3EXjvJj7UrlUggsdLTaHdn3+y8Nwr/WQuRYXQ6WB0drXlGu6USx+P6brVa/ZWvpGnKZDKRSJimY6LwvI52cMVnzeXECTEcm61vn9jc36V74aw9XzGfZ8xmOdPpnKIoUEajEWEYSESycoDr7JKOI/aaBo++tHjVMDnRO9z/uM2dnee0XIskKxmkOeO5wL90sXvnOLYqSaco698ty7JGkiSM45jlclm3tVwsSMYTvAsPf+CxsXfK3TffeXvaw3OOMbRNvP6OzC9RhsMhge8zGPiy2gGu/VImfWXvzOTBh188Pehw2Dzl9uvH3Np6SMPUEKLEdC/IywVlkZNliURaF1eEEFQoipL5LJL6eSyKCbNcYAUj/DglmSacubL1ns4ouTZkmib/NFGxTBNTot1qEUVD4qsBo3hCo3dJww447Ho4QcxRt8375hFFJrWTJoZRdOP0OpQwlC7qOmpblcS61OKYQBJv/7R4dmzx5EeXE8tnY/8d93ZeILKMPM8Rhfjj9dr4KJlMqNyJpQnVD6X+sn0pQT6nzLM6SrURUgIhiarRqN5cy1TUxq2T3rgcBAG2bdftu/0+umFgSFR7q9dD0zQcx0FVVVzXrWN1Vs3xOuFv6kbqLnB6QpMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png\"\n        srcset=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/12f09/voice-conversion-system.png 148w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/e4a3f/voice-conversion-system.png 295w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png 590w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/efc66/voice-conversion-system.png 885w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png 936w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>위 이미지처럼 voice-conversion system 인데, 전반적인 pipeline 이 그려져 있습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.56756756756756%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADNUlEQVQ4y02SaW/aWBSG+bmtRlXV+TLS/ID5MItmaWapqpKkaTKELM06SjtJ0yyEQNkxJqzGS8DYEAgQjEnoMxenUuZIj87r46vX5xxf3/D6ALWyTjEXIJ9ZopRfxtS36Xfec3MVYj8d5eudWb7ZnefJ0gxPFmd4GvzT09Pas20/24kQ/tAexxdpfPV2CbUhUxNkixGqhoRq5jHsC8xWFc1uEFIkworMueBQjvFRjnNWzopajnAtR15X+PatME6d4ft1X+KPowK/H8r8JvTzA4m/jovMHJdYTmj0BkNa/TFW16EtctWw0cyOp61rRzDidgK9bpdbd4zvn1SZvUyFd5LC24gkdNV73k1XiFYuSWlNZvNdXsY0fvmQYeZUfOy0wPOTC17GdV5JbZLGFaObPs5ohG8uJBNI1AimdV5HSgSSKn/Hq8yfl9iVLxk6DjfOiOHIZXR7R9Nu0ep0cYWe1qbvptHv93FdF99OzmA1IrMSzrF0mhY6z1aqypZkcFox0e0uRxWLfTHBYV5nL13mnZjiIFfjg6zyXlKpmG3atnVvuFtqsZZUPJZjZdbTKjt5k+1ii5DWQTYsApk6C+ELFiJF3kTLHvNnFyxGS8xFyiSUBqPhDZPJZ7FDYbgaF0YphaVwXhjWWEtU2C7YfKy2uHPFSGPB3fh+tE4bp3/taa926/IQwnBH7CkYlryxF44SrETzrAo2szqn5QaS6HCl3GM518R/VsAvdvtKdDcfrRCURfeFK7L1K89u8lkYBlMGgZhCIK6KH6KJq6KyJpkEMw2OtAFGq0u8MSRmXBOuNDkuXHIiOFdsr/bpckCjO7zvb2q4kZRY/5T0WDwJe3kzkWEjJXFYrIrd9Ji4LcaOLcbrcmUp9Dq6pydum7uRLSa/eTB8tvGCR/7veTz3I49f/8Sj2R/4auFnnm6+4Lt/V9C0JG1ri1x2gWTMTyoxS1ogS2/Qa+uY9XWsZvaL4QRfua5TbdY9FIHetqjZJjWrgSWW77pDxuOeyNfirll0uw0GA5tBXzAQnYv67dh56NBQNXRBqVBAKVcwL+tebjUt/h+O46KqOs2mTa2mUSiUMM2HM1OzafwHfCfZgmA+/70AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png\"\n        srcset=\"/static/d0d7975fc223ded182582768b92bd9fc/12f09/residual_encoder_vc_decoder.png 148w,\n/static/d0d7975fc223ded182582768b92bd9fc/e4a3f/residual_encoder_vc_decoder.png 295w,\n/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png 590w,\n/static/d0d7975fc223ded182582768b92bd9fc/efc66/residual_encoder_vc_decoder.png 885w,\n/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png 978w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h4 id=\"21-residual-encoder\" style=\"position:relative;\"><a href=\"#21-residual-encoder\" aria-label=\"21 residual encoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 residual encoder</h4>\n<p>speech 를 decoding 하는 과정에서 아무리 transcription + speech 에 정보가 잘 있어도 speech 자체 만에 대한 정보도 다양하고 중요하여서,\n해당 정보를 따로 encoding 해서 decoder 에서 사용한다고 합니다.</p>\n<p>residual encoder 의 특징은 </p>\n<ul>\n<li>위에 한 번 언급된 speaker encoder 와 비슷한 구조</li>\n<li>temporal information 보존을 위해 time-wise 하게는 stride 적용 x</li>\n<li>특정 speaker feature 에 overfit 을 막기 위해 작은 channel size 를 사용. </li>\n<li>결론적으로 single channel output 이 위 문제를 막으면서 잘 동작했다고 캅니다.</li>\n<li>plus) Hann 으로 smoothing 함 (<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>21</mn></mrow><annotation encoding=\"application/x-tex\">k = 21</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">1</span></span></span></span>)</li>\n</ul>\n<h4 id=\"22-vc-decoder\" style=\"position:relative;\"><a href=\"#22-vc-decoder\" aria-label=\"22 vc decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2 VC decoder</h4>\n<p>위에 image 처럼, Cotatron feature 와 mel encoded feature 가 concat 돼서 들어가고 target speaker id 도 같이 들어갑니다.</p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>M</mi><mrow><mi>s</mi><mo>→</mo><mo>∗</mo></mrow></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>v</mi><mi>c</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mi>s</mi></msub><mo separator=\"true\">,</mo><msub><mi>R</mi><mi>s</mi></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msup><mi>y</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">M_{s \\to *} = Decoder_{vc} (concat(L_s, R_s), y^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.175696em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">s</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∗</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.099108em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathdefault mtight\">c</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p>VC decoder 구조는 <em>GAN-TTS</em> 란 paper 와 유사합니다. head, tail 에 1d conv 가 1 layer 씩 있고, 중간에 GBlock w/ CondBN 4 blocks 있는 형태 입니다.\n물론 CondBN 에 Condition 으로 target speaker feature 가 들어갑니다.</p>\n<p>요 decoder 에 대한 모델적인 여러 시도를 했는데 결론적으로 성능 향상은 없었다고 하면서 future works 로 남기며 턴을 종료했습니다.</p>\n<h3 id=\"3-training-recipe\" style=\"position:relative;\"><a href=\"#3-training-recipe\" aria-label=\"3 training recipe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. training recipe</h3>\n<p>은 논문 참고해 주세요 (<del>귀찮</del>)</p>\n<h2 id=\"experiment-result\" style=\"position:relative;\"><a href=\"#experiment-result\" aria-label=\"experiment result permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiment Result</h2>\n<h3 id=\"vctk-benchmark-many-to-many\" style=\"position:relative;\"><a href=\"#vctk-benchmark-many-to-many\" aria-label=\"vctk benchmark many to many permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VCTK Benchmark (many-to-many)</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABk0lEQVQoz12Tx44CMRBE5/9/B04gLiQJkUHknHPOsdjXK7PSWrLa7mlXV5U9nn7G6XRSoVBQs9nUcDhUuVy2da/XU7VaVbfb1Wg0sjWx3+9rPB6r3W6r0+mo1Wrpfr8DJe94POp8Pou43++13W612Wy+c7Vaab1e29pFN//vD4eDPLr5/X6Fw2HF43EDvlwuxpoGwWBQkUhEt9vNvnEoEAjI5/OZiufzaSypmU6n8mazmUkcDAYmh7lcLo01OSwgzudzXa9XLRYLy00mEwPa7XbWHDuoMUCYlUol1Wo1hUIhA2CQcz4BwoAFnlJTLBYNDOmZTOYPMJfLfbsCSgFyG42GHXQA5IhcAhFW1LJPpVKmzqM4kUiYTHzCE+Lj8RDNMBuZXM7r9TIPyQMEW+p5DQCS87hVAGOxmLLZrFGH7fv9lnsByMI/cngGODnOEmlOI2o8fEmn08rn84pGowbK4CNrZCC9Xq/bwUqlYmxQxtvFBhokk8nfW4YmDCmCJR7CAiCacJDnwQXhMfLYuzzy3c/AmQ8zdN71V6EArAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png\"\n        srcset=\"/static/1ff9906a2a1bfb44626eff66a7423181/12f09/vctk_benchmark.png 148w,\n/static/1ff9906a2a1bfb44626eff66a7423181/e4a3f/vctk_benchmark.png 295w,\n/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png 590w,\n/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png 821w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>기존 SOTA 인 Blow 보다 훨 높은 MOS, DMOS 를 보여줍니다. SCA 는 Blow 를 넘진 못헀네요.</p>\n<h3 id=\"speaker-disentanglement\" style=\"position:relative;\"><a href=\"#speaker-disentanglement\" aria-label=\"speaker disentanglement permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Speaker Disentanglement</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.675675675675674%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA2klEQVQY001QSQqEQBDz/78RxA+IV2/uihsquO+4QYYUzDBCsLuSTqpKwd8XBAF830ff93AcB1mWoSgKuK6LKIqQ57nwnucJqO+67t8CynEc2LYN67piWRY57/uOeZ4FrH85gucvN03T7y1x3zcUpqqqCsMwoOs6NE1DXdeI41hqpmmiLEvpJEkSMWJn5G3bxjiOCMNQ7td1QWmaBpZlifB5HpznKQTTOB4D3/eVP43YCc25EgZxQppxJWJIkgUaM20Yhh9owkesV1Ul+2zbVpCmqUxCHTXUcvwPlBJy1bxcaOoAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png\"\n        srcset=\"/static/81ba0c3552364e82dc7d254d975d1804/12f09/degree_of_speaker_disentanglement.png 148w,\n/static/81ba0c3552364e82dc7d254d975d1804/e4a3f/degree_of_speaker_disentanglement.png 295w,\n/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png 590w,\n/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png 830w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>그냥 Cotatron feature 만 쓸 때와 mel spectogram 만 따로 encoding 해서 쓴 경우와 비교했을 때,\nSCA 가 훨씬 높은 걸 보여주네요.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>간단한 concept 으로 꽤괜 성능이 나오고,\ntranscript 를 주지 않아도 성능이 준 것과 comparable 하다는 점도 재밌고,\nCortatron encoder 를 다른 task 에 적용해 봐도 재밌는 결과 볼 수 있을 것 같네용</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR 최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다. 간단하게 요약하면, 유명한 google 의 TTS model 인 tacotron2 기반…","tableOfContents":"<ul>\n<li><a href=\"/Cotatron/#tldr\">TL;DR</a></li>\n<li><a href=\"/Cotatron/#related-work\">Related Work</a></li>\n<li>\n<p><a href=\"/Cotatron/#architecture\">Architecture</a></p>\n<ul>\n<li><a href=\"/Cotatron/#1-speaker-independent-linguistic-features-from-tts\">1. speaker-independent linguistic features from TTS</a></li>\n<li><a href=\"/Cotatron/#2-voice-conversion\">2. voice conversion</a></li>\n<li><a href=\"/Cotatron/#3-training-recipe\">3. training recipe</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/Cotatron/#experiment-result\">Experiment Result</a></p>\n<ul>\n<li><a href=\"/Cotatron/#vctk-benchmark-many-to-many\">VCTK Benchmark (many-to-many)</a></li>\n<li><a href=\"/Cotatron/#speaker-disentanglement\">Speaker Disentanglement</a></li>\n</ul>\n</li>\n<li><a href=\"/Cotatron/#conclusion\">Conclusion</a></li>\n</ul>","fields":{"slug":"/Cotatron/"},"frontmatter":{"title":"Cotatron Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data","date":"May 10, 2020","tags":["Deep-Learning"],"keywords":["NLP","ChatBot","Blender"],"update":"May 10, 2020"},"timeToRead":4}},"pageContext":{"slug":"/Cotatron/","series":[],"lastmod":"2020-05-10"}},"staticQueryHashes":["2027115977","694178885"]}