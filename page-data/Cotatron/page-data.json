{"componentChunkName":"component---src-templates-post-tsx","path":"/Cotatron/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다.</p>\n<p>간단하게 요약하면, 유명한 google 의 TTS model 인 <em>tacotron2</em> 기반으로 given transcription 와 mel alignment 를 활용해서 speaker-independent linguistic representation 을 뽑는 concept(?) 입니다.</p>\n<p>결론은 VCTK dataset 에서 최근 paper 인 <em>Blow</em> 보다 높은 MOS, DMOS 를 달성했습니다. 아래 링크에 들어가면 모델이 생성한 sample 들을 들어볼 수 있어요.</p>\n<p>paper : <a href=\"https://arxiv.org/pdf/2005.03295.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></p>\n<p>demo : <a href=\"https://mindslab-ai.github.io/cotatron/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">link</a></p>\n<p>code : 아직 official code / pre-trained model은 없는데, 곧 나올 예정인 듯합니다</p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>이전 SOTA 였던 paper</p>\n<ul>\n<li>Blow : <a href=\"https://arxiv.org/pdf/1906.00794.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p><em>Cotatron</em>의 전체적인 architecture 는 아래와 같습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 88.51351351351352%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEaElEQVQ4y22UaWxUVRTHnwaX6Ae/GD+amPhRJDFRkBiwpQsqKgoIiCaaKCEghggKskUTN1SsrLad2nZoGeiCbVmkUGgplBbaaWfa6SydTjvtMPvSztKZ6cx0+vO+V5qY6En+Oeed++7vnvPevVcKx5Nc6LfTpBvh4uA9XMFJZrMzpDNZPG4jbmc7NmsLo7brjI22KZJjx9gNJS97r/s2Pk8HoZATyRuJc6LbQVGbkWK9jy7DEBMBHx5vkHuOW0zHmxkyVWG1VGMaPIXVXI2urxyvqxGX4y8BayQxdY3MdAuBwDBSZmaGyUgMvcFEIBTm35aMR5kMuknEgsSjAUVy3N/Xhb63S8D1mAxasaCekN9JOpVEkida3eN821iJbsRM0O/HZDaL6sYxuydosfq4anTSYnErumbxUNs5SM2tfs51GWnqtdGktdI6EsI7GZsDNna3s0b9E5VtlxgftXO3pwe7zSpeHuZ4j4ufm3X8cLGbHy9pOXSln2MdNlR9Ho7cMPNrywC/XNFTYghhdPrngKl0Fu2wiWQ6RTaTJjWdVFpOZTNMijg2kyEq8tFMipjI9QwasN5zYBkfYyI1Nz4ZmSIzM4sUiwaZCNlhdkaBmMZcmOxOJXZa3Wj/1qG72k+fqKyvWU/vZR1XNNfouniX62db6arrRH/dSL9jmGgigOR2dottUEUs5iWRTHPG6KfO6FOAVd/Vc3x/KQ2nLlCnauCCphnN0XreePR9cqTV5C9Yz4qnP2D50s28/Mwmrta2Ivk8vQwPVZEUdFExqttmym8aFaD6m1r2r/ue33acpGhHMcd2lXLowyIKn9jEsoWbyc3ZQt6ij8h7fAPLpFW0aNqQnI67dN85SSTiIhJLoOowo2obELhZ/thZyfPSqyyVXmeJlM9L0mssfmoDucu3kPPsx6x4cB150rvkS2sF8G3xCdpFy64edNoSPB4bo3YHZZ1DVNy2MBH2c+KLCl6R3mTlIxvJWbiVFXnbyV/4iYCsFXpHaA15D6wlX4CXSW/RWnMTyePWCmAp08mg0mZJu4GyGwNKXPbVaQFcRcHSbeS+sJWCxzZSKCAFC96j4KH1FAova6WIc8QCCtDtvIPFqCIR9xFPpKjUu9AMeBXg8S8ree7JVSx5eLVoN5cXpQLhC/+jxdJKFkk5XFa3IIXElvG47whgmFnxU25ZnXQOuxTggMVEyeEaKnZrKD9wlvJ9Z/hzr4bS3VWUfX0a1Z5qymSJuHinmhHDGJIMyYgtKHvZMtMJ/B4X/kCAWCSinM9UNkk6O01w0o/DZWd03EYoHOD/TJL/5rxm71NnslnSaXEyYjExMcyEAMvyiUXsDgdanQ6X10tYjMficaJTU4SjMXHi0nKFc6B5mOyz9+O6nnY+VR9mm7qIz6qP8vmZE+xqKGOr/Fx1RMltO/U7O2qL2X6umG6bae4sz4PmoVlRoWxNvR3sqilmf30ZBxoqOCBupIPn1eytU7GnpmQuJ3SwSc2+8+K2Gh3iH0I5evVqSeDsAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png\"\n        srcset=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/12f09/cotatron-architecture.png 148w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e4a3f/cotatron-architecture.png 295w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png 590w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png 861w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"1-speaker-independent-linguistic-features-from-tts\" style=\"position:relative;\"><a href=\"#1-speaker-independent-linguistic-features-from-tts\" aria-label=\"1 speaker independent linguistic features from tts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. speaker-independent linguistic features from TTS</h3>\n<p>이번에 제안한 <em>cotatron</em> 은 google 의 <em>tacotron2</em> 를 기반으로 합니다. </p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mover accent=\"true\"><msub><mi>M</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>^</mo></mover><mo separator=\"true\">,</mo><msub><mi>A</mi><mi>i</mi></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>M</mi><mrow><mn>0</mn><mo>:</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msup><mi>z</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{M_{1:i}} , A_i = Decoder (Encoder(T), M_{0:i-1}, z^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1412099999999998em;vertical-align:-0.19444em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9467699999999999em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathdefault mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.25233em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\">^</span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.31166399999999994em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.099108em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mrel mtight\">:</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p><em>T</em> 는 Transcription, <em>M</em> 은 log mel-spectogram, <em>z</em> 는 speaker representation.</p>\n<p>요거로부터 mel alignment + given transcription + speaker representation 으로 새로운 speech 를 생성합니다.</p>\n<p>이 이후가 중요(?)한데, TTS 훈련 후에,\nDecoder output 으로 transcription 과 mel-spectogram 사이의 <em>Alignment</em> 가 나오는데, 요 부분을 training 할 때 <em>teacher-forcing</em> 기술을 사용해서 훈련했다고 합니다.</p>\n<p>그래서 최종적으로 Speaker-Independent linguistic features 는 다음과 같습니다.</p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>L</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>t</mi><mi>m</mi><mi>u</mi><mi>l</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo separator=\"true\">,</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L = matmul(A, Encoder_{text}(T))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">m</span><span class=\"mord mathdefault\">u</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mord mathdefault mtight\">x</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p>그런데 한 가지 짚어야 할 점은,\n<em>T</em> 는 speaker 에 대한 정보가 없는 text 고,\n<em>A</em> 는 간단히 text 와 mel spectogram 과의 coef 라 할 수 있는데,\n즉, <em>L</em> 이 speaker 에 대한 정보를 담고 있지 않다는 점이다. 이 부분은 아래에</p>\n<p><em>Cotatron</em>은 이미 <em>Tacotron2</em> 기반의 모델이라 multi-speaker speech synthesis 에 well-optimized 됐을 거지만,\n조금 더 잘해 보려고(?) 기존의 embedding table 을 걷어내고, speaker representation encoder 를 하나 만들어 넣었다고 합니다.</p>\n<p>해당 encoder 구조는 2d cnn 6 layers + gru 구조로 구성.</p>\n<h4 id=\"speaker-disentanglement-issue-\" style=\"position:relative;\"><a href=\"#speaker-disentanglement-issue-\" aria-label=\"speaker disentanglement issue  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>speaker disentanglement issue ?</h4>\n<p>그래서 이런 speaker disentanglement 에 대한 issue 를 해결하기 위해 speaker classifier 를 추가로 붙여 줬다고 캅니다.</p>\n<p>이 때 사용된 모델은 간단한 1d cnn 4 layers + temporal max-pooling + fc 로 구성.</p>\n<h3 id=\"2-voice-conversion\" style=\"position:relative;\"><a href=\"#2-voice-conversion\" aria-label=\"2 voice conversion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. voice conversion</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.972972972972975%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACBklEQVQoz4WSS2/TQBSF/YP5A2yR2AFrFogFFHVRKoSEkFoeghYo0IaGpokTp44fSdzYTupX6meSj5sUlVQgMdLRSDN3zr3nnFH4z5oVGd1Oh15Ho33SoNVUCcJwdbdYLP6qV+I4JopCQUySBPheg2kSYowmfFBtji0PzTTZ+vqejc+7dAfW2vMFaZpxeZkznaYURYkymUzwPFfgEwQutvWGJPT5eKLxaL/Ji5rOsdbh/rtt7uxs0rR7xFmFk+SEacHo3MY0TrFMVUinKOvjVlVJWVbEcUQYBMxns5Ws5R6FEcPBgHNnyNO9OndffeN13WBoHYklzxj2d5jPZyjj8Rh3NMJxRtLtC7a5JUWf2GvoPHj7k42DDgcndW6/fMyt5w+p6W2RVqHbA/JqRlXmZFksSFbNlaLIpaBYTZZe+jK2w6yMSPMCw73ADRLiacypSK2bXSbxVSBJEv8zRKWn6+iCVrOF748JLhwmQUTNOKdmuhycDbHcgMOzFruNQ8pMvIsiPN+/Tnodiud5dDUNtaUKsYYzOMIVG7Z/9Ng86vHk+xnHhisJ73Bvd4tCCPM8F0Xln6zXvo+SZdkqnUBCWE4o/kuxWJCnVHkmSBG3KcSC4jfR8s2VTaVczW+QXqfsui6m/Lel/H6/j9bt0hXoeo+eYdBut7EsC1VVsW17tS/PkiS5QfgLwbfqMJ8UCT8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png\"\n        srcset=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/12f09/voice-conversion-system.png 148w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/e4a3f/voice-conversion-system.png 295w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png 590w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/efc66/voice-conversion-system.png 885w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png 936w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>위 이미지처럼 voice-conversion system 인데, 전반적인 pipeline 이 그려져 있습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.56756756756756%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADPklEQVQ4y02T2XPaVhjF+XOT6WQy6Use+t6HLtPF7l7j4K2Abbw3aR279oANOGaREYsMQiBhEBI7mNX2LxfcGefOnPmOPt0595xPV45+54iiusl10k36ao1s2oNp7NFr/ctt44xD6YLP9xd5ve/ixdocL1bneOn5RfB5Xh+4eLXnZDd6xkLgLX5FwlGuZylU0mgCCSWMWpIpmhkMK4NZy2PYJkEtSbiQEkhzkopwmo4SVGVCWoqQ6GdKGl9sOTmQQjh+eC/z86nCT8cpfhR87kjmV/8186dZPFGdTq9PrTvGag2oi5ov2ehmc8bt9gCrPWRyD51Wi8l4jOPveJZ3Vyr/yBpbYVnw/Oz5QMpzod4Q16ssplv8canz/fEV8wFxWEBhzp/hz4jBglwnVmowvO0yGI5wvDlL4Y4W8EoGS+Es7liRvyJ5XKEsB6kb+oMBt4MhfbF5OLmjateoNVuMBJ/2pu+mq9vtMhoJwf1kifVQCm8wyZpfYj2cZieeZ1cuEVBNdLvJiWpxmMhznNZ5G8/xTlJ5LxIdJQsiWQHVrFO3LSE4jZyt4YtpM3guc2xJRfYzJnvXNc70JqmShTtRZjmksCISrH5QWb3IsRTMiJrFFc4R1SoM+7fcPzw8Cm5EcvjiGmvBND6pwGZUZU+xOcnXuBuJSGOBu/FjtGadQbc947PeZMTTEoL7Yk7eoMxGOMXyaZT1izQbAjsJg0Cugiwcruc6eJJVnOcKTjHbhfMMLuHUmxLulQaJcmMmN3PojZdwX2q4I0XxQQxxVYpsJky8VxVO9R6lWouo2Sdy0yYkZulXygQEwlqNSKnNZblHpd1/9DcV3I4l8H2ICsRY9Z/P6nZUYjsu85+iitl0uB/VGPdtHiYtGpZGp2GIqE3Rr3M3tEXy2yfBV9u/88z5Fc9d3/B86VueLX7NZyvf8XLnN748XEfXY9StXZKJZWIRJ/HoIlLsDSl5BaPowyz7sKqJ/wXvceTKBvlqeQZNwKhbFMTvVrAqWGL4o1Gf8bgjalvcNYtWq0KvZwtuiyqci/5kPHhyWCrq4iSdrKKg5VTMm/Ks1qoWn67BYESxaFCt2hQKOoqSxfxkz1Rsuj4C0sLZodpsIawAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png\"\n        srcset=\"/static/d0d7975fc223ded182582768b92bd9fc/12f09/residual_encoder_vc_decoder.png 148w,\n/static/d0d7975fc223ded182582768b92bd9fc/e4a3f/residual_encoder_vc_decoder.png 295w,\n/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png 590w,\n/static/d0d7975fc223ded182582768b92bd9fc/efc66/residual_encoder_vc_decoder.png 885w,\n/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png 978w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<h4 id=\"21-residual-encoder\" style=\"position:relative;\"><a href=\"#21-residual-encoder\" aria-label=\"21 residual encoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 residual encoder</h4>\n<p>speech 를 decoding 하는 과정에서 아무리 transcription + speech 에 정보가 잘 있어도 speech 자체 만에 대한 정보도 다양하고 중요하여서,\n해당 정보를 따로 encoding 해서 decoder 에서 사용한다고 합니다.</p>\n<p>residual encoder 의 특징은 </p>\n<ul>\n<li>위에 한 번 언급된 speaker encoder 와 비슷한 구조</li>\n<li>temporal information 보존을 위해 time-wise 하게는 stride 적용 x</li>\n<li>특정 speaker feature 에 overfit 을 막기 위해 작은 channel size 를 사용. </li>\n<li>결론적으로 single channel output 이 위 문제를 막으면서 잘 동작했다고 캅니다.</li>\n<li>plus) Hann 으로 smoothing 함 (<span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>k</mi><mo>=</mo><mn>21</mn></mrow><annotation encoding=\"application/x-tex\">k = 21</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">2</span><span class=\"mord\">1</span></span></span></span>)</li>\n</ul>\n<h4 id=\"22-vc-decoder\" style=\"position:relative;\"><a href=\"#22-vc-decoder\" aria-label=\"22 vc decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2 VC decoder</h4>\n<p>위에 image 처럼, Cotatron feature 와 mel encoded feature 가 concat 돼서 들어가고 target speaker id 도 같이 들어갑니다.</p>\n<blockquote>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><msub><mi>M</mi><mrow><mi>s</mi><mo>→</mo><mo>∗</mo></mrow></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>v</mi><mi>c</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mi>s</mi></msub><mo separator=\"true\">,</mo><msub><mi>R</mi><mi>s</mi></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msup><mi>y</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">M_{s \\to *} = Decoder_{vc} (concat(L_s, R_s), y^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.83333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.175696em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.10903em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">s</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∗</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.099108em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mord mathdefault\">e</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">d</span><span class=\"mord mathdefault\">e</span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathdefault mtight\">c</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">o</span><span class=\"mord mathdefault\">n</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathdefault\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-left:-0.00773em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathdefault mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.849108em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></p>\n</blockquote>\n<p>VC decoder 구조는 <em>GAN-TTS</em> 란 paper 와 유사합니다. head, tail 에 1d conv 가 1 layer 씩 있고, 중간에 GBlock w/ CondBN 4 blocks 있는 형태 입니다.\n물론 CondBN 에 Condition 으로 target speaker feature 가 들어갑니다.</p>\n<p>요 decoder 에 대한 모델적인 여러 시도를 했는데 결론적으로 성능 향상은 없었다고 하면서 future works 로 남기며 턴을 종료했습니다.</p>\n<h3 id=\"3-training-recipe\" style=\"position:relative;\"><a href=\"#3-training-recipe\" aria-label=\"3 training recipe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. training recipe</h3>\n<p>은 논문 참고해 주세요 (<del>귀찮</del>)</p>\n<h2 id=\"experiment-result\" style=\"position:relative;\"><a href=\"#experiment-result\" aria-label=\"experiment result permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiment Result</h2>\n<h3 id=\"vctk-benchmark-many-to-many\" style=\"position:relative;\"><a href=\"#vctk-benchmark-many-to-many\" aria-label=\"vctk benchmark many to many permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VCTK Benchmark (many-to-many)</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABk0lEQVQoz3WTR44CMRBFff/rNCsQG5KEyCByzjnn+GdejZrdWLLcuMo/2Tj9jvP5rGKxqFarpdFopEqlona7rX6/r1qtpl6vp/F4bN+sg8FAk8lEnU5H3W7Xeh+PB1Byp9NJl8tFrIfDQbvdTtvt9jvX67U2m419/7f683g8ysEWCAQUiUSUSCQM+Hq9mmoIQqGQYrGY7ve71TgUDAbleZ45er1epjIajWo2m8nN53OzOBwOzQ5ztVqZavaIgHWxWOh2u2m5XNredDo1oP1+b+TEQc0AUVYul1Wv1xUOhw2AwR45MQFhoIJM6SmVSgaG9Ww2a6QGmM/nv6yA0gBzs9m0gz4AEbByCayoopff6XTa3Dmak8mkySUnMsHa8/kUZIRNjct5v9+WIUoAQi39vIZMJmN7jlsFMB6PK5fLmXTUfj4f+S8AW5CwRz/g1CCjBjlE9DhyAb1QKNhtYp9BEQJsYL3RaNjBarVq9nDG2yUGCFKp1N8tIxOFNKGSDMkPIEg4yPPgJZAx9vjt7xOL/2fgzA8yY97yRcAXngAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png\"\n        srcset=\"/static/1ff9906a2a1bfb44626eff66a7423181/12f09/vctk_benchmark.png 148w,\n/static/1ff9906a2a1bfb44626eff66a7423181/e4a3f/vctk_benchmark.png 295w,\n/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png 590w,\n/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png 821w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>기존 SOTA 인 Blow 보다 훨 높은 MOS, DMOS 를 보여줍니다. SCA 는 Blow 를 넘진 못헀네요.</p>\n<h3 id=\"speaker-disentanglement\" style=\"position:relative;\"><a href=\"#speaker-disentanglement\" aria-label=\"speaker disentanglement permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Speaker Disentanglement</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.675675675675674%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA10lEQVQY001QWQqFMBDr/W8jiBcQf/1z31BRwX0HRcgjA8orhJZkmsyMwt8JwxBBEGAYBriuizzPUZYlPM9DHMcoikJ03/cFrO/7/t8C6jxP7PuObduwrqu8j+PAsiwC8q9G8P1q8zx/f4n7vqGYqmkaTNOEYRjQdR1N0yBJEuEsy0JVVdJJlmViws6oO46DaZoQRRHSNMV1XVBt28K2bUl8nkdIgmkcj4HkedOIndCcK2EQJ6Q5VyKGFEnQmGnjOH6gCT+Rr+ta9sn6rutkv5yEdayhxvF/l+1y5B6RtxYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"img\"\n        src=\"/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png\"\n        srcset=\"/static/81ba0c3552364e82dc7d254d975d1804/12f09/degree_of_speaker_disentanglement.png 148w,\n/static/81ba0c3552364e82dc7d254d975d1804/e4a3f/degree_of_speaker_disentanglement.png 295w,\n/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png 590w,\n/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png 830w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n  </a>\n    </span></p>\n<p>그냥 Cotatron feature 만 쓸 때와 mel spectogram 만 따로 encoding 해서 쓴 경우와 비교했을 때,\nSCA 가 훨씬 높은 걸 보여주네요.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>간단한 concept 으로 꽤괜 성능이 나오고,\ntranscript 를 주지 않아도 성능이 준 것과 comparable 하다는 점도 재밌고,\nCortatron encoder 를 다른 task 에 적용해 봐도 재밌는 결과 볼 수 있을 것 같네용</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR 최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다. 간단하게 요약하면, 유명한 google 의 TTS model 인 tacotron2 기반…","tableOfContents":"<ul>\n<li><a href=\"/Cotatron/#tldr\">TL;DR</a></li>\n<li><a href=\"/Cotatron/#related-work\">Related Work</a></li>\n<li>\n<p><a href=\"/Cotatron/#architecture\">Architecture</a></p>\n<ul>\n<li><a href=\"/Cotatron/#1-speaker-independent-linguistic-features-from-tts\">1. speaker-independent linguistic features from TTS</a></li>\n<li><a href=\"/Cotatron/#2-voice-conversion\">2. voice conversion</a></li>\n<li><a href=\"/Cotatron/#3-training-recipe\">3. training recipe</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"/Cotatron/#experiment-result\">Experiment Result</a></p>\n<ul>\n<li><a href=\"/Cotatron/#vctk-benchmark-many-to-many\">VCTK Benchmark (many-to-many)</a></li>\n<li><a href=\"/Cotatron/#speaker-disentanglement\">Speaker Disentanglement</a></li>\n</ul>\n</li>\n<li><a href=\"/Cotatron/#conclusion\">Conclusion</a></li>\n</ul>","fields":{"slug":"/Cotatron/"},"frontmatter":{"title":"Cotatron Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data","date":"May 10, 2020","tags":["Deep-Learning"],"keywords":["NLP","ChatBot","Blender"],"update":"May 10, 2020"},"timeToRead":4}},"pageContext":{"slug":"/Cotatron/","series":[],"lastmod":"2020-05-10"}},"staticQueryHashes":["2027115977","694178885"]}