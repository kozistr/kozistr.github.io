{"componentChunkName":"component---src-templates-post-tsx","path":"/Cotatron/","result":{"data":{"markdownRemark":{"html":"<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다.</p>\n<p>간단하게 요약하면, 유명한 google 의 TTS model 인 <em>tacotron2</em> 기반으로 given transcription 와 mel alignment 를 활용해서 speaker-independent linguistic representation 을 뽑는 concept(?) 입니다.</p>\n<p>결론은 VCTK dataset 에서 최근 paper 인 <em>Blow</em> 보다 높은 MOS, DMOS 를 달성했습니다. 아래 링크에 들어가면 모델이 생성한 sample 들을 들어볼 수 있어요.</p>\n<p>paper : <a href=\"https://arxiv.org/pdf/2005.03295.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></p>\n<p>demo : <a href=\"https://mindslab-ai.github.io/cotatron/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">link</a></p>\n<p>code : 아직 official code / pre-trained model은 없는데, 곧 나올 예정인 듯합니다</p>\n<h2 id=\"related-work\" style=\"position:relative;\"><a href=\"#related-work\" aria-label=\"related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Related Work</h2>\n<p>이전 SOTA 였던 paper</p>\n<ul>\n<li>Blow : <a href=\"https://arxiv.org/pdf/1906.00794.pdf\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">arXiv</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p><em>Cotatron</em>의 전체적인 architecture 는 아래와 같습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 88.51351351351352%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsTAAALEwEAmpwYAAAEXElEQVR42m2TXUxTZxjHz3Bm2bLszl0s8X5Z5sU2pzM6pgxEM53bRMzMFqPuwyXuZnEXW7LtYk6FiW5+4MSiyJACAxEhWsEyFPm0lFJqKdBS+kV7ji2c0u/S9rf0gMm+nuSX98lzzvmd95+8ryBHYjQbpmkcsnLd5MEhBkgvJEkkUvi8o0i+LqzjGqas7UxPdTBt78Bmbcfl6MQ6ocHt7OSReJ+A1M1swIUgBiNc0Lk4c9eMakRk0DyJHHiEKM3idvUSj7QzaVFjHa/DYr6KdVzNyPAVfJ4bzLhb8M20Egl1koxp8fttCKl0mnA4gsFoQg6GSKfTPK5YJIQcEImGZSKhOaLhOeKRIAb9APoHfYybjTw06rGYjQSkGRaSCYTsh0aHlW+bVfSNGxFnvIwYjdhtNoxuPzctIq1GB20m1xJuansfUnt/lLo+M026SRofTHDbGsAzO78obNV1U3ylhJp7GtwOJ3qDAfe0nbZhK+d1M5S1Gyi9qaNUo6esw0h5j5VLBh9n741zSjvKyY4RVKYAZo9/UZhcWMDstBNPJoiEw8iyrEReyKSIpZMkMiniSyTJYBgz4fC6mXI7iS4kSJEhHouTTmcQgkERv3+SZCKqSEbtHkx2t9LbRx3cb+xnoEVHX/OgQk9TP22qW3TVd3NTpUFbqaW3dYi+SRNz8z4Er2eQadvvhMMisViSqyaJepOoCKuPNfDbj5W01d2ipbqN201aGi5cp/DZXWwQ3mHj8iJyV+5h/ep9rF6xC02tFkH0DjFhqSYakUimoKLbTOXdUUVY9X0dhwu/48i+Mn7ad4rj+3/hhx3HKFzxMW+9dpC8TV9Q8NJeCp4uJlfYxp26LgS3c4DBvnKCsodZOcTFHguqrqwwxfnDVawSNrJu2VbWCvm8LmxlzQsfkpd7kLyVe8l/ooh84QMKcorIFXagrb+XjfyA4aEKfF4b0w43ql4Ll3ssBEMByr+6zJvCNrY8s4eNrx4iP/9LCl48QH7OTkWkCHOKKMjZRa7wLp0N3QjeGR16XQWRiMRCNvJd09IOQfV1DRuE7Wxef4i8lz+n8KndFAo72fxkMZuX76ZwWbHCluW72SS8T+fiDgeYGKskGhGJRhNUG72oH0qK8Ow3Vax6fjvrnnuPtcLbrBEKWSNk42/5B2/kbOUVIQ+NWoswN+vC59MTjc4rkgGrh0Hr4rEZs41ztaKVhuMt1JfdoP7nFtQl16k52oi6pJna49eUVV3aTM2RRhwWF0ImA9nrm12Vw5yM4xd9SJJEUJZJJKPE0jES6Rii34fdacPmmFD6v9/7xyX8e5D1Zl/MIofm8c0GkOZmFTySxJTTyeDwME6fF0mewx+UFbLPY4n4f4XZSmcW/1zbr+Wji0fZX1HCgUsn+Kz6JIcaytlfWcqBylI+qTqh9AdrT/Np3Wn6J0z/L8ws5e8aG+bk7T84e+ca5/5soTxL1w3OtDfxq6ZRmZ3rXJyf6WrB4p7mLzwvfS/JDnZaAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png\"\n        srcset=\"/static/0ccd6e470b0bbb9a40438dd5fa01217b/12f09/cotatron-architecture.png 148w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e4a3f/cotatron-architecture.png 295w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/fcda8/cotatron-architecture.png 590w,\n/static/0ccd6e470b0bbb9a40438dd5fa01217b/e35ec/cotatron-architecture.png 861w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3 id=\"1-speaker-independent-linguistic-features-from-tts\" style=\"position:relative;\"><a href=\"#1-speaker-independent-linguistic-features-from-tts\" aria-label=\"1 speaker independent linguistic features from tts permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. speaker-independent linguistic features from TTS</h3>\n<p>이번에 제안한 <em>cotatron</em> 은 google 의 <em>tacotron2</em> 를 기반으로 합니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mover accent=\"true\"><msub><mi>M</mi><mrow><mn>1</mn><mo>:</mo><mi>i</mi></mrow></msub><mo>^</mo></mover><mo separator=\"true\">,</mo><msub><mi>A</mi><mi>i</mi></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>r</mi><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msub><mi>M</mi><mrow><mn>0</mn><mo>:</mo><mi>i</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><msup><mi>z</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\hat{M_{1:i}} , A_i = Decoder (Encoder(T), M_{0:i-1}, z^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1412em;vertical-align:-0.1944em;\"></span><span class=\"mord accent\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.9468em;\"><span style=\"top:-3em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span><span style=\"top:-3.2523em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"accent-body\" style=\"left:-0.25em;\"><span class=\"mord\">^</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">A</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">i</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0991em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">Deco</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">co</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">er</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3117em;\"><span style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span><span class=\"mrel mtight\">:</span><span class=\"mord mathnormal mtight\">i</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2083em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.04398em;\">z</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n</blockquote>\n<p><em>T</em> 는 Transcription, <em>M</em> 은 log mel-spectogram, <em>z</em> 는 speaker representation.</p>\n<p>요거로부터 mel alignment + given transcription + speaker representation 으로 새로운 speech 를 생성합니다.</p>\n<p>이 이후가 중요(?)한데, TTS 훈련 후에,\nDecoder output 으로 transcription 과 mel-spectogram 사이의 <em>Alignment</em> 가 나오는데, 요 부분을 training 할 때 <em>teacher-forcing</em> 기술을 사용해서 훈련했다고 합니다.</p>\n<p>그래서 최종적으로 Speaker-Independent linguistic features 는 다음과 같습니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>L</mi><mo>=</mo><mi>m</mi><mi>a</mi><mi>t</mi><mi>m</mi><mi>u</mi><mi>l</mi><mo stretchy=\"false\">(</mo><mi>A</mi><mo separator=\"true\">,</mo><mi>E</mi><mi>n</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>t</mi><mi>e</mi><mi>x</mi><mi>t</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>T</mi><mo stretchy=\"false\">)</mo><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">L = matmul(A, Encoder_{text}(T))</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\">L</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">ma</span><span class=\"mord mathnormal\">t</span><span class=\"mord mathnormal\">m</span><span class=\"mord mathnormal\">u</span><span class=\"mord mathnormal\" style=\"margin-right:0.01968em;\">l</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">A</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">co</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2806em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">t</span><span class=\"mord mathnormal mtight\">e</span><span class=\"mord mathnormal mtight\">x</span><span class=\"mord mathnormal mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"mclose\">))</span></span></span></span></span></p>\n</blockquote>\n<p>그런데 한 가지 짚어야 할 점은,\n<em>T</em> 는 speaker 에 대한 정보가 없는 text 고,\n<em>A</em> 는 간단히 text 와 mel spectogram 과의 coef 라 할 수 있는데,\n즉, <em>L</em> 이 speaker 에 대한 정보를 담고 있지 않다는 점이다. 이 부분은 아래에</p>\n<p><em>Cotatron</em>은 이미 <em>Tacotron2</em> 기반의 모델이라 multi-speaker speech synthesis 에 well-optimized 됐을 거지만,\n조금 더 잘해 보려고(?) 기존의 embedding table 을 걷어내고, speaker representation encoder 를 하나 만들어 넣었다고 합니다.</p>\n<p>해당 encoder 구조는 2d cnn 6 layers + gru 구조로 구성.</p>\n<h4 id=\"speaker-disentanglement-issue-\" style=\"position:relative;\"><a href=\"#speaker-disentanglement-issue-\" aria-label=\"speaker disentanglement issue  permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>speaker disentanglement issue ?</h4>\n<p>그래서 이런 speaker disentanglement 에 대한 issue 를 해결하기 위해 speaker classifier 를 추가로 붙여 줬다고 캅니다.</p>\n<p>이 때 사용된 모델은 간단한 1d cnn 4 layers + temporal max-pooling + fc 로 구성.</p>\n<h3 id=\"2-voice-conversion\" style=\"position:relative;\"><a href=\"#2-voice-conversion\" aria-label=\"2 voice conversion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. voice conversion</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.972972972972975%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACAUlEQVR42nWS7WvTUBjF8yf7QfBfUPzoFxkMBT+IQycqQ8QpYllX2Fu3dUnzsibpW9KkbdI1bzdN8pNEBhXmgYfnudzL4ZznHon/oKqqpidxhCLfoMkKcveS7nkXx3H+ebMNKUsz4jgmjmLSNCEMBqTJHf4q4nLoobohI8fl8KLD55MWinX7l4yqZkQIQZblZJkgzzdI8/kcx5kymUxZLH0s84BgMaIjD3jxo8vrdp9TReX59z0ef3lFW7umLGAlCtK8wPdchrbeVBiGSNtyi6JksylIkowgCNhsNlRVSZ7nROuI6XjCfOay3+nx9OspH88GTEfX6P23jO0DchEj1ayeN8N1PTz3nMnwE2PrFyfKgJe/e7zpqJzeKDz79o5HH3ZoKV2iWHBtWARRisgSorVHHC0oyxJJiJw0TZsdRGuHVaiTJQ5hlHA18lCdJX4Q0NZ7/FQuMGfTxk3t4CFI5sDEtoeoah/fX7C+C1ivY3RngeYskMcek/kK0x1zpF6RC0GcxHi+f5+HrQLJ8zx0XeOm18PQNWzziNlsyvuzW3aPdXbaGi1lzN7xIU/2dwnCsHFUJ+NBhfVFGAYsl0t836coimYXQmSNmrpXZUkmBHdx1Mz1Jz2UwYbwfqiVDkwTw9AZDodomo6u6xiGgWVZKIqCbdtNr8/9fh9ZlpuobIf8D3I86hyOA3FhAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png\"\n        srcset=\"/static/2e3ff1af06cf5a395aa66de760bdc7b0/12f09/voice-conversion-system.png 148w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/e4a3f/voice-conversion-system.png 295w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/fcda8/voice-conversion-system.png 590w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/efc66/voice-conversion-system.png 885w,\n/static/2e3ff1af06cf5a395aa66de760bdc7b0/6d2da/voice-conversion-system.png 936w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>위 이미지처럼 voice-conversion system 인데, 전반적인 pipeline 이 그려져 있습니다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 67.56756756756756%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsTAAALEwEAmpwYAAADPklEQVR42kWPe1MaZxjF+cCZTjrptNP2v36ATDu5GKtpEqwK0YhBvDSOl0HUyFVYdoHdFXZhuYmwwC67gOCvI7l4Zs6c5z3zPpfjsbsHGFoQWfRTyPqRpfdU9S16nX3sTpjPuUt+2Vnit50lfvTP8Xj1JU/W/+ax7yW/hrw8Cb3hQyxMMHXKcS6Fp9vP02xlqDfTKOoplWp89m6bIl0zj9Y02C0k2MvH2ZGibKYibCTChDLn7EoxtvNxUqUCvwfesHiyg+fZocTcicKrsMzzQ4kXRxLzEYW5iIo3VqZnOTjDCf3BGHc45brVpX7dwR3dYQ3GM06n0DE7WLaNZ/tSYTet8p9QZOMiy3ZKYS9zxU76iohcQaw08ea7LKZq/HmU5VlE5vmMBeZjOq9Fk1PthpFj4zgunn8iEsuJEr60gTeqsprUWUmUePdZYUMwMK0B3cEQ03ZnWm21MZo39JwRHdvFHLgMxxMGto3runh2JYPNRIFALM/7M4GNaI5Qusi2WOFYqdMw+6SqJhdXNWKlBpF8mZOcRqxYJ1qsc67W0Fo9zE77y8AttY0/rrIaVViOKvgSVwTEGoF8iwOti3Qf+bLKfFjkVVhk8azAwmmBuSOBhUiOF+Ecx7kKg36PyXSKZ7/YISSU2RYN1uMyoWyFkKCzp7Q4LrVxHAduR9xNxtzjvtHqmbN65t2OYTLhGzzBXJ3VU4HVM4G3xwlWzrP4zrNsZMrsy3XkaoutYp+P8g0rcZXlmMLShYIvWWIz3ySgmiSN9pcFd3d4PmQM1pJF1pMaa6kya0mNTbHOvX+o99CvO5xVbSJ6l33J4JNYZk/QOcjXCJc6nFT6qC3r60DwhASFYEokmJLwn6f4mBQJpQuEBJlDpczAsbm7tZiM+sAQq9uk12kALtOxxXTUY3rrPkT+ees1j7xPefTu6Xf94d+/+Cm4wB+ffKilDObNHoWcn2T8Lemkl8vEO6TsCnopwHUjSLOReIicNTTEqoZUK89YaBrkG8asLrabDByL0fCGodvCthv0uga2VccZNLGtxswfDfsPF1b0MmVN40pWZqxXa+jFErVq9fvWe4zHY3S9QqNxPVNZVqkYX//wgP8B6GvYu3NXNDAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png\"\n        srcset=\"/static/d0d7975fc223ded182582768b92bd9fc/12f09/residual_encoder_vc_decoder.png 148w,\n/static/d0d7975fc223ded182582768b92bd9fc/e4a3f/residual_encoder_vc_decoder.png 295w,\n/static/d0d7975fc223ded182582768b92bd9fc/fcda8/residual_encoder_vc_decoder.png 590w,\n/static/d0d7975fc223ded182582768b92bd9fc/efc66/residual_encoder_vc_decoder.png 885w,\n/static/d0d7975fc223ded182582768b92bd9fc/914c7/residual_encoder_vc_decoder.png 978w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h4 id=\"21-residual-encoder\" style=\"position:relative;\"><a href=\"#21-residual-encoder\" aria-label=\"21 residual encoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 residual encoder</h4>\n<p>speech 를 decoding 하는 과정에서 아무리 transcription + speech 에 정보가 잘 있어도 speech 자체 만에 대한 정보도 다양하고 중요하여서,\n해당 정보를 따로 encoding 해서 decoder 에서 사용한다고 합니다.</p>\n<p>residual encoder 의 특징은</p>\n<ul>\n<li>위에 한 번 언급된 speaker encoder 와 비슷한 구조</li>\n<li>temporal information 보존을 위해 time-wise 하게는 stride 적용 x</li>\n<li>특정 speaker feature 에 overfit 을 막기 위해 작은 channel size 를 사용.</li>\n<li>결론적으로 single channel output 이 위 문제를 막으면서 잘 동작했다고 캅니다.</li>\n<li>plus) Hann 으로 smoothing 함 (<span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi><mo>=</mo><mn>21</mn></mrow><annotation encoding=\"application/x-tex\">k = 21</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.03148em;\">k</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6444em;\"></span><span class=\"mord\">21</span></span></span></span></span>)</li>\n</ul>\n<h4 id=\"22-vc-decoder\" style=\"position:relative;\"><a href=\"#22-vc-decoder\" aria-label=\"22 vc decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2 VC decoder</h4>\n<p>위에 image 처럼, Cotatron feature 와 mel encoded feature 가 concat 돼서 들어가고 target speaker id 도 같이 들어갑니다.</p>\n<blockquote>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>M</mi><mrow><mi>s</mi><mo>→</mo><mo>∗</mo></mrow></msub><mo>=</mo><mi>D</mi><mi>e</mi><mi>c</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>r</mi><mrow><mi>v</mi><mi>c</mi></mrow></msub><mo stretchy=\"false\">(</mo><mi>c</mi><mi>o</mi><mi>n</mi><mi>c</mi><mi>a</mi><mi>t</mi><mo stretchy=\"false\">(</mo><msub><mi>L</mi><mi>s</mi></msub><mo separator=\"true\">,</mo><msub><mi>R</mi><mi>s</mi></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><msup><mi>y</mi><mrow><mi>i</mi><mi>d</mi></mrow></msup><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">M_{s \\to *} = Decoder_{vc} (concat(L_s, R_s), y^{id})</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8333em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.10903em;\">M</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1757em;\"><span style=\"top:-2.55em;margin-left:-0.109em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">s</span><span class=\"mrel mtight\">→</span><span class=\"mord mtight\">∗</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0991em;vertical-align:-0.25em;\"></span><span class=\"mord mathnormal\">Deco</span><span class=\"mord mathnormal\">d</span><span class=\"mord mathnormal\">e</span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">r</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0278em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03588em;\">v</span><span class=\"mord mathnormal mtight\">c</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\">co</span><span class=\"mord mathnormal\">n</span><span class=\"mord mathnormal\">c</span><span class=\"mord mathnormal\">a</span><span class=\"mord mathnormal\">t</span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">L</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.00773em;\">R</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">s</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.03588em;\">y</span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8491em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">i</span><span class=\"mord mathnormal mtight\">d</span></span></span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span></span></p>\n</blockquote>\n<p>VC decoder 구조는 <em>GAN-TTS</em> 란 paper 와 유사합니다. head, tail 에 1d conv 가 1 layer 씩 있고, 중간에 GBlock w/ CondBN 4 blocks 있는 형태 입니다.\n물론 CondBN 에 Condition 으로 target speaker feature 가 들어갑니다.</p>\n<p>요 decoder 에 대한 모델적인 여러 시도를 했는데 결론적으로 성능 향상은 없었다고 하면서 future works 로 남기며 턴을 종료했습니다.</p>\n<h3 id=\"3-training-recipe\" style=\"position:relative;\"><a href=\"#3-training-recipe\" aria-label=\"3 training recipe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. training recipe</h3>\n<p>은 논문 참고해 주세요 (<del>귀찮</del>)</p>\n<h2 id=\"experiment-result\" style=\"position:relative;\"><a href=\"#experiment-result\" aria-label=\"experiment result permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Experiment Result</h2>\n<h3 id=\"vctk-benchmark-many-to-many\" style=\"position:relative;\"><a href=\"#vctk-benchmark-many-to-many\" aria-label=\"vctk benchmark many to many permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>VCTK Benchmark (many-to-many)</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABkklEQVR42jWSV64CMRRDZ/+b4S0ACT7oILrovfcOovvpWGKkKIlz42t7EkhSv99XsVjUbDZTq9VSo9HQaDRSu932Hrzb7XpMp1Ofjcdj9Xo916zXa2j0/X4VXC4XMU6nk47Ho/b7vXa7neftduvB/of91uDsD4eD98z3+11BNBpVOBwWM0rf77fO57Mej4dqtZr+/v60WCx0u92MVatVhUIhxeNxYwhJp9Mql8t6Pp8Kms2mpWOFMZ/PXYiCwWBgbDKZ2MX1evWaGmwTxev18po4TFgoFJTP59XpdJTNZt2Nj0uoIStyQh2ENIGUbFmTG3UIgzzAFocEi1K6ofAXOpeJ4pcbSn6KmMEQVK/XfS/IZDJWQHdUAH4+H4e8Wq1MxAyOpeVyqc1mYwGc8SNwRnPyd4axWMxWS6WSKpWKL1JIbhAxYwcMcn4aA0JIEEMNQgIsJZNJk0UiET8FPjIlCqxjB1UQpFIp47iihkaIoMYZojCRSCiXy1nl7+3xuDkjJ4qxhF1I+BnkOhwOXUsDcFT/A2EZ33YqWIBQAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png\"\n        srcset=\"/static/1ff9906a2a1bfb44626eff66a7423181/12f09/vctk_benchmark.png 148w,\n/static/1ff9906a2a1bfb44626eff66a7423181/e4a3f/vctk_benchmark.png 295w,\n/static/1ff9906a2a1bfb44626eff66a7423181/fcda8/vctk_benchmark.png 590w,\n/static/1ff9906a2a1bfb44626eff66a7423181/02cd5/vctk_benchmark.png 821w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>기존 SOTA 인 Blow 보다 훨 높은 MOS, DMOS 를 보여줍니다. SCA 는 Blow 를 넘진 못헀네요.</p>\n<h3 id=\"speaker-disentanglement\" style=\"position:relative;\"><a href=\"#speaker-disentanglement\" aria-label=\"speaker disentanglement permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Speaker Disentanglement</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 25.675675675675674%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA4UlEQVR42k2Q1wqEQAxF/f+/8kFfRSzYe+8dC3iXBHZZISSTyZzrjYC/z/d9GIaBrutg2zaiKEKWZVx7nse167pwHAeWZXGvrut/BIRt27AsC+Z5xjAMmKaJo2katG3LPcrfM2WCUFRVxeI00/c99n2HQCBRFKEoCiRJ4voLUlUVmqbx+b5vhjzPg6IouCYHx3HwfZ7neN8XAj2UZZmH6G9JkZQIYJomr+C6LpRlydbHceTQdR1hGOI8T14VrYDgAtkLgoBBBFzXlVdAQaokRD3KcRz/LCZJwiLkkO7SNOW5DxfNc/W3QucXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img\"\n        title=\"\"\n        src=\"/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png\"\n        srcset=\"/static/81ba0c3552364e82dc7d254d975d1804/12f09/degree_of_speaker_disentanglement.png 148w,\n/static/81ba0c3552364e82dc7d254d975d1804/e4a3f/degree_of_speaker_disentanglement.png 295w,\n/static/81ba0c3552364e82dc7d254d975d1804/fcda8/degree_of_speaker_disentanglement.png 590w,\n/static/81ba0c3552364e82dc7d254d975d1804/715a3/degree_of_speaker_disentanglement.png 830w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>그냥 Cotatron feature 만 쓸 때와 mel spectogram 만 따로 encoding 해서 쓴 경우와 비교했을 때,\nSCA 가 훨씬 높은 걸 보여주네요.</p>\n<h2 id=\"conclusion\" style=\"position:relative;\"><a href=\"#conclusion\" aria-label=\"conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Conclusion</h2>\n<p>간단한 concept 으로 꽤괜 성능이 나오고,\ntranscript 를 주지 않아도 성능이 준 것과 comparable 하다는 점도 재밌고,\nCortatron encoder 를 다른 task 에 적용해 봐도 재밌는 결과 볼 수 있을 것 같네용</p>\n<p>결론 : 굳</p>","excerpt":"TL;DR 최근 mindslab 에서 VC (Voice Conversion)관련 논문이 나와서 오랜만에 요 쪽 domain 도 볼 겸 해서 논문을 읽게 됐습니다. 간단하게 요약하면, 유명한 google 의 TTS model 인 tacotron2 기반…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#related-work\">Related Work</a></p>\n</li>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li>\n<p><a href=\"#1-speaker-independent-linguistic-features-from-tts\">1. speaker-independent linguistic features from TTS</a></p>\n<ul>\n<li><a href=\"#speaker-disentanglement-issue-\">speaker disentanglement issue ?</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#2-voice-conversion\">2. voice conversion</a></p>\n<ul>\n<li><a href=\"#21-residual-encoder\">2.1 residual encoder</a></li>\n<li><a href=\"#22-vc-decoder\">2.2 VC decoder</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#3-training-recipe\">3. training recipe</a></p>\n</li>\n</ul>\n</li>\n<li>\n<p><a href=\"#experiment-result\">Experiment Result</a></p>\n<ul>\n<li><a href=\"#vctk-benchmark-many-to-many\">VCTK Benchmark (many-to-many)</a></li>\n<li><a href=\"#speaker-disentanglement\">Speaker Disentanglement</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#conclusion\">Conclusion</a></p>\n</li>\n</ul>","fields":{"slug":"/Cotatron/"},"frontmatter":{"title":"Cotatron Transcription-Guided Speech Encoder for Any-to-Many Voice Conversion without Parallel Data","date":"May 10, 2020","tags":["Deep-Learning"],"keywords":["NLP","ChatBot","Blender"],"update":"May 10, 2020"},"timeToRead":3}},"pageContext":{"slug":"/Cotatron/","series":[],"lastmod":"2020-05-10"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}