{"componentChunkName":"component---src-templates-post-tsx","path":"/birdcelf-2023/","result":{"data":{"markdownRemark":{"html":"<ul>\n<li>Original Post : <a href=\"https://www.kaggle.com/competitions/birdclef-2023/discussion/412996\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.kaggle.com/competitions/birdclef-2023/discussion/412996</a></li>\n</ul>\n<h2 id=\"architecture\" style=\"position:relative;\"><a href=\"#architecture\" aria-label=\"architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Architecture</h2>\n<p>Here's the pipeline.</p>\n<ol>\n<li>pre-train on 2020, 2021, 2022, xeno-canto datasets.</li>\n<li>fine-tune on 2023 dataset (based on the pre-trained weight).\n<ul>\n<li>minor classes (&#x3C;= 5 samples) are included in all folds</li>\n</ul>\n</li>\n</ol>\n<p>I applied the same training recipes (e.g. augmentation, loss functions, ...) each step.</p>\n<h3 id=\"cv\" style=\"position:relative;\"><a href=\"#cv\" aria-label=\"cv permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>CV</h3>\n<p>(although based on my few experiments) my cv score and LB/PB are kinda correlated.</p>\n<table>\n<thead>\n<tr>\n<th align=\"center\">Exp</th>\n<th align=\"center\">CV</th>\n<th align=\"center\">LB</th>\n<th align=\"center\">PB</th>\n<th align=\"center\">Note</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\"><code class=\"language-text\">effnetb0</code></td>\n<td align=\"center\">0.7720</td>\n<td align=\"center\">0.82438</td>\n<td align=\"center\">0.73641</td>\n<td align=\"center\">multiple losses, 5 folds</td>\n</tr>\n<tr>\n<td align=\"center\"><code class=\"language-text\">effnetb0</code></td>\n<td align=\"center\">0.7693</td>\n<td align=\"center\">0.82402</td>\n<td align=\"center\">0.73604</td>\n<td align=\"center\">clipwise loss, 5 folds</td>\n</tr>\n<tr>\n<td align=\"center\"><code class=\"language-text\">eca_nfnet_l0</code></td>\n<td align=\"center\">0.7753</td>\n<td align=\"center\">0.80731</td>\n<td align=\"center\">0.71845</td>\n<td align=\"center\">clipwise loss, single fold</td>\n</tr>\n</tbody>\n</table>\n<h3 id=\"model\" style=\"position:relative;\"><a href=\"#model\" aria-label=\"model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model</h3>\n<p>I used SED architecture with the <code class=\"language-text\">efficientnet_b0</code> backbone. Also, I tested <code class=\"language-text\">eca_nfnet_l0</code> backbone, and it has a better cv score, but I can't use it due to the latency.</p>\n<h3 id=\"training-recipe\" style=\"position:relative;\"><a href=\"#training-recipe\" aria-label=\"training recipe permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Training recipe</h3>\n<ul>\n<li>[<strong>Important</strong>] pre-training</li>\n<li>[<strong>Important</strong>] augmentations\n<ul>\n<li>waveform-level\n<ul>\n<li>[Important] or mixup on a raw waveform</li>\n<li>gaussian &#x26; uniform noise</li>\n<li>pitch shift</li>\n<li>[Important] background noise</li>\n</ul>\n</li>\n<li>spectrogram-level\n<ul>\n<li>spec augment</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>log-mel spectrogram\n<ul>\n<li>n_fft &#x26; window size 1024, hop size 320, min/max freq 20/14000, num_mels 256, top_db 80. (actually, I wanted n_fft with 2048, but I set it to 1024 by my mistake)</li>\n</ul>\n</li>\n<li>trained on 5 secs clips</li>\n<li>stratified k fold (5 folds, on primary_label)</li>\n<li>label smoothing 0.1</li>\n<li>multiple losses (from <a href=\"https://www.kaggle.com/competitions/birdclef-2021/discussion/243351\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">birdcelf 2021 top 5</a>)\n<ul>\n<li>bce loss on clip-wise output w/ weight 1.0</li>\n<li>bce loss on max of segment-wise outputs w/ weight 0.5</li>\n</ul>\n</li>\n<li>fp32</li>\n<li>AdamW + cosine annealing (w/o warmup)\n<ul>\n<li>50 epochs (usually converged between 40 ~ 50)</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"inference\" style=\"position:relative;\"><a href=\"#inference\" aria-label=\"inference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Inference</h2>\n<p>I can ensemble up to 4 models with Pytorch (it took nearly 2 hrs). To mix more models, I utilized ONNX and did graph optimization, and it makes one more model to be ensembled! Finally, I can ensemble 5 models (single model 5 folds). Also, to utilize the full CPU, I do some multi-processing stuff.</p>\n<h2 id=\"not-worked-perhaps-i-might-be-wrong\" style=\"position:relative;\"><a href=\"#not-worked-perhaps-i-might-be-wrong\" aria-label=\"not worked perhaps i might be wrong permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Not worked (perhaps I might be wrong)</h2>\n<ul>\n<li>secondary label (both hard label, soft label (e.g. 0.3, 0.5))</li>\n<li>focal loss</li>\n<li>longer clips (e.g. 15s)</li>\n<li>post-processings (proposed in the BirdCLEF 2021, and 2022 competitions)\n<ul>\n<li>aggregate the probs of the previous and next segments.</li>\n<li>if there's a bird above the threshold, multiply constants on all segments of the bird.)</li>\n</ul>\n</li>\n</ul>\n<p>I hope this could help!</p>\n<p>Thanks : )</p>","excerpt":"Original Post : https://www.kaggle.com/competitions/birdclef-2023/discussion/412996 Architecture Here's the pipeline. pre-train on 2020, 20â€¦","tableOfContents":"<ul>\n<li>\n<p><a href=\"#architecture\">Architecture</a></p>\n<ul>\n<li><a href=\"#cv\">CV</a></li>\n<li><a href=\"#model\">Model</a></li>\n<li><a href=\"#training-recipe\">Training recipe</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#inference\">Inference</a></p>\n</li>\n<li>\n<p><a href=\"#not-worked-perhaps-i-might-be-wrong\">Not worked (perhaps I might be wrong)</a></p>\n</li>\n</ul>","fields":{"slug":"/birdcelf-2023/"},"frontmatter":{"title":"(Kaggle) BirdCLEF 2023 - 24th (top 2%) place solution","date":"May 26, 2023","tags":["Deep-Learning","Kaggle"],"keywords":["audio","birdclef","cv","cnn"],"update":"May 26, 2023"},"timeToRead":2}},"pageContext":{"slug":"/birdcelf-2023/","series":[],"lastmod":"2023-05-26"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}