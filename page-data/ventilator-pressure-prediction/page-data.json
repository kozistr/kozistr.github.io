{"componentChunkName":"component---src-templates-post-tsx","path":"/ventilator-pressure-prediction/","result":{"data":{"markdownRemark":{"html":"<ul>\n<li>Original Post : <a href=\"https://www.kaggle.com/competitions/ventilator-pressure-prediction/discussion/285295\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">https://www.kaggle.com/competitions/ventilator-pressure-prediction/discussion/285295</a></li>\n</ul>\n<h2 id=\"tldr\" style=\"position:relative;\"><a href=\"#tldr\" aria-label=\"tldr permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TL;DR</h2>\n<p>Our solutions are focused on the two parts.</p>\n<ol>\n<li>Deep learning architectures</li>\n<li>multi-task learning that enables us to train the model more stable</li>\n</ol>\n<h2 id=\"pre-processing\" style=\"position:relative;\"><a href=\"#pre-processing\" aria-label=\"pre processing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pre-Processing</h2>\n<p>We didn't take much effort into developing pre-processing. The pre-processing publicly available is good enough for us!</p>\n<p>So, move on to the next chapter : )</p>\n<h2 id=\"model\" style=\"position:relative;\"><a href=\"#model\" aria-label=\"model permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Model</h2>\n<h3 id=\"arhcitecture\" style=\"position:relative;\"><a href=\"#arhcitecture\" aria-label=\"arhcitecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Arhcitecture</h3>\n<p>We developed a total of 3 types of architecture.</p>\n<ol>\n<li>WaveNet-wise blocks + bi-LSTM/GRU</li>\n<li>WaveNet-wise blocks + Transformer Encoder + bi-LSTM/GRU</li>\n<li>WaveNet-wise blocks + Transformer Encoder + Densely-Connected bi-LSTM</li>\n</ol>\n<p><img src=\"https://user-images.githubusercontent.com/15344796/140379611-d8368e31-2303-443d-a9b8-ef9bb309d57b.png\" alt=\"architecture\"></p>\n<p>We encode the features with CNN &#x26; Transformer blocks, then take them into the bi-LSTM layers.\nThe second model (WaveNet-wise blocks + Transformer Encoder + bi-LSTM/GRU) achieved the best CV score among our models.</p>\n<p>Actually, we can't submit those models as a single model because development &#x26; training were finished with the last few days of the challenge left. However, To assume with CV score (there're usually 0.02 gap between CV &#x26; LB scores in our cases), scores are like below.</p>\n<p>Here's the CV/LB table. Actually, we can't submit those models as a single model because development &#x26; training were finished with the last few days of the challenge left. However, To assume with CV score (there're usually 0.02 gap between CV &#x26; LB scores in our cases), maybe we can guess the LB score : )</p>\n<ul>\n<li><strong>w/o pseudo label</strong>, 15 folds (stratified), w/o post-process, same seed.</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">model</th>\n<th align=\"center\">CV</th>\n<th align=\"center\">LB</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">WaveNet-wise blocks + bi-LSTM/GRU</td>\n<td align=\"center\">0.13914</td>\n<td align=\"center\">0.1186</td>\n</tr>\n<tr>\n<td align=\"center\">WaveNet-wise blocks + Transformer Encoder + bi-LSTM/GRU</td>\n<td align=\"center\">0.136130</td>\n<td align=\"center\">0.1160 (assume)</td>\n</tr>\n<tr>\n<td align=\"center\">WaveNet-wise blocks + Transformer Encoder + Densely-Connected bi-LSTM</td>\n<td align=\"center\">0.137117</td>\n<td align=\"center\">0.1170 (assume)</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><strong>w/ pseudo label</strong>, 15 folds (stratified), w/o post-process, same seed.</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th align=\"center\">model</th>\n<th align=\"center\">cv</th>\n<th align=\"center\">lb</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td align=\"center\">WaveNet + bi-LSTM/GRU</td>\n<td align=\"center\">0.110575</td>\n<td align=\"center\">0.1147</td>\n</tr>\n<tr>\n<td align=\"center\">WaveNet + TRFM + bi-LSTM/GRU</td>\n<td align=\"center\">0.107606</td>\n<td align=\"center\">?</td>\n</tr>\n<tr>\n<td align=\"center\">WaveNet + TRFM + DC bi-LSTM</td>\n<td align=\"center\">0.110126</td>\n<td align=\"center\">?</td>\n</tr>\n<tr>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n<td align=\"center\"></td>\n</tr>\n</tbody>\n</table>\n<p>% There're 3 variants of models based on WaveNet + bi-LSTM/GRU. Posted one is the baseline version.\n% there's validation set mismatch between w/o and w/ pseudo label experiment.</p>\n<p>I'll also attach this table into the post!</p>\n<h3 id=\"multi-task-learning\" style=\"position:relative;\"><a href=\"#multi-task-learning\" aria-label=\"multi task learning permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Multi-Task Learning</h3>\n<p>In the early stage of the competition, I found that using <code class=\"language-text\">delta pressure</code> (diff of pressure) as an auxiliary loss raises CV/LB scores (+0.01 ~ 0.015 boosts).</p>\n<p>Similarly, <code class=\"language-text\">delta of delta pressure</code> (double diff pressure) as an auxiliary loss also boosts the performance by about +0.002 ~ 3 on CV/LB scores.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">df<span class=\"token punctuation\">[</span><span class=\"token string\">'delta_pressure'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'pressure'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> df<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token string\">'breath_id'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">'pressure'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shift<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>values\ndf<span class=\"token punctuation\">[</span><span class=\"token string\">'delta_delta_pressure'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span>df<span class=\"token punctuation\">[</span><span class=\"token string\">'delta_pressure'</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">-</span> df<span class=\"token punctuation\">.</span>groupby<span class=\"token punctuation\">(</span><span class=\"token string\">'breath_id'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token string\">'delta_pressure'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>shift<span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>fillna<span class=\"token punctuation\">(</span><span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>values</code></pre></div>\n<p>In the TF 2.x code, we use like below.\n<img src=\"https://user-images.githubusercontent.com/15344796/140241043-89243eb7-dfb1-4313-97d0-6dd47f1d6f0a.png\" alt=\"image\"></p>\n<h2 id=\"post-processing--ensemble\" style=\"position:relative;\"><a href=\"#post-processing--ensemble\" aria-label=\"post processing  ensemble permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Post-Processing / Ensemble</h2>\n<p>We can't find any huge boosts from the post-processing. However, Ensemble methods do bring an improvement!</p>\n<p>First, We tuned an ensemble weight with <code class=\"language-text\">Optuna</code> library based on the OOF predictions.\nAfter that, calculating <code class=\"language-text\">gap of predictions (spread)</code> and taking mean (w/o min, max predictions) or median selectively by <code class=\"language-text\">spread threshold</code> (optimized based on OOF) on the whole models (include the weighted ensemble prediction). It improves +0.0001 ~ CV boost compared with just taking a median.</p>\n<p>Ultimately, We ensembled the 5 models based on the above architectures with some differences (e.g. layers, features). Got CV 0.096600 LB 0.1131 PB 0.1171 (low CV score is due to training on the pseudo label)</p>\n<h2 id=\"summary\" style=\"position:relative;\"><a href=\"#summary\" aria-label=\"summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Summary</h2>\n<h3 id=\"works\" style=\"position:relative;\"><a href=\"#works\" aria-label=\"works permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Works</h3>\n<ul>\n<li>cross-validation\n<ul>\n<li>stratified k fold (on R, C factors) is better than group k fold</li>\n<li>15 folds is better than 10 folds (about +0.002 CV/LB boosts)</li>\n</ul>\n</li>\n<li>pseudo label\n<ul>\n<li>single model : CV 0.13914 LB 0.1186 PB 0.1226 -> CV 0.11057 LB 0.1147 PB 0.1186 (about LB/PB +0.004 improvement)</li>\n</ul>\n</li>\n<li>masked loss\n<ul>\n<li>only for <code class=\"language-text\">u_out</code> == 0 works better</li>\n</ul>\n</li>\n<li>multi-task learning\n<ul>\n<li><code class=\"language-text\">delta pressure</code> (about +0.01 ~ 0.015 CV/LB boosts)</li>\n<li><code class=\"language-text\">delta of delta pressure</code> (about +0.002 ~ 0.004 CV/LB boosts)</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"did-not-work\" style=\"position:relative;\"><a href=\"#did-not-work\" aria-label=\"did not work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Did not work</h3>\n<ul>\n<li>adding more features (e.g. more u_in lag, etc...)</li>\n<li>deeper network</li>\n<li>few folds/epochs</li>\n</ul>","excerpt":"Original Post : https://www.kaggle.com/competitions/ventilator-pressure-prediction/discussion/285295 TL;DR Our solutions are focused on the…","tableOfContents":"<ul>\n<li>\n<p><a href=\"#tldr\">TL;DR</a></p>\n</li>\n<li>\n<p><a href=\"#pre-processing\">Pre-Processing</a></p>\n</li>\n<li>\n<p><a href=\"#model\">Model</a></p>\n<ul>\n<li><a href=\"#arhcitecture\">Arhcitecture</a></li>\n<li><a href=\"#multi-task-learning\">Multi-Task Learning</a></li>\n</ul>\n</li>\n<li>\n<p><a href=\"#post-processing--ensemble\">Post-Processing / Ensemble</a></p>\n</li>\n<li>\n<p><a href=\"#summary\">Summary</a></p>\n<ul>\n<li><a href=\"#works\">Works</a></li>\n<li><a href=\"#did-not-work\">Did not work</a></li>\n</ul>\n</li>\n</ul>","fields":{"slug":"/ventilator-pressure-prediction/"},"frontmatter":{"title":"Ventilator Pressure Prediction (Kaggle) - 20th place solution","date":"Nov 03, 2021","tags":["Deep-Learning"],"keywords":["kaggle","google-brain","ventilator-pressure-prediction","transformer","rnn","cnn"],"update":"Jan 19, 2023"},"timeToRead":3}},"pageContext":{"slug":"/ventilator-pressure-prediction/","series":[],"lastmod":"2023-01-19"}},"staticQueryHashes":["2027115977","2744905544","694178885"],"slicesMap":{}}