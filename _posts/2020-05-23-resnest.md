---
layout: post
title: ResNeSt Split-Attention Networks
author: kozistr
categories: deep-learning
tags: DeepLearning, CV, ImageNet, ResNeSt, attention
use_math: true
---

posted by [kozistr](http://kozistr.tech)

## tl;dr

Amazon 에서 지난달에 재밌는 논문이 나왔는데요, 
새로운 image classification architecture 를 제안했는데, 
EfficientNet 보다 더 좋은 성능을 보이는 human-made architecture 를 선보였습니다. 멋지죠?

핵심은 *Split-Attention* 을 사용하는것 인데요, 자세한 건 본문에

결론은 ImageNet 에서 새로운 SOTA 를 찍었습니다.

paper : [arXiv](https://arxiv.org/pdf/2004.08955.pdf)
code : [github](https://github.com/zhanghang1989/ResNeSt)

## Related Work

ResNet 계열 논문들

* ResNet : [paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf)
* ResNetV2 : [paper](https://arxiv.org/pdf/1603.05027.pdf)
* ResNeXt : [paper](https://arxiv.org/pdf/1611.05431.pdf)

## Introduce



## Architecture

## Experiment Result

## Conclusion

요즘 architecture 들은 주로 baseline 구조에 AutoML 를 이용한 architecture search 가 이뤄지고 있는데,
이렇게 아직도 사람이 만든 architecture 에 대한 연구가 나오고 있고, 더 좋은 성능을 냈다는 게 정말 인상적 이네요.

또 전에 구글에서 나온 논문 무언가에서 ResNet 의 모든 convolution 을 attention 으로 교체했더니 더 좋은 성능이 나왔다라는 걸 본 적이 있는데,
여기서도 뭔가 더 아이디어를 얻어 볼 수 있을 것 같네요.

결론 : 굳굳굳
