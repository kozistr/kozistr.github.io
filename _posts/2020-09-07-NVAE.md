---
layout: post
title: NVAE A Deep Hierarchical Variational Autoencoder
author: kozistr
categories: deep-learning
tags: DeepLearning, Hierarchical, VAE, Generative-Models
use_math: true
---

posted by [kozistr](http://kozistr.tech)

## tl;dr

최근(?)에 NVLabs 에서 VAE 관련 논문이 하나 나왔는데, 매주 월요일이 회사 짬데이라고 개인 or 팀 끼리 공부하고 싶은 주제 공부하고 공유하는 문화가 있어서, 마침 잘 돼서 논문 리뷰를 해 봅니다.

paper : [arXiv](https://arxiv.org/pdf/2007.03898.pdf)

code : [github](https://github.com/NVlabs/NVAE)

## Related Work

VAE 관련 연구들이 엄청 많아서, 요 논문과 직접 연관이 있는 것들만 적어보면

1. IAF-VAEs (VAE w/ Invertible Autoregressive Flows) : [paper](https://arxiv.org/pdf/1606.04934.pdf)
2. VQ-VAE-2 (Vector Quantized Variational AutoEncoder v2) : [paper](https://arxiv.org/pdf/1906.00446.pdf)
3. BIVA (Bidirectional-Inference Variational Autoencoder) : [paper](https://arxiv.org/pdf/1902.02102.pdf)

## Difference

논문에서 previous works 와 this work 의 차이를 *related work* 에 적힌 3 개의 연구와 비교를 합니다.

요약하면 아래와 같습니다.

### VQ-VAE-2 vs NVAE

비슷한 점은 둘 다 high quality image 생성이 가능하다는 점

| diff \ work | VQ-VAE-2 | NVAE |
| :---: | :---: | :---: |
| objective | ~~VAE objective~~ | VAE objective |
| latent variable | up to 128x128 (big) | small | 

### IAF-VAEs vs NVAE

statistical models (hierarchical prior, approximate posterior) 컨셉을 IAF-VAEs 에서 가져온 것은 맞는데,

| diff \ work | IAF-VAEs | NVAE |
| :---: | :---: | :---: |
| statistical models | ~~neural network~~ | neural network |
| posterior | x | parameterized | 
| large-scale | x | o |

### BN (Batch Normalization) in VAE?

이전 연구들에선 BN 이 instability 를 cause 해서 사용을 지양했는데, 
이번 엔구에선 BN parameter 를 적절하게 사용하면 오히려 좋은 성능이 나온다 라고 하더군요.

## Novelty

위와 같은 차이점들에 대해서 이번 연구는 요약해서 크게 3 가지 novelties 를 가집니다.

### Network Design

이전 Hierarchical VAE 연구들은 hierarchical 한 요소들을 objective term 이나 level 에서 고려헀지만, 

이번 연구에서는 statistical models 을 **network design 자체에 녹여냈다**.

### Stability

hierarchical groups 수가 증가, input image size (high resolution) 가 커 지면서 stabilization 이 issue 가 되는데, 
이를 직접 디자인한 **(1) network modules**, **(2) approximate posterior 를 parameterize** 함으로 문제 해결. 

### Efficiency

효율적은 operation 사용 (e.g. depthwise separable convolution at decoder) 으로 memory 를 아끼고 성능도 잡아냈다.

% 저자 왈 depthwise separable conv 를 decoder 에 사용했을 땐 성능이 좋았는데, encoder 에 사용했을 땐 성능이 오히려 안좋았다고 캅니다. 

## Introduce

간단하게 deep hierarchical VAE 를 review 하고 넘어가면,

*approximate posterior* 와 *prior* 를 증가시키기 위해, *latent variables* 를 총 *$L$* 개의 disjoint groups 으로 나눕니다.

> $z = {z_1, z_2, ..., z_L}$

그리고 *prior* 와 *approximate posterior* 는 이렇게 써 볼 수 있을텐데, (물론 두 distributions 은 Normal 을 따른다 가정한다)

> $p(z) = \prod_{l} p(z_l\|z_{<l})$

> $q(z\|x) = \prod_{l} q(z_l\|z_{<l}, x)$

그럼 $log p(x)$ 에 대한 lower bound $L_{VAE} (x)$ 는 아래와 같이 쓸 수 있겠죠...?

> $L_{VAE} (x) = \mathbb{E}_{q(z\|x)} - KL(q(z_1\|x)\|\|p(z_1)) - \sum_{l=2}^{L} \mathbb{E}_{q(z_l\|x)}^{L} KL(q(z_{l}\|x, z_{<l})\|\|p(z_{l}\|z_{<l}))$

한번 더 적어보면, 아래가 이제 $(l - 1)^{th}$ group 까지의*approximate posterior* 가 되는 겁니다.

> $q(z_{<l}\|x) = \prod_{i=1}^{l-1} q(z_{i}\|x, z_{<i})$

그럼 여기서 $p(x, z)$, $p(z\|x)$ 를 어떻게 neural network 로 구현할 지가 이번 연구에서 포인트 입니다.

## Architecture

![img](/assets/NVAE/architecture.png)

## Experiment Result

이미지 생성 결과.

![img](/assets/NVAE/generated_images.png)

## Conclusion

개인적으로 NVIDIA 연구들은 보면 StyleGANv2 도 그렇고 network design 으로 문제를 해결해 나가는 모습을 많이 보이는데, 이번에도 어썸했다.

또, 연구를 진행하고 결과를 내는 것들이 대단하다 생각하지만,
최근 들어 VAE 쪽 논문들이 큰 novelty 없이 생산되는(?) 경향이 있었는데, 오랜만에 개인적으로 괜찮다 생각되는 AE 논문이 나온거 같아서 기분이가 좋았다.

결론 : 굳굳굳
